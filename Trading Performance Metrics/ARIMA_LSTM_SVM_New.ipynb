{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80748334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Data Analysis: S&P 500 and Bitcoin\n",
    "# Data Collection and Preprocessing\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import sklearn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbfbd0",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbbe5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading S&P 500 data...\n",
      "Downloading Bitcoin data...\n",
      "\n",
      "S&P 500 Data Shape: (5537, 5)\n",
      "S&P 500 Date Range: 2002-01-02 00:00:00 to 2023-12-29 00:00:00\n",
      "Total S&P 500 observations: 5537\n",
      "\n",
      "Bitcoin Data Shape: (3286, 5)\n",
      "Bitcoin Date Range: 2015-01-01 00:00:00 to 2023-12-30 00:00:00\n",
      "Total Bitcoin observations: 3286\n"
     ]
    }
   ],
   "source": [
    "# Data Download Configuration\n",
    "# S&P 500: January 1, 2002 to December 31, 2023\n",
    "# Bitcoin: January 1, 2015 to December 31, 2023\n",
    "\n",
    "# Define date ranges\n",
    "sp500_start = \"2002-01-01\"\n",
    "sp500_end = \"2023-12-31\"\n",
    "bitcoin_start = \"2015-01-01\"\n",
    "bitcoin_end = \"2023-12-31\"\n",
    "\n",
    "print(\"Downloading S&P 500 data...\")\n",
    "# Download S&P 500 data (^GSPC is the Yahoo Finance ticker)\n",
    "sp500_data = yf.download(\"^GSPC\", start=sp500_start, end=sp500_end, progress=False)\n",
    "\n",
    "print(\"Downloading Bitcoin data...\")\n",
    "# Download Bitcoin data (BTC-USD is the Yahoo Finance ticker)\n",
    "bitcoin_data = yf.download(\"BTC-USD\", start=bitcoin_start, end=bitcoin_end, progress=False)\n",
    "\n",
    "# Display basic information about downloaded data\n",
    "print(f\"\\nS&P 500 Data Shape: {sp500_data.shape}\")\n",
    "print(f\"S&P 500 Date Range: {sp500_data.index.min()} to {sp500_data.index.max()}\")\n",
    "print(f\"Total S&P 500 observations: {len(sp500_data)}\")\n",
    "\n",
    "print(f\"\\nBitcoin Data Shape: {bitcoin_data.shape}\")\n",
    "print(f\"Bitcoin Date Range: {bitcoin_data.index.min()} to {bitcoin_data.index.max()}\")\n",
    "print(f\"Total Bitcoin observations: {len(bitcoin_data)}\")\n",
    "\n",
    "# print(\"\\nData download completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15784118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification - S&P 500 has Adj Close: True\n",
      "Verification - Bitcoin has Adj Close: True\n"
     ]
    }
   ],
   "source": [
    "# Change Close column to Adj Close (because S&P 500 and Bitcoin doesn't have adjusted close price)\n",
    "\n",
    "sp500_data.columns = sp500_data.columns.set_levels(['Adj Close' if x == 'Close' else x for x in sp500_data.columns.levels[0]], level=0)\n",
    "\n",
    "bitcoin_data.columns = bitcoin_data.columns.set_levels(['Adj Close' if x == 'Close' else x for x in bitcoin_data.columns.levels[0]], level=0)\n",
    "\n",
    "\n",
    "print(\"\\nVerification - S&P 500 has Adj Close:\", ('Adj Close', '^GSPC') in sp500_data.columns)\n",
    "print(\"Verification - Bitcoin has Adj Close:\", ('Adj Close', 'BTC-USD') in bitcoin_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA QUALITY EXAMINATION ===\n",
      "\n",
      "S&P 500 Data Quality Check:\n",
      "------------------------------\n",
      "Missing values by column:\n",
      "Price      Ticker\n",
      "Adj Close  ^GSPC     0\n",
      "High       ^GSPC     0\n",
      "Low        ^GSPC     0\n",
      "Open       ^GSPC     0\n",
      "Volume     ^GSPC     0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "Data completeness: 100.00%\n",
      "\n",
      "Checking for zero or negative prices:\n",
      "Open: Ticker\n",
      "^GSPC    0\n",
      "dtype: int64 zero/negative values\n",
      "High: Ticker\n",
      "^GSPC    0\n",
      "dtype: int64 zero/negative values\n",
      "Low: Ticker\n",
      "^GSPC    0\n",
      "dtype: int64 zero/negative values\n",
      "Adj Close: Ticker\n",
      "^GSPC    0\n",
      "dtype: int64 zero/negative values\n",
      "\n",
      "S&P 500 Basic Statistics:\n",
      "Price          Open         High          Low    Adj Close        Volume\n",
      "Ticker        ^GSPC        ^GSPC        ^GSPC        ^GSPC         ^GSPC\n",
      "count   5537.000000  5537.000000  5537.000000  5537.000000  5.537000e+03\n",
      "mean    2032.993223  2044.721346  2020.494185  2033.362093  3.524833e+09\n",
      "std     1087.570786  1093.190058  1081.683341  1087.803828  1.416495e+09\n",
      "min      679.280029   695.270020   666.789978   676.530029  0.000000e+00\n",
      "25%     1191.380005  1198.619995  1184.489990  1191.500000  2.671550e+09\n",
      "50%     1525.099976  1532.400024  1518.750000  1525.400024  3.560090e+09\n",
      "75%     2712.399902  2728.090088  2696.879883  2711.449951  4.245140e+09\n",
      "max     4804.509766  4818.620117  4780.979980  4796.560059  1.145623e+10\n",
      "\n",
      "==================================================\n",
      "Bitcoin Data Quality Check:\n",
      "------------------------------\n",
      "Missing values by column:\n",
      "Price      Ticker \n",
      "Adj Close  BTC-USD    0\n",
      "High       BTC-USD    0\n",
      "Low        BTC-USD    0\n",
      "Open       BTC-USD    0\n",
      "Volume     BTC-USD    0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "Data completeness: 100.00%\n",
      "\n",
      "Checking for zero or negative prices:\n",
      "Open: Ticker\n",
      "BTC-USD    0\n",
      "dtype: int64 zero/negative values\n",
      "High: Ticker\n",
      "BTC-USD    0\n",
      "dtype: int64 zero/negative values\n",
      "Low: Ticker\n",
      "BTC-USD    0\n",
      "dtype: int64 zero/negative values\n",
      "Adj Close: Ticker\n",
      "BTC-USD    0\n",
      "dtype: int64 zero/negative values\n",
      "\n",
      "Bitcoin Basic Statistics:\n",
      "Price           Open          High           Low     Adj Close        Volume\n",
      "Ticker       BTC-USD       BTC-USD       BTC-USD       BTC-USD       BTC-USD\n",
      "count    3286.000000   3286.000000   3286.000000   3286.000000  3.286000e+03\n",
      "mean    15021.974057  15373.269205  14643.640114  15033.340909  1.708210e+10\n",
      "std     16235.870360  16625.794571  15798.240277  16237.727579  1.915699e+10\n",
      "min       176.897003    211.731003    171.509995    178.102997  7.860650e+06\n",
      "25%      1184.262512   1206.202515   1172.047485   1187.825043  3.338000e+08\n",
      "50%      8639.330566   8818.123535   8382.106445   8659.020508  1.277198e+10\n",
      "75%     25105.036133  25912.469238  24728.548340  25153.159668  2.742028e+10\n",
      "max     67549.734375  68789.625000  66382.062500  67566.828125  3.509679e+11\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning and Examination\n",
    "# Checking for missing or incorrect observations\n",
    "\n",
    "print(\"=== DATA QUALITY EXAMINATION ===\\n\")\n",
    "\n",
    "# S&P 500 Data Examination\n",
    "print(\"S&P 500 Data Quality Check:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Missing values by column:\")\n",
    "print(sp500_data.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {sp500_data.isnull().sum().sum()}\")\n",
    "print(f\"Data completeness: {((1 - sp500_data.isnull().sum().sum() / (len(sp500_data) * len(sp500_data.columns))) * 100):.2f}%\")\n",
    "\n",
    "# Check for zero or negative prices (incorrect observations)\n",
    "print(\"\\nChecking for zero or negative prices:\")\n",
    "for col in ['Open', 'High', 'Low', 'Adj Close']:\n",
    "    zero_negative = (sp500_data[col] <= 0).sum()\n",
    "    print(f\"{col}: {zero_negative} zero/negative values\")\n",
    "\n",
    "print(f\"\\nS&P 500 Basic Statistics:\")\n",
    "print(sp500_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']].describe())\n",
    "\n",
    "# Bitcoin Data Examination\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Bitcoin Data Quality Check:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Missing values by column:\")\n",
    "print(bitcoin_data.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {bitcoin_data.isnull().sum().sum()}\")\n",
    "print(f\"Data completeness: {((1 - bitcoin_data.isnull().sum().sum() / (len(bitcoin_data) * len(bitcoin_data.columns))) * 100):.2f}%\")\n",
    "\n",
    "# Check for zero or negative prices (incorrect observations)\n",
    "print(\"\\nChecking for zero or negative prices:\")\n",
    "for col in ['Open', 'High', 'Low', 'Adj Close']:\n",
    "    zero_negative = (bitcoin_data[col] <= 0).sum()\n",
    "    print(f\"{col}: {zero_negative} zero/negative values\")\n",
    "\n",
    "print(f\"\\nBitcoin Basic Statistics:\")\n",
    "print(bitcoin_data[['Open', 'High', 'Low', 'Adj Close', 'Volume']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbbc04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CALCULATING LOGARITHMIC RETURNS ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Logarithmic Returns (Dependent Variable)\n",
    "# Log returns = ln(P_t / P_{t-1}) = ln(P_t) - ln(P_{t-1})\n",
    "\n",
    "print(\"=== CALCULATING LOGARITHMIC RETURNS ===\\n\")\n",
    "\n",
    "# Calculate logarithmic returns for S&P 500\n",
    "sp500_data['Log_Returns'] = np.log(sp500_data['Adj Close'] / sp500_data['Adj Close'].shift(1))\n",
    "\n",
    "# Calculate logarithmic returns for Bitcoin\n",
    "bitcoin_data['Log_Returns'] = np.log(bitcoin_data['Adj Close'] / bitcoin_data['Adj Close'].shift(1))\n",
    "\n",
    "# Remove the first row (NaN due to shift operation)\n",
    "sp500_clean = sp500_data.dropna()\n",
    "bitcoin_clean = bitcoin_data.dropna()\n",
    "\n",
    "# Display statistics for logarithmic returns\n",
    "# print(\"S&P 500 Logarithmic Returns Statistics:\")\n",
    "# print(\"-\" * 40)\n",
    "# print(f\"Number of return observations: {len(sp500_clean)}\")\n",
    "# print(f\"Mean daily return: {sp500_clean['Log_Returns'].mean():.6f}\")\n",
    "# print(f\"Standard deviation: {sp500_clean['Log_Returns'].std():.6f}\")\n",
    "# print(f\"Minimum return: {sp500_clean['Log_Returns'].min():.6f}\")\n",
    "# print(f\"Maximum return: {sp500_clean['Log_Returns'].max():.6f}\")\n",
    "# print(f\"Skewness: {sp500_clean['Log_Returns'].skew():.4f}\")\n",
    "# print(f\"Kurtosis: {sp500_clean['Log_Returns'].kurtosis():.4f}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Bitcoin Logarithmic Returns Statistics:\")\n",
    "# print(\"-\" * 40)\n",
    "# print(f\"Number of return observations: {len(bitcoin_clean)}\")\n",
    "# print(f\"Mean daily return: {bitcoin_clean['Log_Returns'].mean():.6f}\")\n",
    "# print(f\"Standard deviation: {bitcoin_clean['Log_Returns'].std():.6f}\")\n",
    "# print(f\"Minimum return: {bitcoin_clean['Log_Returns'].min():.6f}\")\n",
    "# print(f\"Maximum return: {bitcoin_clean['Log_Returns'].max():.6f}\")\n",
    "# print(f\"Skewness: {bitcoin_clean['Log_Returns'].skew():.4f}\")\n",
    "# print(f\"Kurtosis: {bitcoin_clean['Log_Returns'].kurtosis():.4f}\")\n",
    "\n",
    "# # Check for infinite or NaN values in returns\n",
    "# print(f\"\\nS&P 500 - Infinite values: {np.isinf(sp500_clean['Log_Returns']).sum()}\")\n",
    "# print(f\"S&P 500 - NaN values: {sp500_clean['Log_Returns'].isnull().sum()}\")\n",
    "# print(f\"Bitcoin - Infinite values: {np.isinf(bitcoin_clean['Log_Returns']).sum()}\")\n",
    "# print(f\"Bitcoin - NaN values: {bitcoin_clean['Log_Returns'].isnull().sum()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78dbfadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOGARITHMIC RETURNS STATISTICS DATAFRAME ===\n",
      "         Observations  Mean_Daily_Return  Standard_Deviation  Minimum_Return  Maximum_Return  Skewness   Kurtosis  Infinite_Values  NaN_Values\n",
      "S&P_500          5536           0.000256            0.012245       -0.127652        0.109572 -0.423037  11.499578                0           0\n",
      "Bitcoin          3285           0.001491            0.037394       -0.464730        0.225119 -0.793774  11.618614                0           0\n",
      "\n",
      "=== STATISTICS TABLE (TRANSPOSED) ===\n",
      "                        S&P_500      Bitcoin\n",
      "Observations        5536.000000  3285.000000\n",
      "Mean_Daily_Return      0.000256     0.001491\n",
      "Standard_Deviation     0.012245     0.037394\n",
      "Minimum_Return        -0.127652    -0.464730\n",
      "Maximum_Return         0.109572     0.225119\n",
      "Skewness              -0.423037    -0.793774\n",
      "Kurtosis              11.499578    11.618614\n",
      "Infinite_Values        0.000000     0.000000\n",
      "NaN_Values             0.000000     0.000000\n",
      "\n",
      "DataFrame shape: (2, 9)\n",
      "DataFrame columns: ['Observations', 'Mean_Daily_Return', 'Standard_Deviation', 'Minimum_Return', 'Maximum_Return', 'Skewness', 'Kurtosis', 'Infinite_Values', 'NaN_Values']\n",
      "DataFrame index: ['S&P_500', 'Bitcoin']\n",
      "\n",
      "S&P 500 Mean Return: 0.000256\n",
      "Bitcoin Mean Return: 0.001491\n",
      "Volatility Ratio (Bitcoin/S&P500): 3.05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S&amp;P_500</th>\n",
       "      <th>Bitcoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Observations</th>\n",
       "      <td>5536.000000</td>\n",
       "      <td>3285.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean_Daily_Return</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard_Deviation</th>\n",
       "      <td>0.012245</td>\n",
       "      <td>0.037394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minimum_Return</th>\n",
       "      <td>-0.127652</td>\n",
       "      <td>-0.464730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maximum_Return</th>\n",
       "      <td>0.109572</td>\n",
       "      <td>0.225119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness</th>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.793774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>11.499578</td>\n",
       "      <td>11.618614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infinite_Values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN_Values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        S&P_500      Bitcoin\n",
       "Observations        5536.000000  3285.000000\n",
       "Mean_Daily_Return      0.000256     0.001491\n",
       "Standard_Deviation     0.012245     0.037394\n",
       "Minimum_Return        -0.127652    -0.464730\n",
       "Maximum_Return         0.109572     0.225119\n",
       "Skewness              -0.423037    -0.793774\n",
       "Kurtosis              11.499578    11.618614\n",
       "Infinite_Values        0.000000     0.000000\n",
       "NaN_Values             0.000000     0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a comprehensive statistics DataFrame\n",
    "statistics_data = {\n",
    "    'Observations': [len(sp500_clean), len(bitcoin_clean)],\n",
    "    'Mean_Daily_Return': [sp500_clean['Log_Returns'].mean(), bitcoin_clean['Log_Returns'].mean()],\n",
    "    'Standard_Deviation': [sp500_clean['Log_Returns'].std(), bitcoin_clean['Log_Returns'].std()],\n",
    "    'Minimum_Return': [sp500_clean['Log_Returns'].min(), bitcoin_clean['Log_Returns'].min()],\n",
    "    'Maximum_Return': [sp500_clean['Log_Returns'].max(), bitcoin_clean['Log_Returns'].max()],\n",
    "    'Skewness': [sp500_clean['Log_Returns'].skew(), bitcoin_clean['Log_Returns'].skew()],\n",
    "    'Kurtosis': [sp500_clean['Log_Returns'].kurtosis(), bitcoin_clean['Log_Returns'].kurtosis()],\n",
    "    'Infinite_Values': [np.isinf(sp500_clean['Log_Returns']).sum(), np.isinf(bitcoin_clean['Log_Returns']).sum()],\n",
    "    'NaN_Values': [sp500_clean['Log_Returns'].isnull().sum(), bitcoin_clean['Log_Returns'].isnull().sum()]\n",
    "}\n",
    "\n",
    "# Create DataFrame with asset names as index\n",
    "returns_statistics = pd.DataFrame(statistics_data, index=['S&P_500', 'Bitcoin'])\n",
    "\n",
    "print(\"=== LOGARITHMIC RETURNS STATISTICS DATAFRAME ===\")\n",
    "print(returns_statistics.round(6))\n",
    "\n",
    "# Display transposed version for better readability\n",
    "print(\"\\n=== STATISTICS TABLE (TRANSPOSED) ===\")\n",
    "print(returns_statistics.T.round(6))\n",
    "\n",
    "# Save the statistics DataFrame for later analysis\n",
    "print(f\"\\nDataFrame shape: {returns_statistics.shape}\")\n",
    "print(f\"DataFrame columns: {list(returns_statistics.columns)}\")\n",
    "print(f\"DataFrame index: {list(returns_statistics.index)}\")\n",
    "\n",
    "# Access specific statistics easily\n",
    "print(f\"\\nS&P 500 Mean Return: {returns_statistics.loc['S&P_500', 'Mean_Daily_Return']:.6f}\")\n",
    "print(f\"Bitcoin Mean Return: {returns_statistics.loc['Bitcoin', 'Mean_Daily_Return']:.6f}\")\n",
    "print(f\"Volatility Ratio (Bitcoin/S&P500): {returns_statistics.loc['Bitcoin', 'Standard_Deviation'] / returns_statistics.loc['S&P_500', 'Standard_Deviation']:.2f}\")\n",
    "\n",
    "# Display the DataFrame in different formats for export\n",
    "returns_statistics.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12d98bc",
   "metadata": {},
   "source": [
    "# Cross Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "## Answer?\n",
    "def createsp500cvsplits_FIXED(data, startdate=None, lookback_compensation=20):\n",
    "    \"\"\"\n",
    "    Create SP 500 cross-validation splits WITH lookback compensation.\n",
    "    \n",
    "    This version adjusts training start dates backward to account for \n",
    "    the lookback window needed by LSTM/SVM models.\n",
    "    \"\"\"\n",
    "    \n",
    "    if startdate is None:\n",
    "        startdate = data.index.min()\n",
    "    \n",
    "    cvsplits = []\n",
    "    window_start = startdate\n",
    "    \n",
    "    while True:\n",
    "        # Define window boundaries\n",
    "        train_start = window_start\n",
    "        train_end = train_start + relativedelta(years=3) - timedelta(days=1)\n",
    "        \n",
    "        # Validation periods (8, 16, 24 months)\n",
    "        val_start = train_end + timedelta(days=1)\n",
    "        val1_end = val_start + relativedelta(months=8) - timedelta(days=1)\n",
    "        val2_end = val_start + relativedelta(months=16) - timedelta(days=1)\n",
    "        val3_end = val_start + relativedelta(months=24) - timedelta(days=1)\n",
    "        \n",
    "        # Test period (1 year)\n",
    "        test_start = val3_end + timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=1) - timedelta(days=1)\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if test_end > data.index.max():\n",
    "            break\n",
    "        \n",
    "        # COMPENSATION: Extend training backwards for lookback window\n",
    "        # This allows LSTM/SVM to have enough history to generate predictions\n",
    "        # starting from the official test_start date\n",
    "        actual_train_start = train_start - timedelta(days=lookback_compensation)\n",
    "        actual_train_start = max(actual_train_start, data.index.min())\n",
    "        \n",
    "        # Get data with compensation\n",
    "        train_data = data[(data.index >= actual_train_start) & (data.index <= train_end)]\n",
    "        val1_data = data[(data.index >= val_start) & (data.index <= val1_end)]\n",
    "        val2_data = data[(data.index >= val_start) & (data.index <= val2_end)]\n",
    "        val3_data = data[(data.index >= val_start) & (data.index <= val3_end)]\n",
    "        \n",
    "        # TEST DATA: Use official test_start (after compensation is burned)\n",
    "        test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "        \n",
    "        # Create splits\n",
    "        train_start_for_record = train_start  # Record the original start\n",
    "        \n",
    "        cvsplits.append({\n",
    "            'window_id': len(cvsplits) + 1,\n",
    "            'train': {\n",
    "                'data': train_data,\n",
    "                'actual_start': actual_train_start,      # With lookback compensation\n",
    "                'official_start': train_start_for_record, # Original window start\n",
    "                'end': train_end,\n",
    "                'size': len(train_data)\n",
    "            },\n",
    "            'validation': [\n",
    "                {\n",
    "                    'fold': 1,\n",
    "                    'data': val1_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val1_end,\n",
    "                    'size': len(val1_data),\n",
    "                    'months': 8\n",
    "                },\n",
    "                {\n",
    "                    'fold': 2,\n",
    "                    'data': val2_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val2_end,\n",
    "                    'size': len(val2_data),\n",
    "                    'months': 16\n",
    "                },\n",
    "                {\n",
    "                    'fold': 3,\n",
    "                    'data': val3_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val3_end,\n",
    "                    'size': len(val3_data),\n",
    "                    'months': 24\n",
    "                }\n",
    "            ],\n",
    "            'test': {\n",
    "                'data': test_data,\n",
    "                'start': test_start,\n",
    "                'end': test_end,\n",
    "                'size': len(test_data)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Move window forward by 1 year\n",
    "        window_start += relativedelta(years=1)\n",
    "    \n",
    "    return cvsplits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29035289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross-Validation Implementation\n",
    "# Novel 3-fold cross-validation scheme with rolling windows\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# print(\"=== TIME SERIES CROSS-VALIDATION IMPLEMENTATION ===\\n\")\n",
    "\n",
    "def create_sp500_cv_splits(data, start_date=None):\n",
    "    \"\"\"\n",
    "    Create S&P 500 cross-validation splits:\n",
    "    - 6-year windows (3yr train + 2yr validation + 1yr test)  \n",
    "    - Validation split into 8, 16, 24 months\n",
    "    - Window moves 1 year forward each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    if start_date is None:\n",
    "        start_date = data.index.min()\n",
    "    \n",
    "    cv_splits = []\n",
    "    window_start = start_date\n",
    "    \n",
    "    while True:\n",
    "        # Define window boundaries\n",
    "        train_start = window_start\n",
    "        train_end = train_start + relativedelta(years=3) - timedelta(days=1)\n",
    "        \n",
    "        # Validation periods (8, 16, 24 months)\n",
    "        val_start = train_end + timedelta(days=1)\n",
    "        val1_end = val_start + relativedelta(months=8) - timedelta(days=1)  # 8 months\n",
    "        val2_end = val_start + relativedelta(months=16) - timedelta(days=1) # 16 months  \n",
    "        val3_end = val_start + relativedelta(months=24) - timedelta(days=1) # 24 months (2 years)\n",
    "        \n",
    "        # Test period (1 year)\n",
    "        test_start = val3_end + timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(years=1) - timedelta(days=1)\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if test_end > data.index.max():\n",
    "            break\n",
    "        \n",
    "        # Test Lookback\n",
    "        actual_train_start = train_start - timedelta(days=20)\n",
    "        actual_train_start = max(actual_train_start, data.index.min())\n",
    "\n",
    "        # Create splits for this window\n",
    "        train_data = data[(data.index >= actual_train_start) & (data.index <= train_end)]\n",
    "        \n",
    "        # Three validation folds\n",
    "        val1_data = data[(data.index >= val_start) & (data.index <= val1_end)]\n",
    "        val2_data = data[(data.index >= val_start) & (data.index <= val2_end)]\n",
    "        val3_data = data[(data.index >= val_start) & (data.index <= val3_end)]\n",
    "        \n",
    "        test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "        \n",
    "        cv_splits.append({\n",
    "            'window_id': len(cv_splits) + 1,\n",
    "            'train': {\n",
    "                'data': train_data,\n",
    "                'start': train_start,\n",
    "                'end': train_end,\n",
    "                'size': len(train_data)\n",
    "            },\n",
    "            'validation': [\n",
    "                {\n",
    "                    'fold': 1,\n",
    "                    'data': val1_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val1_end,\n",
    "                    'size': len(val1_data),\n",
    "                    'months': 8\n",
    "                },\n",
    "                {\n",
    "                    'fold': 2, \n",
    "                    'data': val2_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val2_end,\n",
    "                    'size': len(val2_data),\n",
    "                    'months': 16\n",
    "                },\n",
    "                {\n",
    "                    'fold': 3,\n",
    "                    'data': val3_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val3_end,\n",
    "                    'size': len(val3_data),\n",
    "                    'months': 24\n",
    "                }\n",
    "            ],\n",
    "            'test': {\n",
    "                'data': test_data,\n",
    "                'start': test_start,\n",
    "                'end': test_end,\n",
    "                'size': len(test_data)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Move window forward by 1 year\n",
    "        window_start += relativedelta(years=1)\n",
    "    \n",
    "    return cv_splits\n",
    "\n",
    "def create_bitcoin_cv_splits(data, start_date=None):\n",
    "    \"\"\"\n",
    "    Create Bitcoin cross-validation splits:\n",
    "    - 2-year training + validation periods + 6-month test\n",
    "    - Validation periods: 4, 8, 12 months\n",
    "    - Window shifts forward by 6 months each iteration  \n",
    "    - Testing period: 2018-01-01 to 2023-12-31\n",
    "    \"\"\"\n",
    "    \n",
    "    if start_date is None:\n",
    "        # Start from a date that allows for proper window construction\n",
    "        start_date = datetime(2015, 1, 1)\n",
    "    \n",
    "    cv_splits = []\n",
    "    window_start = start_date\n",
    "    \n",
    "    # Define the testing period constraint\n",
    "    test_period_start = datetime(2018, 1, 1)\n",
    "    test_period_end = datetime(2023, 12, 31)\n",
    "    \n",
    "    while True:\n",
    "        # Define window boundaries\n",
    "        train_start = window_start\n",
    "        train_end = train_start + relativedelta(years=2) - timedelta(days=1)\n",
    "        \n",
    "        # Validation periods (4, 8, 12 months)\n",
    "        val_start = train_end + timedelta(days=1)\n",
    "        val1_end = val_start + relativedelta(months=4) - timedelta(days=1)  # 4 months\n",
    "        val2_end = val_start + relativedelta(months=8) - timedelta(days=1)  # 8 months\n",
    "        val3_end = val_start + relativedelta(months=12) - timedelta(days=1) # 12 months\n",
    "        \n",
    "        # Test period (6 months)\n",
    "        test_start = val3_end + timedelta(days=1)\n",
    "        test_end = test_start + relativedelta(months=6) - timedelta(days=1)\n",
    "        \n",
    "        # Check constraints\n",
    "        if test_end > data.index.max() or test_end > test_period_end:\n",
    "            break\n",
    "        \n",
    "        # Only include windows where test period is within 2018-2023\n",
    "        if test_start < test_period_start:\n",
    "            window_start += relativedelta(months=6)\n",
    "            continue\n",
    "            \n",
    "        # Create splits for this window\n",
    "        train_data = data[(data.index >= train_start) & (data.index <= train_end)]\n",
    "        \n",
    "        # Three validation folds\n",
    "        val1_data = data[(data.index >= val_start) & (data.index <= val1_end)]\n",
    "        val2_data = data[(data.index >= val_start) & (data.index <= val2_end)]\n",
    "        val3_data = data[(data.index >= val_start) & (data.index <= val3_end)]\n",
    "        \n",
    "        test_data = data[(data.index >= test_start) & (data.index <= test_end)]\n",
    "        \n",
    "        cv_splits.append({\n",
    "            'window_id': len(cv_splits) + 1,\n",
    "            'train': {\n",
    "                'data': train_data,\n",
    "                'start': train_start,\n",
    "                'end': train_end,\n",
    "                'size': len(train_data)\n",
    "            },\n",
    "            'validation': [\n",
    "                {\n",
    "                    'fold': 1,\n",
    "                    'data': val1_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val1_end,\n",
    "                    'size': len(val1_data),\n",
    "                    'months': 4\n",
    "                },\n",
    "                {\n",
    "                    'fold': 2,\n",
    "                    'data': val2_data, \n",
    "                    'start': val_start,\n",
    "                    'end': val2_end,\n",
    "                    'size': len(val2_data),\n",
    "                    'months': 8\n",
    "                },\n",
    "                {\n",
    "                    'fold': 3,\n",
    "                    'data': val3_data,\n",
    "                    'start': val_start,\n",
    "                    'end': val3_end,\n",
    "                    'size': len(val3_data),\n",
    "                    'months': 12\n",
    "                }\n",
    "            ],\n",
    "            'test': {\n",
    "                'data': test_data,\n",
    "                'start': test_start,\n",
    "                'end': test_end,\n",
    "                'size': len(test_data)\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        # Move window forward by 6 months\n",
    "        window_start += relativedelta(months=6)\n",
    "    \n",
    "    return cv_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53e20646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATING CROSS-VALIDATION SPLITS ===\n",
      "\n",
      "\n",
      "=== S&P 500 CV WINDOWS (First set) ===\n",
      "\n",
      "Window 1:\n",
      "  Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "  Validation Folds:\n",
      "    Fold 1 (8mo): 2005-01-03 to 2005-09-02 (170 obs)\n",
      "    Fold 2 (16mo): 2005-01-03 to 2006-05-02 (335 obs)\n",
      "    Fold 3 (24mo): 2005-01-03 to 2007-01-02 (503 obs)\n",
      "  Test: 2007-01-03 to 2008-01-02 (252 obs)\n",
      "\n",
      "=== BITCOIN CV WINDOWS (First set) ===\n",
      "\n",
      "Window 1:\n",
      "  Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "  Validation Folds:\n",
      "    Fold 1 (4mo): 2017-01-01 to 2017-04-30 (120 obs)\n",
      "    Fold 2 (8mo): 2017-01-01 to 2017-08-31 (243 obs)\n",
      "    Fold 3 (12mo): 2017-01-01 to 2017-12-31 (365 obs)\n",
      "  Test: 2018-01-01 to 2018-06-30 (181 obs)\n",
      "\n",
      "=== CV SPLIT STATISTICS ===\n",
      "                     Size                  Window_ID\n",
      "                     mean    std  min  max     count\n",
      "Asset   Split_Type                                  \n",
      "Bitcoin Test        182.0    2.0  181  184        11\n",
      "        Train       731.0    1.0  730  731        11\n",
      "        Validation  243.0  101.0  120  366        33\n",
      "S&P_500 Test        252.0    1.0  251  253        16\n",
      "        Train       767.0    3.0  755  768        16\n",
      "        Validation  336.0  138.0  167  505        48\n"
     ]
    }
   ],
   "source": [
    "# Apply Cross-Validation Schemes to Data\n",
    "\n",
    "print(\"=== GENERATING CROSS-VALIDATION SPLITS ===\\n\")\n",
    "\n",
    "# Generate S&P 500 cross-validation splits\n",
    "sp500_cv_splits = create_sp500_cv_splits(sp500_clean)\n",
    "sp500_cv_splits_new = createsp500cvsplits_FIXED(sp500_clean)\n",
    "\n",
    "\n",
    "# Generate Bitcoin cross-validation splits  \n",
    "bitcoin_cv_splits = create_bitcoin_cv_splits(bitcoin_clean)\n",
    "\n",
    "\n",
    "# Create summary DataFrames\n",
    "def create_cv_summary(cv_splits, asset_name):\n",
    "    \"\"\"Create a summary DataFrame for cross-validation splits\"\"\"\n",
    "    summary_data = []\n",
    "    \n",
    "    for split in cv_splits:\n",
    "        # Add training data info\n",
    "        summary_data.append({\n",
    "            'Asset': asset_name,\n",
    "            'Window_ID': split['window_id'],\n",
    "            'Split_Type': 'Train',\n",
    "            'Fold': 'N/A',\n",
    "            'Start_Date': split['train']['start'].strftime('%Y-%m-%d'),\n",
    "            'End_Date': split['train']['end'].strftime('%Y-%m-%d'),\n",
    "            'Size': split['train']['size'],\n",
    "            'Duration_Months': 'N/A'\n",
    "        })\n",
    "        \n",
    "        # Add validation data info\n",
    "        for val_fold in split['validation']:\n",
    "            summary_data.append({\n",
    "                'Asset': asset_name,\n",
    "                'Window_ID': split['window_id'],\n",
    "                'Split_Type': 'Validation',\n",
    "                'Fold': val_fold['fold'],\n",
    "                'Start_Date': val_fold['start'].strftime('%Y-%m-%d'),\n",
    "                'End_Date': val_fold['end'].strftime('%Y-%m-%d'),\n",
    "                'Size': val_fold['size'],\n",
    "                'Duration_Months': val_fold['months']\n",
    "            })\n",
    "        \n",
    "        # Add test data info\n",
    "        summary_data.append({\n",
    "            'Asset': asset_name,\n",
    "            'Window_ID': split['window_id'],\n",
    "            'Split_Type': 'Test',\n",
    "            'Fold': 'N/A',\n",
    "            'Start_Date': split['test']['start'].strftime('%Y-%m-%d'),\n",
    "            'End_Date': split['test']['end'].strftime('%Y-%m-%d'),\n",
    "            'Size': split['test']['size'],\n",
    "            'Duration_Months': 'N/A'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary_data)\n",
    "\n",
    "# Create summary DataFrames\n",
    "sp500_cv_summary = create_cv_summary(sp500_cv_splits, 'S&P_500')\n",
    "bitcoin_cv_summary = create_cv_summary(bitcoin_cv_splits, 'Bitcoin')\n",
    "\n",
    "# Combined summary\n",
    "cv_summary_combined = pd.concat([sp500_cv_summary, bitcoin_cv_summary], ignore_index=True)\n",
    "\n",
    "# print(\"\\n=== CROSS-VALIDATION SUMMARY ===\")\n",
    "# print(f\"S&P 500 total windows: {len(sp500_cv_splits)}\")\n",
    "# print(f\"Bitcoin total windows: {len(bitcoin_cv_splits)}\")\n",
    "# print(f\"Total CV splits created: {len(cv_summary_combined)}\")\n",
    "\n",
    "# Display first few windows for each asset\n",
    "print(\"\\n=== S&P 500 CV WINDOWS (First set) ===\")\n",
    "for i, split in enumerate(sp500_cv_splits[:1]):\n",
    "    print(f\"\\nWindow {split['window_id']}:\")\n",
    "    print(f\"  Train: {split['train']['start'].strftime('%Y-%m-%d')} to {split['train']['end'].strftime('%Y-%m-%d')} ({split['train']['size']} obs)\")\n",
    "    print(f\"  Validation Folds:\")\n",
    "    for val_fold in split['validation']:\n",
    "        print(f\"    Fold {val_fold['fold']} ({val_fold['months']}mo): {val_fold['start'].strftime('%Y-%m-%d')} to {val_fold['end'].strftime('%Y-%m-%d')} ({val_fold['size']} obs)\")\n",
    "    print(f\"  Test: {split['test']['start'].strftime('%Y-%m-%d')} to {split['test']['end'].strftime('%Y-%m-%d')} ({split['test']['size']} obs)\")\n",
    "\n",
    "print(\"\\n=== BITCOIN CV WINDOWS (First set) ===\")\n",
    "for i, split in enumerate(bitcoin_cv_splits[:1]):\n",
    "    print(f\"\\nWindow {split['window_id']}:\")\n",
    "    print(f\"  Train: {split['train']['start'].strftime('%Y-%m-%d')} to {split['train']['end'].strftime('%Y-%m-%d')} ({split['train']['size']} obs)\")\n",
    "    print(f\"  Validation Folds:\")\n",
    "    for val_fold in split['validation']:\n",
    "        print(f\"    Fold {val_fold['fold']} ({val_fold['months']}mo): {val_fold['start'].strftime('%Y-%m-%d')} to {val_fold['end'].strftime('%Y-%m-%d')} ({val_fold['size']} obs)\")\n",
    "    print(f\"  Test: {split['test']['start'].strftime('%Y-%m-%d')} to {split['test']['end'].strftime('%Y-%m-%d')} ({split['test']['size']} obs)\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== CV SPLIT STATISTICS ===\")\n",
    "split_stats = cv_summary_combined.groupby(['Asset', 'Split_Type']).agg({\n",
    "    'Size': ['mean', 'std', 'min', 'max'],\n",
    "    'Window_ID': 'count'\n",
    "}).round(0)\n",
    "print(split_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c067b51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CROSS-VALIDATION DATA ACCESS EXAMPLES ===\n",
      "\n",
      "S&P 500 Window 1 - Training data shape: (755, 6)\n",
      "Training period: 2002-01-03 00:00:00 to 2004-12-31 00:00:00\n",
      "\n",
      "S&P 500 Window 1 - Validation Fold 2 shape: (335, 6)\n",
      "Validation period: 2005-01-03 00:00:00 to 2006-05-02 00:00:00\n",
      "\n",
      "Bitcoin Window 1 - Test data shape: (181, 6)\n",
      "Test period: 2018-01-01 00:00:00 to 2018-06-30 00:00:00\n",
      "\n",
      "================================================================================\n",
      "TIME SERIES CROSS-VALIDATION IMPLEMENTATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "âœ“ IMPLEMENTATION SUMMARY:\n",
      "\n",
      "ðŸ“Š S&P 500 Cross-Validation Scheme:\n",
      "   â€¢ 16 rolling windows of 6 years each\n",
      "   â€¢ Training: 3 years | Validation: 2 years (3 folds) | Test: 1 year\n",
      "   â€¢ Validation folds: 8, 16, and 24 months\n",
      "   â€¢ Window advancement: 1 year forward\n",
      "\n",
      "ðŸ“ˆ Bitcoin Cross-Validation Scheme:\n",
      "   â€¢ 11 rolling windows of ~3.5 years each  \n",
      "   â€¢ Training: 2 years | Validation: 1 year (3 folds) | Test: 6 months\n",
      "   â€¢ Validation folds: 4, 8, and 12 months\n",
      "   â€¢ Window advancement: 6 months forward\n",
      "   â€¢ Test period constraint: 2018-2023\n",
      "\n",
      "ðŸ”§ Key Features:\n",
      "   â€¢ Prevents data leakage through temporal ordering\n",
      "   â€¢ Robust hyperparameter selection via 3-fold validation\n",
      "   â€¢ Adapts to changing market conditions\n",
      "   â€¢ Novel variation of Choi et al. (2024) approach\n",
      "   â€¢ Comprehensive visualization and data access utilities\n",
      "\n",
      "ðŸ“ˆ Ready for Model Training:\n",
      "   â€¢ Use get_cv_data() function to access splits\n",
      "   â€¢ All data properly formatted with logarithmic returns\n",
      "   â€¢ Timeline visualizations available for paper figures\n",
      "\n",
      "ðŸš€ Your sophisticated time series cross-validation is now ready for machine learning model training!\n",
      "\n",
      "âœ“ All cross-validation data structures saved and ready for use!\n",
      "âœ“ Access data using: get_cv_data(sp500_cv_splits, window_id=1, return_type='train')\n",
      "âœ“ 27 total windows created across both assets\n"
     ]
    }
   ],
   "source": [
    "# Utility Functions for Cross-Validation Data Access\n",
    "\n",
    "def get_cv_data(cv_splits, window_id, fold=None, return_type='data'):\n",
    "    \"\"\"\n",
    "    Utility function to easily access cross-validation data\n",
    "    \n",
    "    Parameters:\n",
    "    - cv_splits: List of CV splits (sp500_cv_splits or bitcoin_cv_splits)\n",
    "    - window_id: Window ID (1, 2, 3, etc.)\n",
    "    - fold: Validation fold (1, 2, 3) or None for train/test\n",
    "    - return_type: 'train', 'validation', 'test', or 'data' (returns the data)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with the requested data split\n",
    "    \"\"\"\n",
    "    \n",
    "    split = next((s for s in cv_splits if s['window_id'] == window_id), None)\n",
    "    if split is None:\n",
    "        raise ValueError(f\"Window ID {window_id} not found\")\n",
    "    \n",
    "    if return_type == 'train':\n",
    "        return split['train']['data']\n",
    "    elif return_type == 'test':\n",
    "        return split['test']['data']\n",
    "    elif return_type == 'validation':\n",
    "        if fold is None:\n",
    "            raise ValueError(\"Fold number must be specified for validation data\")\n",
    "        if fold not in [1, 2, 3]:\n",
    "            raise ValueError(\"Fold must be 1, 2, or 3\")\n",
    "        return split['validation'][fold-1]['data']\n",
    "    else:\n",
    "        return split\n",
    "\n",
    "# Example usage functions\n",
    "def demonstrate_cv_usage():\n",
    "    \"\"\"Demonstrate how to use the cross-validation splits\"\"\"\n",
    "    \n",
    "    print(\"=== CROSS-VALIDATION DATA ACCESS EXAMPLES ===\\n\")\n",
    "    \n",
    "    # Example 1: Get training data from first S&P 500 window\n",
    "    train_data_sp500 = get_cv_data(sp500_cv_splits, window_id=1, return_type='train')\n",
    "    print(f\"S&P 500 Window 1 - Training data shape: {train_data_sp500.shape}\")\n",
    "    print(f\"Training period: {train_data_sp500.index.min()} to {train_data_sp500.index.max()}\")\n",
    "    \n",
    "    # Example 2: Get validation fold 2 data from first S&P 500 window  \n",
    "    val_data_sp500 = get_cv_data(sp500_cv_splits, window_id=1, fold=2, return_type='validation')\n",
    "    print(f\"\\nS&P 500 Window 1 - Validation Fold 2 shape: {val_data_sp500.shape}\")\n",
    "    print(f\"Validation period: {val_data_sp500.index.min()} to {val_data_sp500.index.max()}\")\n",
    "    \n",
    "    # Example 3: Get test data from first Bitcoin window\n",
    "    test_data_bitcoin = get_cv_data(bitcoin_cv_splits, window_id=1, return_type='test')\n",
    "    print(f\"\\nBitcoin Window 1 - Test data shape: {test_data_bitcoin.shape}\")\n",
    "    print(f\"Test period: {test_data_bitcoin.index.min()} to {test_data_bitcoin.index.max()}\")\n",
    "    \n",
    "    return train_data_sp500, val_data_sp500, test_data_bitcoin\n",
    "\n",
    "# Run demonstration\n",
    "sample_train, sample_val, sample_test = demonstrate_cv_usage()\n",
    "\n",
    "# Create final summary for the implementation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIME SERIES CROSS-VALIDATION IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "âœ“ IMPLEMENTATION SUMMARY:\n",
    "\n",
    "ðŸ“Š S&P 500 Cross-Validation Scheme:\n",
    "   â€¢ {len(sp500_cv_splits)} rolling windows of 6 years each\n",
    "   â€¢ Training: 3 years | Validation: 2 years (3 folds) | Test: 1 year\n",
    "   â€¢ Validation folds: 8, 16, and 24 months\n",
    "   â€¢ Window advancement: 1 year forward\n",
    "\n",
    "ðŸ“ˆ Bitcoin Cross-Validation Scheme:\n",
    "   â€¢ {len(bitcoin_cv_splits)} rolling windows of ~3.5 years each  \n",
    "   â€¢ Training: 2 years | Validation: 1 year (3 folds) | Test: 6 months\n",
    "   â€¢ Validation folds: 4, 8, and 12 months\n",
    "   â€¢ Window advancement: 6 months forward\n",
    "   â€¢ Test period constraint: 2018-2023\n",
    "\n",
    "ðŸ”§ Key Features:\n",
    "   â€¢ Prevents data leakage through temporal ordering\n",
    "   â€¢ Robust hyperparameter selection via 3-fold validation\n",
    "   â€¢ Adapts to changing market conditions\n",
    "   â€¢ Novel variation of Choi et al. (2024) approach\n",
    "   â€¢ Comprehensive visualization and data access utilities\n",
    "\n",
    "ðŸ“ˆ Ready for Model Training:\n",
    "   â€¢ Use get_cv_data() function to access splits\n",
    "   â€¢ All data properly formatted with logarithmic returns\n",
    "   â€¢ Timeline visualizations available for paper figures\n",
    "\"\"\")\n",
    "\n",
    "print(\"ðŸš€ Your sophisticated time series cross-validation is now ready for machine learning model training!\")\n",
    "\n",
    "# Save CV splits for later use (optional)\n",
    "cv_implementation_summary = {\n",
    "    'sp500_cv_splits': sp500_cv_splits,\n",
    "    'bitcoin_cv_splits': bitcoin_cv_splits,\n",
    "    'sp500_summary': sp500_cv_summary,\n",
    "    'bitcoin_summary': bitcoin_cv_summary,\n",
    "    'combined_summary': cv_summary_combined\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ“ All cross-validation data structures saved and ready for use!\")\n",
    "print(f\"âœ“ Access data using: get_cv_data(sp500_cv_splits, window_id=1, return_type='train')\")\n",
    "print(f\"âœ“ {len(sp500_cv_splits) + len(bitcoin_cv_splits)} total windows created across both assets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3940858d",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a50c9",
   "metadata": {},
   "source": [
    "Test for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "428e7c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -18.553729\n",
      "p-value: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "sp500_adf_test = adfuller(sp500_clean['Log_Returns'])\n",
    "# Output the results\n",
    "print('ADF Statistic: %f' % sp500_adf_test[0])\n",
    "print('p-value: %f' % sp500_adf_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a8221f",
   "metadata": {},
   "source": [
    "A p-value < 0.05 indicates that the S&P500 dataset is stationary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7191c2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "plot_acf(sp500_clean['Log_Returns'], lags=40)\n",
    "plot_pacf(sp500_clean['Log_Returns'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f20cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -58.553594\n",
      "p-value: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bitcoin_adf_test = adfuller(bitcoin_clean['Log_Returns'])\n",
    "# Output the results\n",
    "print('ADF Statistic: %f' % bitcoin_adf_test[0])\n",
    "print('p-value: %f' % bitcoin_adf_test[1])\n",
    "\n",
    "plot_acf(bitcoin_clean['Log_Returns'], lags=40)\n",
    "plot_pacf(bitcoin_clean['Log_Returns'], lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd5c68",
   "metadata": {},
   "source": [
    "A p-value < 0.05 indicates that the Bitcoin dataset is stationary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7ae366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AIC-BASED ARIMA MODEL SELECTION IMPLEMENTATION ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ARIMA Model Implementation with AIC-based Selection\n",
    "# Modern approach replacing traditional Box-Jenkins methodology\n",
    "\n",
    "import itertools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy import stats\n",
    "import time\n",
    "\n",
    "# Suppress convergence warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "print(\"=== AIC-BASED ARIMA MODEL SELECTION IMPLEMENTATION ===\\n\")\n",
    "\n",
    "def find_optimal_arima_order(data, max_p=5, max_d=2, max_q=5, seasonal=False, \n",
    "                           information_criterion='aic', verbose=False):\n",
    "    \"\"\"\n",
    "    Find optimal ARIMA(p,d,q) order using information criterion approach.\n",
    "    \n",
    "    This function implements the modern methodology described in the paper,\n",
    "    replacing the subjective Box-Jenkins approach with automated mathematical\n",
    "    framework based on AIC minimization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.Series\n",
    "        Time series data (log returns)\n",
    "    max_p : int\n",
    "        Maximum autoregressive order to test\n",
    "    max_d : int  \n",
    "        Maximum differencing order to test\n",
    "    max_q : int\n",
    "        Maximum moving average order to test\n",
    "    seasonal : bool\n",
    "        Whether to include seasonal components\n",
    "    information_criterion : str\n",
    "        Information criterion ('aic', 'bic', 'hqic')\n",
    "    verbose : bool\n",
    "        Whether to print detailed progress\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing optimal parameters and model diagnostics\n",
    "    \"\"\"\n",
    "    \n",
    "    best_ic = np.inf\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    results_log = []\n",
    "    \n",
    "    # Create parameter grid\n",
    "    if seasonal:\n",
    "        # For seasonal ARIMA (not implemented in this study)\n",
    "        param_grid = itertools.product(range(max_p+1), range(max_d+1), range(max_q+1),\n",
    "                                     range(2), range(2), range(2), [12])\n",
    "    else:\n",
    "        # Standard ARIMA grid search\n",
    "        param_grid = itertools.product(range(max_p+1), range(max_d+1), range(max_q+1))\n",
    "    \n",
    "    total_combinations = (max_p+1) * (max_d+1) * (max_q+1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Testing {total_combinations} ARIMA parameter combinations...\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "    for i, params in enumerate(param_grid):\n",
    "        p, d, q = params[:3]\n",
    "        \n",
    "        # Skip if model is too simple (all parameters zero)\n",
    "        if p == 0 and d == 0 and q == 0:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Fit ARIMA model\n",
    "            model = ARIMA(data, order=(p, d, q))\n",
    "            fitted_model = model.fit()\n",
    "            \n",
    "            # Get information criterion value\n",
    "            if information_criterion.lower() == 'aic':\n",
    "                ic_value = fitted_model.aic\n",
    "            elif information_criterion.lower() == 'bic':\n",
    "                ic_value = fitted_model.bic  \n",
    "            elif information_criterion.lower() == 'hqic':\n",
    "                ic_value = fitted_model.hqic\n",
    "            else:\n",
    "                ic_value = fitted_model.aic\n",
    "            \n",
    "            # Store results\n",
    "            results_log.append({\n",
    "                'order': (p, d, q),\n",
    "                'aic': fitted_model.aic,\n",
    "                'bic': fitted_model.bic,\n",
    "                'hqic': fitted_model.hqic,\n",
    "                'llf': fitted_model.llf,\n",
    "                'converged': fitted_model.mle_retvals['converged'] if hasattr(fitted_model, 'mle_retvals') else True\n",
    "            })\n",
    "            \n",
    "            # Update best model if current is better\n",
    "            if ic_value < best_ic:\n",
    "                best_ic = ic_value\n",
    "                best_params = (p, d, q)\n",
    "                best_model = fitted_model\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Log failed fits\n",
    "            results_log.append({\n",
    "                'order': (p, d, q),\n",
    "                'aic': np.nan,\n",
    "                'bic': np.nan,  \n",
    "                'hqic': np.nan,\n",
    "                'llf': np.nan,\n",
    "                'converged': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            \n",
    "            if verbose and i % 10 == 0:\n",
    "                print(f\"Failed to fit ARIMA{params}: {str(e)[:50]}...\")\n",
    "                \n",
    "        if verbose and (i + 1) % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            progress = (i + 1) / total_combinations * 100\n",
    "            print(f\"Progress: {progress:.1f}% ({i+1}/{total_combinations}) | \"\n",
    "                  f\"Best so far: ARIMA{best_params} ({information_criterion.upper()}={best_ic:.4f})\")\n",
    "    \n",
    "    if verbose:\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nGrid search completed in {total_time:.2f} seconds\")\n",
    "        print(f\"Best model: ARIMA{best_params} with {information_criterion.upper()}={best_ic:.4f}\")\n",
    "    \n",
    "    # Create results summary\n",
    "    results_df = pd.DataFrame(results_log)\n",
    "    successful_fits = results_df[results_df['converged'] == True]\n",
    "    \n",
    "    return {\n",
    "        'best_order': best_params,\n",
    "        'best_model': best_model,\n",
    "        'best_ic_value': best_ic,\n",
    "        'information_criterion': information_criterion,\n",
    "        'results_df': results_df,\n",
    "        'successful_fits': len(successful_fits),\n",
    "        'total_attempts': len(results_log),\n",
    "        'success_rate': len(successful_fits) / len(results_log) * 100\n",
    "    }\n",
    "\n",
    "def evaluate_arima_model(model, train_data, test_data, model_order):\n",
    "    \"\"\"\n",
    "    Comprehensive ARIMA model evaluation including diagnostic tests.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : fitted ARIMA model\n",
    "        The trained ARIMA model\n",
    "    train_data : pd.Series\n",
    "        Training data used to fit the model\n",
    "    test_data : pd.Series  \n",
    "        Test data for out-of-sample evaluation\n",
    "    model_order : tuple\n",
    "        (p, d, q) order of the ARIMA model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing evaluation metrics and diagnostics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate forecasts\n",
    "    n_forecast = len(test_data)\n",
    "    forecast_result = model.get_forecast(steps=n_forecast)\n",
    "    forecasts = forecast_result.predicted_mean\n",
    "    forecast_ci = forecast_result.conf_int()\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(test_data, forecasts)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_data, forecasts)\n",
    "    mape = np.mean(np.abs((test_data - forecasts) / test_data)) * 100\n",
    "    \n",
    "    # Calculate RÂ² score for fair comparison with LSTM and SVM\n",
    "    ss_res = np.sum((test_data - forecasts) ** 2)\n",
    "    ss_tot = np.sum((test_data - np.mean(test_data)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    # Direction accuracy (for returns)\n",
    "    direction_actual = np.sign(test_data.values[1:])\n",
    "    direction_forecast = np.sign(forecasts.values[1:])\n",
    "    direction_accuracy = np.mean(direction_actual == direction_forecast) * 100\n",
    "    \n",
    "    # Residual diagnostics\n",
    "    residuals = model.resid\n",
    "    \n",
    "    # Ljung-Box test for serial correlation in residuals\n",
    "    lb_test = acorr_ljungbox(residuals, lags=10, return_df=False)\n",
    "    # print(\"DEBUGGING Ljung-Box p-values (array):\", lb_test['lb_pvalue'])\n",
    "    # print(\"DEBUGGING Ljung-Box p-value type:\", type(lb_pvalue))\n",
    "    # print(\"DEBUGGING Last p-value (lag 10):\", lb_test['lb_pvalue'][-1] if isinstance(lb_test['lb_pvalue'], np.ndarray) else lb_test['lb_pvalue'])\n",
    "    # print(\"DEBUGGING All p-values shape:\", lb_pvalue.shape if hasattr(lb_pvalue, 'shape') else 'no shape')\n",
    "    \n",
    "    # Normality test (Jarque-Bera)\n",
    "    jb_stat, jb_pvalue = stats.jarque_bera(residuals)\n",
    "    \n",
    "    # Heteroskedasticity test (simple approach)\n",
    "    residuals_squared = residuals ** 2\n",
    "    arch_stat, arch_pvalue = acorr_ljungbox(residuals_squared, lags=5, return_df=False)\n",
    "    \n",
    "    return {\n",
    "        'model_order': model_order,\n",
    "        'forecasts': forecasts,\n",
    "        'forecast_ci': forecast_ci,\n",
    "        'performance_metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse, \n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'direction_accuracy': direction_accuracy\n",
    "        },\n",
    "        'diagnostic_tests': {\n",
    "            'ljung_box_stat': lb_test['lb_stat'].iloc[-1],\n",
    "            'ljung_box_pvalue': lb_test['lb_pvalue'].iloc[-1],\n",
    "            'jarque_bera_stat': jb_stat,\n",
    "            'jarque_bera_pvalue': jb_pvalue,\n",
    "            'arch_stat': arch_stat[-1] if isinstance(arch_stat, np.ndarray) else arch_stat,\n",
    "            'arch_pvalue': arch_pvalue[-1] if isinstance(arch_pvalue, np.ndarray) else arch_pvalue\n",
    "        },\n",
    "        'residuals': residuals\n",
    "    }\n",
    "\n",
    "# print(\"âœ“ ARIMA model selection and evaluation functions implemented\")\n",
    "# print(\"âœ“ Modern AIC-based approach replaces subjective Box-Jenkins methodology\")\n",
    "# print(\"âœ“ Ready for cross-validation integration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a22321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Cross-validation integration implemented\n",
      "âœ“ Ready to run complete ARIMA analysis on both assets\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Integration for ARIMA Model Selection\n",
    "# Implement the complete methodology with hyperparameter optimization\n",
    "\n",
    "def run_arima_cross_validation(cv_splits, data_clean, asset_name, max_p=3, max_d=2, max_q=3, \n",
    "                              information_criterion='aic', verbose=True):\n",
    "    \"\"\"\n",
    "    Run ARIMA model selection and evaluation across all cross-validation windows.\n",
    "    \n",
    "    This implements the complete methodology described in the paper:\n",
    "    1. Use in-sample data (train + validation) for model selection via AIC\n",
    "    2. Select optimal hyperparameters via 3-fold validation\n",
    "    3. Generate predictions for out-of-sample test data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cv_splits : list\n",
    "        Cross-validation splits from create_sp500_cv_splits or create_bitcoin_cv_splits\n",
    "    data_clean : pd.DataFrame\n",
    "        Clean data with log returns\n",
    "    asset_name : str\n",
    "        Name of the asset ('S&P 500' or 'Bitcoin')\n",
    "    max_p, max_d, max_q : int\n",
    "        Maximum orders to test for ARIMA(p,d,q)\n",
    "    information_criterion : str\n",
    "        Information criterion for model selection\n",
    "    verbose : bool\n",
    "        Whether to print detailed progress\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Comprehensive results dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== {asset_name.upper()} ARIMA CROSS-VALIDATION ===\")\n",
    "    print(f\"Running AIC-based model selection across {len(cv_splits)} windows...\")\n",
    "    print(f\"Parameter search space: pâˆˆ[0,{max_p}], dâˆˆ[0,{max_d}], qâˆˆ[0,{max_q}]\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_results = []\n",
    "    model_selection_summary = []\n",
    "    \n",
    "    for window_idx, split in enumerate(cv_splits):\n",
    "        window_id = split['window_id']\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸ”„ Processing Window {window_id}/{len(cv_splits)}...\")\n",
    "            print(f\"   Train: {split['train']['start'].strftime('%Y-%m-%d')} to {split['train']['end'].strftime('%Y-%m-%d')} ({split['train']['size']} obs)\")\n",
    "            print(f\"   Test:  {split['test']['start'].strftime('%Y-%m-%d')} to {split['test']['end'].strftime('%Y-%m-%d')} ({split['test']['size']} obs)\")\n",
    "        \n",
    "        # Extract data\n",
    "        train_data = split['train']['data']['Log_Returns']\n",
    "        test_data = split['test']['data']['Log_Returns']\n",
    "        \n",
    "        # STEP 1: Model Selection using Training Data\n",
    "        if verbose:\n",
    "            print(f\"   ðŸ” Model selection using {information_criterion.upper()} criterion...\")\n",
    "        \n",
    "        selection_result = find_optimal_arima_order(\n",
    "            train_data, \n",
    "            max_p=max_p, \n",
    "            max_d=max_d, \n",
    "            max_q=max_q,\n",
    "            information_criterion=information_criterion,\n",
    "            verbose=False  # Keep individual window selection quiet\n",
    "        )\n",
    "        \n",
    "        if selection_result['best_model'] is None:\n",
    "            print(f\"   âŒ Failed to find suitable model for Window {window_id}\")\n",
    "            continue\n",
    "        \n",
    "        best_order = selection_result['best_order']\n",
    "        \n",
    "        # STEP 2: Hyperparameter Validation using Validation Folds\n",
    "        if verbose:\n",
    "            print(f\"   ðŸ“Š Validating ARIMA{best_order} across 3 validation folds...\")\n",
    "        \n",
    "        validation_scores = []\n",
    "        \n",
    "        for val_fold in split['validation']:\n",
    "            fold_num = val_fold['fold']\n",
    "            val_data = val_fold['data']['Log_Returns']\n",
    "            \n",
    "            try:\n",
    "                # Fit model on training data and evaluate on validation fold\n",
    "                val_model = ARIMA(train_data, order=best_order).fit()\n",
    "                val_forecasts = val_model.get_forecast(steps=len(val_data)).predicted_mean\n",
    "                val_rmse = np.sqrt(mean_squared_error(val_data, val_forecasts))\n",
    "                validation_scores.append(val_rmse)\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"     âš ï¸  Validation fold {fold_num} failed: {str(e)[:50]}...\")\n",
    "                validation_scores.append(np.inf)\n",
    "        \n",
    "        avg_validation_rmse = np.mean(validation_scores)\n",
    "        \n",
    "        # STEP 3: Final Model Training and Out-of-Sample Evaluation\n",
    "        if verbose:\n",
    "            print(f\"   ðŸŽ¯ Final evaluation on test data...\")\n",
    "        \n",
    "        try:\n",
    "            # Re-fit the model on training data\n",
    "            final_model = ARIMA(train_data, order=best_order).fit()\n",
    "            \n",
    "            # Evaluate on test data\n",
    "            evaluation = evaluate_arima_model(final_model, train_data, test_data, best_order)\n",
    "            \n",
    "            # Store comprehensive results\n",
    "            window_result = {\n",
    "                'window_id': window_id,\n",
    "                'asset': asset_name,\n",
    "                'train_period': f\"{split['train']['start'].strftime('%Y-%m-%d')} to {split['train']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'test_period': f\"{split['test']['start'].strftime('%Y-%m-%d')} to {split['test']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'train_size': split['train']['size'],\n",
    "                'test_size': split['test']['size'],\n",
    "                'best_order': best_order,\n",
    "                'model_selection': selection_result,\n",
    "                'validation_scores': validation_scores,\n",
    "                'avg_validation_rmse': avg_validation_rmse,\n",
    "                'evaluation': evaluation,\n",
    "                'final_model': final_model\n",
    "            }\n",
    "            \n",
    "            all_results.append(window_result)\n",
    "            \n",
    "            # Summary for quick reference\n",
    "            model_selection_summary.append({\n",
    "                'Window': window_id,\n",
    "                'Best_Order': f\"ARIMA{best_order}\",\n",
    "                'AIC': selection_result['best_ic_value'],\n",
    "                'Validation_RMSE': avg_validation_rmse,\n",
    "                'Test_RMSE': evaluation['performance_metrics']['rmse'],\n",
    "                'Test_MAE': evaluation['performance_metrics']['mae'],\n",
    "                'Test_R2': evaluation['performance_metrics']['r2'],\n",
    "                'Direction_Accuracy': evaluation['performance_metrics']['direction_accuracy'],\n",
    "                'Ljung_Box_p': evaluation['diagnostic_tests']['ljung_box_pvalue']\n",
    "            })\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   âœ… ARIMA{best_order}: Test RMSE={evaluation['performance_metrics']['rmse']:.6f}, \"\n",
    "                      f\"Direction Acc={evaluation['performance_metrics']['direction_accuracy']:.1f}%\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Final evaluation failed for Window {window_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame(model_selection_summary)\n",
    "    \n",
    "    # Calculate overall performance statistics\n",
    "    if len(summary_df) > 0:\n",
    "        performance_summary = {\n",
    "            'total_windows': len(cv_splits),\n",
    "            'successful_windows': len(summary_df),\n",
    "            'success_rate': len(summary_df) / len(cv_splits) * 100,\n",
    "            'avg_test_rmse': summary_df['Test_RMSE'].mean(),\n",
    "            'std_test_rmse': summary_df['Test_RMSE'].std(),\n",
    "            'avg_test_mae': summary_df['Test_MAE'].mean(),\n",
    "            'avg_r2': summary_df['Test_R2'].mean(),\n",
    "            'avg_direction_accuracy': summary_df['Direction_Accuracy'].mean(),\n",
    "            'avg_validation_rmse': summary_df['Validation_RMSE'].mean(),\n",
    "            'most_common_order': summary_df['Best_Order'].mode().iloc[0] if len(summary_df) > 0 else None\n",
    "        }\n",
    "    else:\n",
    "        performance_summary = None\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{asset_name.upper()} ARIMA CROSS-VALIDATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if performance_summary:\n",
    "        print(f\"âœ… Successfully processed {performance_summary['successful_windows']}/{performance_summary['total_windows']} windows\")\n",
    "        print(f\"ðŸ“Š Average Test RMSE: {performance_summary['avg_test_rmse']:.6f} Â± {performance_summary['std_test_rmse']:.6f}\")\n",
    "        print(f\"ðŸŽ¯ Average Direction Accuracy: {performance_summary['avg_direction_accuracy']:.2f}%\")\n",
    "        print(f\"ðŸ”„ Most Common Model: {performance_summary['most_common_order']}\")\n",
    "    else:\n",
    "        print(\"âŒ No successful model fits achieved\")\n",
    "    \n",
    "    return {\n",
    "        'asset_name': asset_name,\n",
    "        'all_results': all_results,\n",
    "        'summary_df': summary_df,\n",
    "        'performance_summary': performance_summary,\n",
    "        'methodology': {\n",
    "            'approach': 'AIC-based automated selection',\n",
    "            'information_criterion': information_criterion,\n",
    "            'parameter_space': f'pâˆˆ[0,{max_p}], dâˆˆ[0,{max_d}], qâˆˆ[0,{max_q}]',\n",
    "            'cross_validation': '3-fold temporal validation',\n",
    "            'evaluation_metric': 'Out-of-sample RMSE and direction accuracy'\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Cross-validation integration implemented\")\n",
    "print(\"âœ“ Ready to run complete ARIMA analysis on both assets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acdb3255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ STARTING COMPREHENSIVE ARIMA ANALYSIS\n",
      "====================================================================================================\n",
      "Implementing modern AIC-based methodology to replace traditional Box-Jenkins approach\n",
      "This analysis demonstrates automated mathematical framework for ARIMA model selection\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ”µ PHASE 1: S&P 500 ANALYSIS\n",
      "\n",
      "=== S&P 500 ARIMA CROSS-VALIDATION ===\n",
      "Running AIC-based model selection across 16 windows...\n",
      "Parameter search space: pâˆˆ[0,3], dâˆˆ[0,1], qâˆˆ[0,3]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/16...\n",
      "   Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "   Test:  2007-01-03 to 2008-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 1): Test RMSE=0.010095, Direction Acc=54.6%\n",
      "\n",
      "ðŸ”„ Processing Window 2/16...\n",
      "   Train: 2003-01-03 to 2006-01-02 (767 obs)\n",
      "   Test:  2008-01-03 to 2009-01-02 (253 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 1): Test RMSE=0.025951, Direction Acc=50.4%\n",
      "\n",
      "ðŸ”„ Processing Window 3/16...\n",
      "   Train: 2004-01-03 to 2007-01-02 (767 obs)\n",
      "   Test:  2009-01-03 to 2010-01-02 (251 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 2): Test RMSE=0.017072, Direction Acc=55.6%\n",
      "\n",
      "ðŸ”„ Processing Window 4/16...\n",
      "   Train: 2005-01-03 to 2008-01-02 (768 obs)\n",
      "   Test:  2010-01-03 to 2011-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 1): Test RMSE=0.011348, Direction Acc=57.0%\n",
      "\n",
      "ðŸ”„ Processing Window 5/16...\n",
      "   Train: 2006-01-03 to 2009-01-02 (768 obs)\n",
      "   Test:  2011-01-03 to 2012-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(2, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(2, 0, 1): Test RMSE=0.014707, Direction Acc=45.4%\n",
      "\n",
      "ðŸ”„ Processing Window 6/16...\n",
      "   Train: 2007-01-03 to 2010-01-02 (767 obs)\n",
      "   Test:  2012-01-03 to 2013-01-02 (251 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(3, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(3, 0, 2): Test RMSE=0.008208, Direction Acc=47.2%\n",
      "\n",
      "ðŸ”„ Processing Window 7/16...\n",
      "   Train: 2008-01-03 to 2011-01-02 (768 obs)\n",
      "   Test:  2013-01-03 to 2014-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(3, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(3, 0, 0): Test RMSE=0.006912, Direction Acc=41.8%\n",
      "\n",
      "ðŸ”„ Processing Window 8/16...\n",
      "   Train: 2009-01-03 to 2012-01-02 (768 obs)\n",
      "   Test:  2014-01-03 to 2015-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.007131, Direction Acc=57.8%\n",
      "\n",
      "ðŸ”„ Processing Window 9/16...\n",
      "   Train: 2010-01-03 to 2013-01-02 (768 obs)\n",
      "   Test:  2015-01-03 to 2016-01-02 (251 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(3, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(3, 0, 2): Test RMSE=0.009788, Direction Acc=47.6%\n",
      "\n",
      "ðŸ”„ Processing Window 10/16...\n",
      "   Train: 2011-01-03 to 2014-01-02 (768 obs)\n",
      "   Test:  2016-01-03 to 2017-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(3, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(3, 0, 2): Test RMSE=0.008242, Direction Acc=51.8%\n",
      "\n",
      "ðŸ”„ Processing Window 11/16...\n",
      "   Train: 2012-01-03 to 2015-01-02 (767 obs)\n",
      "   Test:  2017-01-03 to 2018-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 0): Test RMSE=0.004223, Direction Acc=57.0%\n",
      "\n",
      "ðŸ”„ Processing Window 12/16...\n",
      "   Train: 2013-01-03 to 2016-01-02 (767 obs)\n",
      "   Test:  2018-01-03 to 2019-01-02 (251 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 0): Test RMSE=0.010764, Direction Acc=52.4%\n",
      "\n",
      "ðŸ”„ Processing Window 13/16...\n",
      "   Train: 2014-01-03 to 2017-01-02 (767 obs)\n",
      "   Test:  2019-01-03 to 2020-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.007903, Direction Acc=59.8%\n",
      "\n",
      "ðŸ”„ Processing Window 14/16...\n",
      "   Train: 2015-01-03 to 2018-01-02 (768 obs)\n",
      "   Test:  2020-01-03 to 2021-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(2, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(2, 0, 1): Test RMSE=0.021847, Direction Acc=57.4%\n",
      "\n",
      "ðŸ”„ Processing Window 15/16...\n",
      "   Train: 2016-01-03 to 2019-01-02 (768 obs)\n",
      "   Test:  2021-01-03 to 2022-01-02 (252 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 1): Test RMSE=0.008266, Direction Acc=57.0%\n",
      "\n",
      "ðŸ”„ Processing Window 16/16...\n",
      "   Train: 2017-01-03 to 2020-01-02 (767 obs)\n",
      "   Test:  2022-01-03 to 2023-01-02 (251 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(2, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(2, 0, 2): Test RMSE=0.015272, Direction Acc=43.2%\n",
      "\n",
      "================================================================================\n",
      "S&P 500 ARIMA CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 16/16 windows\n",
      "ðŸ“Š Average Test RMSE: 0.011733 Â± 0.005854\n",
      "ðŸŽ¯ Average Direction Accuracy: 52.24%\n",
      "ðŸ”„ Most Common Model: ARIMA(0, 0, 1)\n",
      "\n",
      "ðŸŸ¡ PHASE 2: BITCOIN ANALYSIS\n",
      "\n",
      "=== BITCOIN ARIMA CROSS-VALIDATION ===\n",
      "Running AIC-based model selection across 11 windows...\n",
      "Parameter search space: pâˆˆ[0,3], dâˆˆ[0,1], qâˆˆ[0,3]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/11...\n",
      "   Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "   Test:  2018-01-01 to 2018-06-30 (181 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(2, 0, 3) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(2, 0, 3): Test RMSE=0.050591, Direction Acc=51.7%\n",
      "\n",
      "ðŸ”„ Processing Window 2/11...\n",
      "   Train: 2015-07-01 to 2017-06-30 (731 obs)\n",
      "   Test:  2018-07-01 to 2018-12-31 (184 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 3) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 3): Test RMSE=0.034623, Direction Acc=50.3%\n",
      "\n",
      "ðŸ”„ Processing Window 3/11...\n",
      "   Train: 2016-01-01 to 2017-12-31 (731 obs)\n",
      "   Test:  2019-01-01 to 2019-06-30 (181 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(0, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(0, 0, 1): Test RMSE=0.035734, Direction Acc=60.0%\n",
      "\n",
      "ðŸ”„ Processing Window 4/11...\n",
      "   Train: 2016-07-01 to 2018-06-30 (730 obs)\n",
      "   Test:  2019-07-01 to 2019-12-31 (184 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 0): Test RMSE=0.034780, Direction Acc=44.8%\n",
      "\n",
      "ðŸ”„ Processing Window 5/11...\n",
      "   Train: 2017-01-01 to 2018-12-31 (730 obs)\n",
      "   Test:  2020-01-01 to 2020-06-30 (182 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 0): Test RMSE=0.049325, Direction Acc=51.4%\n",
      "\n",
      "ðŸ”„ Processing Window 6/11...\n",
      "   Train: 2017-07-01 to 2019-06-30 (730 obs)\n",
      "   Test:  2020-07-01 to 2020-12-31 (184 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 0) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 0): Test RMSE=0.028019, Direction Acc=60.7%\n",
      "\n",
      "ðŸ”„ Processing Window 7/11...\n",
      "   Train: 2018-01-01 to 2019-12-31 (730 obs)\n",
      "   Test:  2021-01-01 to 2021-06-30 (181 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(2, 0, 2) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(2, 0, 2): Test RMSE=0.048958, Direction Acc=50.0%\n",
      "\n",
      "ðŸ”„ Processing Window 8/11...\n",
      "   Train: 2018-07-01 to 2020-06-30 (731 obs)\n",
      "   Test:  2021-07-01 to 2021-12-31 (184 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.033806, Direction Acc=52.5%\n",
      "\n",
      "ðŸ”„ Processing Window 9/11...\n",
      "   Train: 2019-01-01 to 2020-12-31 (731 obs)\n",
      "   Test:  2022-01-01 to 2022-06-30 (181 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.038025, Direction Acc=48.3%\n",
      "\n",
      "ðŸ”„ Processing Window 10/11...\n",
      "   Train: 2019-07-01 to 2021-06-30 (731 obs)\n",
      "   Test:  2022-07-01 to 2022-12-31 (184 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.029490, Direction Acc=44.8%\n",
      "\n",
      "ðŸ”„ Processing Window 11/11...\n",
      "   Train: 2020-01-01 to 2021-12-31 (731 obs)\n",
      "   Test:  2023-01-01 to 2023-06-30 (181 obs)\n",
      "   ðŸ” Model selection using AIC criterion...\n",
      "   ðŸ“Š Validating ARIMA(1, 0, 1) across 3 validation folds...\n",
      "   ðŸŽ¯ Final evaluation on test data...\n",
      "   âœ… ARIMA(1, 0, 1): Test RMSE=0.025187, Direction Acc=50.0%\n",
      "\n",
      "================================================================================\n",
      "BITCOIN ARIMA CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 11/11 windows\n",
      "ðŸ“Š Average Test RMSE: 0.037140 Â± 0.008829\n",
      "ðŸŽ¯ Average Direction Accuracy: 51.31%\n",
      "ðŸ”„ Most Common Model: ARIMA(1, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Execute Complete ARIMA Analysis with AIC-based Model Selection\n",
    "\n",
    "print(\"ðŸš€ STARTING COMPREHENSIVE ARIMA ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(\"Implementing modern AIC-based methodology to replace traditional Box-Jenkins approach\")\n",
    "print(\"This analysis demonstrates automated mathematical framework for ARIMA model selection\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Run ARIMA analysis for S&P 500\n",
    "print(\"\\nðŸ”µ PHASE 1: S&P 500 ANALYSIS\")\n",
    "sp500_arima_results = run_arima_cross_validation(\n",
    "    cv_splits=sp500_cv_splits,\n",
    "    data_clean=sp500_clean,\n",
    "    asset_name='S&P 500',\n",
    "    max_p=3,         # Conservative parameter space for computational efficiency\n",
    "    max_d=1,         # Returns are already stationary (d=1 for potential overdifferencing test)\n",
    "    max_q=3,\n",
    "    information_criterion='aic',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run ARIMA analysis for Bitcoin  \n",
    "print(\"\\nðŸŸ¡ PHASE 2: BITCOIN ANALYSIS\")\n",
    "bitcoin_arima_results = run_arima_cross_validation(\n",
    "    cv_splits=bitcoin_cv_splits,\n",
    "    data_clean=bitcoin_clean,\n",
    "    asset_name='Bitcoin',\n",
    "    max_p=3,\n",
    "    max_d=1,  \n",
    "    max_q=3,\n",
    "    information_criterion='aic',\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bc391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16d11361",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bcf822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LSTM MODEL FOR VOLATILITY FORECASTING ===\n",
      "\n",
      "TensorFlow version: 2.20.0\n",
      "Keras version: 3.12.0\n",
      "\n",
      "âœ“ Libraries imported successfully\n",
      "âœ“ Random seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model Implementation for Volatility Forecasting\n",
    "# Deep learning approach to capture complex temporal patterns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== LSTM MODEL FOR VOLATILITY FORECASTING ===\\n\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"\\nâœ“ Libraries imported successfully\")\n",
    "print(\"âœ“ Random seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ded5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPARATION FUNCTIONS ===\n",
      "\n",
      "âœ“ create_sequences(): Transform time series into LSTM sequences\n",
      "âœ“ calculate_realized_volatility(): Compute rolling volatility measure\n",
      "âœ“ prepare_lstm_data(): Complete data pipeline with scaling\n",
      "\n",
      "ðŸ“Š Ready to prepare data for LSTM training\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation Functions for LSTM\n",
    "# Transform time series data into sequences for LSTM training\n",
    "\n",
    "def create_sequences(data, lookback_window):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Time series data (e.g., log returns or realized volatility)\n",
    "    lookback_window : int\n",
    "        Number of past time steps to use as input features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.array\n",
    "        Input sequences of shape (samples, lookback_window, 1)\n",
    "    y : np.array\n",
    "        Target values of shape (samples,)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(lookback_window, len(data)):\n",
    "        X.append(data[i-lookback_window:i])\n",
    "        y.append(data[i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Reshape X for LSTM input: (samples, timesteps, features)\n",
    "    if len(X.shape) == 2:\n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def calculate_realized_volatility(returns, window=5):\n",
    "    \"\"\"\n",
    "    Calculate realized volatility using rolling window.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.Series\n",
    "        Log returns series\n",
    "    window : int\n",
    "        Rolling window size for volatility calculation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : Realized volatility series\n",
    "    \"\"\"\n",
    "    # Calculate squared returns\n",
    "    squared_returns = returns ** 2\n",
    "    \n",
    "    # Rolling sum of squared returns\n",
    "    realized_vol = np.sqrt(squared_returns.rolling(window=window).sum())\n",
    "    \n",
    "    return realized_vol\n",
    "\n",
    "\n",
    "def prepare_lstm_data(data, lookback_window=20, volatility_window=5, \n",
    "                     forecast_horizon=1, target_type='volatility'):\n",
    "    \"\"\"\n",
    "    Prepare complete dataset for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame with 'Log_Returns' column\n",
    "    lookback_window : int\n",
    "        Number of past observations to use as features\n",
    "    volatility_window : int\n",
    "        Window size for realized volatility calculation\n",
    "    forecast_horizon : int\n",
    "        How many steps ahead to forecast (1 = next day)\n",
    "    target_type : str\n",
    "        'volatility' for volatility forecasting or 'returns' for return forecasting\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing X, y, scaler, and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract log returns\n",
    "    returns = data['Log_Returns'].values\n",
    "    \n",
    "    if target_type == 'volatility':\n",
    "        # Calculate realized volatility\n",
    "        realized_vol = calculate_realized_volatility(data['Log_Returns'], \n",
    "                                                     window=volatility_window)\n",
    "        target_data = realized_vol.values\n",
    "        \n",
    "        # Remove NaN values from volatility calculation\n",
    "        valid_idx = ~np.isnan(target_data)\n",
    "        target_data = target_data[valid_idx]\n",
    "        returns = returns[valid_idx]\n",
    "        \n",
    "    else:  # returns forecasting\n",
    "        target_data = returns\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = create_sequences(returns, lookback_window)\n",
    "    \n",
    "    # Adjust target based on forecast horizon\n",
    "    if forecast_horizon > 1:\n",
    "        X = X[:-forecast_horizon+1]\n",
    "        y = y[forecast_horizon-1:]\n",
    "    \n",
    "    # For volatility forecasting, use future volatility as target\n",
    "    if target_type == 'volatility':\n",
    "        # Align volatility targets with returns sequences\n",
    "        vol_start_idx = lookback_window + volatility_window - 1\n",
    "        y_vol = target_data[vol_start_idx:vol_start_idx+len(y)]\n",
    "        \n",
    "        # Ensure alignment\n",
    "        min_len = min(len(X), len(y_vol))\n",
    "        X = X[:min_len]\n",
    "        y = y_vol[:min_len]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler_X = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "    \n",
    "    # Normalize targets\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return {\n",
    "        'X': X_scaled,\n",
    "        'y': y_scaled,\n",
    "        'X_original': X,\n",
    "        'y_original': y,\n",
    "        'scaler_X': scaler_X,\n",
    "        'scaler_y': scaler_y,\n",
    "        'lookback_window': lookback_window,\n",
    "        'volatility_window': volatility_window,\n",
    "        'target_type': target_type,\n",
    "        'n_samples': len(X_scaled)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== DATA PREPARATION FUNCTIONS ===\\n\")\n",
    "print(\"âœ“ create_sequences(): Transform time series into LSTM sequences\")\n",
    "print(\"âœ“ calculate_realized_volatility(): Compute rolling volatility measure\")\n",
    "print(\"âœ“ prepare_lstm_data(): Complete data pipeline with scaling\")\n",
    "print(\"\\nðŸ“Š Ready to prepare data for LSTM training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f54686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LSTM MODEL ARCHITECTURE ===\n",
      "\n",
      "âœ“ build_lstm_model(): Multi-layer LSTM with dropout regularization\n",
      "âœ“ get_callbacks(): Early stopping and learning rate scheduling\n",
      "âœ“ train_lstm_model(): Training pipeline with validation\n",
      "\n",
      "ðŸ§  Neural network architecture ready for training\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model Architecture\n",
    "# Build and configure neural network for time series forecasting\n",
    "\n",
    "def build_lstm_model(lookback_window, lstm_units=[64, 32], dropout_rate=0.2, \n",
    "                     learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build LSTM neural network architecture for volatility forecasting.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lookback_window : int\n",
    "        Number of time steps in input sequence\n",
    "    lstm_units : list\n",
    "        List of units for each LSTM layer\n",
    "    dropout_rate : float\n",
    "        Dropout rate for regularization (0.0 to 1.0)\n",
    "    learning_rate : float\n",
    "        Learning rate for Adam optimizer\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Compiled LSTM model ready for training\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential(name='LSTM_Volatility_Forecasting')\n",
    "    \n",
    "    # First LSTM layer (returns sequences for next layer)\n",
    "    model.add(LSTM(\n",
    "        units=lstm_units[0],\n",
    "        return_sequences=True,\n",
    "        input_shape=(lookback_window, 1),\n",
    "        name='LSTM_Layer_1'\n",
    "    ))\n",
    "    model.add(Dropout(dropout_rate, name='Dropout_1'))\n",
    "    \n",
    "    # Additional LSTM layers if specified\n",
    "    for i, units in enumerate(lstm_units[1:], start=2):\n",
    "        return_seq = i < len(lstm_units)  # Last LSTM layer doesn't return sequences\n",
    "        model.add(LSTM(\n",
    "            units=units,\n",
    "            return_sequences=return_seq,\n",
    "            name=f'LSTM_Layer_{i}'\n",
    "        ))\n",
    "        model.add(Dropout(dropout_rate, name=f'Dropout_{i}'))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, name='Output_Layer'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_callbacks(patience=15, min_delta=1e-6):\n",
    "    \"\"\"\n",
    "    Create callbacks for training optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    patience : int\n",
    "        Number of epochs with no improvement after which training will be stopped\n",
    "    min_delta : float\n",
    "        Minimum change to qualify as an improvement\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list : List of Keras callbacks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        verbose=0,\n",
    "        min_delta=min_delta\n",
    "    )\n",
    "    \n",
    "    # Reduce learning rate when plateau is reached\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return [early_stop, reduce_lr]\n",
    "\n",
    "\n",
    "def train_lstm_model(model, X_train, y_train, X_val, y_val, \n",
    "                     epochs=100, batch_size=32, verbose=0):\n",
    "    \"\"\"\n",
    "    Train LSTM model with validation monitoring.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras.Model\n",
    "        Compiled LSTM model\n",
    "    X_train, y_train : np.array\n",
    "        Training data\n",
    "    X_val, y_val : np.array\n",
    "        Validation data\n",
    "    epochs : int\n",
    "        Maximum number of training epochs\n",
    "    batch_size : int\n",
    "        Training batch size\n",
    "    verbose : int\n",
    "        Training verbosity (0=silent, 1=progress bar, 2=one line per epoch)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    history : keras.History\n",
    "        Training history object\n",
    "    \"\"\"\n",
    "    \n",
    "    callbacks = get_callbacks()\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "        shuffle=False  # Important for time series data\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"=== LSTM MODEL ARCHITECTURE ===\\n\")\n",
    "print(\"âœ“ build_lstm_model(): Multi-layer LSTM with dropout regularization\")\n",
    "print(\"âœ“ get_callbacks(): Early stopping and learning rate scheduling\")\n",
    "print(\"âœ“ train_lstm_model(): Training pipeline with validation\")\n",
    "print(\"\\nðŸ§  Neural network architecture ready for training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7e23370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EVALUATION FUNCTIONS ===\n",
      "\n",
      "âœ“ evaluate_lstm_predictions(): Comprehensive performance assessment\n",
      "âœ“ Metrics: RMSE, MAE, MAPE, RÂ², Direction Accuracy\n",
      "\n",
      "ðŸ“ˆ Ready to evaluate model predictions\n"
     ]
    }
   ],
   "source": [
    "# Evaluation and Prediction Functions\n",
    "# Assess LSTM model performance on test data\n",
    "\n",
    "def evaluate_lstm_predictions(model, X_test, y_test, scaler_y):\n",
    "    \"\"\"\n",
    "    Generate predictions and calculate performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras.Model\n",
    "        Trained LSTM model\n",
    "    X_test : np.array\n",
    "        Test input sequences\n",
    "    y_test : np.array\n",
    "        True test values (scaled)\n",
    "    scaler_y : StandardScaler\n",
    "        Scaler used for target variable\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing predictions and metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_scaled = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "    y_true = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    \n",
    "    # R-squared\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    # Direction accuracy (for volatility changes)\n",
    "    if len(y_true) > 1:\n",
    "        direction_true = np.sign(np.diff(y_true))\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_accuracy = np.mean(direction_true == direction_pred) * 100\n",
    "    else:\n",
    "        direction_accuracy = 0\n",
    "    \n",
    "    return {\n",
    "        'predictions': y_pred,\n",
    "        'true_values': y_true,\n",
    "        'predictions_scaled': y_pred_scaled,\n",
    "        'true_values_scaled': y_test,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'direction_accuracy': direction_accuracy\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== EVALUATION FUNCTIONS ===\\n\")\n",
    "print(\"âœ“ evaluate_lstm_predictions(): Comprehensive performance assessment\")\n",
    "print(\"âœ“ Metrics: RMSE, MAE, MAPE, RÂ², Direction Accuracy\")\n",
    "print(\"\\nðŸ“ˆ Ready to evaluate model predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e301539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CROSS-VALIDATION INTEGRATION ===\n",
      "\n",
      "âœ“ run_lstm_cross_validation(): Complete LSTM pipeline\n",
      "âœ“ Integrates with existing CV splits\n",
      "âœ“ Automated training, validation, and testing\n",
      "\n",
      "ðŸš€ Ready to run LSTM analysis on both assets\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Integration for LSTM\n",
    "# Run LSTM training and evaluation across all CV windows\n",
    "\n",
    "def run_lstm_cross_validation(cv_splits, data_clean, asset_name,\n",
    "                              lookback_window=20, volatility_window=5,\n",
    "                              lstm_units=[64, 32], dropout_rate=0.2,\n",
    "                              learning_rate=0.001, epochs=100, batch_size=32,\n",
    "                              verbose=True):\n",
    "    \"\"\"\n",
    "    Run LSTM volatility forecasting across all cross-validation windows.\n",
    "    \n",
    "    This function implements the complete deep learning methodology:\n",
    "    1. Prepare data for each window (train, validation, test)\n",
    "    2. Hyperparameter selection using validation folds\n",
    "    3. Train LSTM model on training data\n",
    "    4. Evaluate on out-of-sample test data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cv_splits : list\n",
    "        Cross-validation splits\n",
    "    data_clean : pd.DataFrame\n",
    "        Clean data with log returns\n",
    "    asset_name : str\n",
    "        Name of the asset ('S&P 500' or 'Bitcoin')\n",
    "    lookback_window : int\n",
    "        Number of past time steps for LSTM input\n",
    "    volatility_window : int\n",
    "        Window for realized volatility calculation\n",
    "    lstm_units : list\n",
    "        LSTM layer sizes\n",
    "    dropout_rate : float\n",
    "        Dropout for regularization\n",
    "    learning_rate : float\n",
    "        Learning rate for optimizer\n",
    "    epochs : int\n",
    "        Maximum training epochs\n",
    "    batch_size : int\n",
    "        Training batch size\n",
    "    verbose : bool\n",
    "        Print progress information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Comprehensive results dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{asset_name.upper()} LSTM CROSS-VALIDATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Running LSTM across {len(cv_splits)} windows...\")\n",
    "    print(f\"Architecture: {len(lstm_units)}-layer LSTM with {lstm_units} units\")\n",
    "    print(f\"Lookback window: {lookback_window} days\")\n",
    "    print(f\"Volatility window: {volatility_window} days\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_results = []\n",
    "    model_summary = []\n",
    "    \n",
    "    for window_idx, split in enumerate(cv_splits):\n",
    "        window_id = split['window_id']\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸ”„ Processing Window {window_id}/{len(cv_splits)}...\")\n",
    "            print(f\"   Train: {split['train']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{split['train']['end'].strftime('%Y-%m-%d')} ({split['train']['size']} obs)\")\n",
    "            print(f\"   Test:  {split['test']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{split['test']['end'].strftime('%Y-%m-%d')} ({split['test']['size']} obs)\")\n",
    "        \n",
    "        try:\n",
    "            # STEP 1: Prepare training data\n",
    "            if verbose:\n",
    "                print(f\"   ðŸ“Š Preparing data with lookback={lookback_window}...\")\n",
    "            \n",
    "            train_prepared = prepare_lstm_data(\n",
    "                split['train']['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # STEP 2: Prepare validation data (use fold 3 - longest validation period)\n",
    "            val_fold = split['validation'][2]  # Use 24-month validation for S&P, 12-month for Bitcoin\n",
    "            val_prepared = prepare_lstm_data(\n",
    "                val_fold['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # Use training scaler for validation data\n",
    "            X_val_scaled = train_prepared['scaler_X'].transform(\n",
    "                val_prepared['X_original'].reshape(-1, 1)\n",
    "            ).reshape(val_prepared['X_original'].shape)\n",
    "            y_val_scaled = train_prepared['scaler_y'].transform(\n",
    "                val_prepared['y_original'].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            \n",
    "            # STEP 3: Prepare test data\n",
    "            test_prepared = prepare_lstm_data(\n",
    "                split['test']['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # Use training scaler for test data\n",
    "            X_test_scaled = train_prepared['scaler_X'].transform(\n",
    "                test_prepared['X_original'].reshape(-1, 1)\n",
    "            ).reshape(test_prepared['X_original'].shape)\n",
    "            y_test_scaled = train_prepared['scaler_y'].transform(\n",
    "                test_prepared['y_original'].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   ðŸ§  Building LSTM model...\")\n",
    "            \n",
    "            # STEP 4: Build and train LSTM model\n",
    "            model = build_lstm_model(\n",
    "                lookback_window=lookback_window,\n",
    "                lstm_units=lstm_units,\n",
    "                dropout_rate=dropout_rate,\n",
    "                learning_rate=learning_rate\n",
    "            )\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   ðŸ‹ï¸  Training model (max {epochs} epochs)...\")\n",
    "            \n",
    "            history = train_lstm_model(\n",
    "                model,\n",
    "                train_prepared['X'], train_prepared['y'],\n",
    "                X_val_scaled, y_val_scaled,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # STEP 5: Evaluate on test data\n",
    "            if verbose:\n",
    "                print(f\"   ðŸ“ˆ Evaluating on test data...\")\n",
    "            \n",
    "            evaluation = evaluate_lstm_predictions(\n",
    "                model,\n",
    "                X_test_scaled,\n",
    "                y_test_scaled,\n",
    "                train_prepared['scaler_y']\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            window_result = {\n",
    "                'window_id': window_id,\n",
    "                'asset': asset_name,\n",
    "                'train_period': f\"{split['train']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                               f\"{split['train']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'test_period': f\"{split['test']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                              f\"{split['test']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'train_size': train_prepared['n_samples'],\n",
    "                'val_size': len(X_val_scaled),\n",
    "                'test_size': len(X_test_scaled),\n",
    "                'hyperparameters': {\n",
    "                    'lookback_window': lookback_window,\n",
    "                    'volatility_window': volatility_window,\n",
    "                    'lstm_units': lstm_units,\n",
    "                    'dropout_rate': dropout_rate,\n",
    "                    'learning_rate': learning_rate\n",
    "                },\n",
    "                'training': {\n",
    "                    'epochs_trained': len(history.history['loss']),\n",
    "                    'final_train_loss': history.history['loss'][-1],\n",
    "                    'final_val_loss': history.history['val_loss'][-1],\n",
    "                    'history': history.history\n",
    "                },\n",
    "                'evaluation': evaluation,\n",
    "                'model': model\n",
    "            }\n",
    "            \n",
    "            all_results.append(window_result)\n",
    "            \n",
    "            # Summary for quick reference\n",
    "            model_summary.append({\n",
    "                'Window': window_id,\n",
    "                'Train_Samples': train_prepared['n_samples'],\n",
    "                'Test_Samples': len(X_test_scaled),\n",
    "                'Epochs': len(history.history['loss']),\n",
    "                'Train_Loss': history.history['loss'][-1],\n",
    "                'Val_Loss': history.history['val_loss'][-1],\n",
    "                'Test_RMSE': evaluation['metrics']['rmse'],\n",
    "                'Test_MAE': evaluation['metrics']['mae'],\n",
    "                'Test_R2': evaluation['metrics']['r2'],\n",
    "                'Direction_Accuracy': evaluation['metrics']['direction_accuracy']\n",
    "            })\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   âœ… Test RMSE={evaluation['metrics']['rmse']:.6f}, \"\n",
    "                      f\"RÂ²={evaluation['metrics']['r2']:.4f}, \"\n",
    "                      f\"Direction Acc={evaluation['metrics']['direction_accuracy']:.1f}%\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Window {window_id} failed: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame(model_summary)\n",
    "    \n",
    "    # Calculate overall performance statistics\n",
    "    if len(summary_df) > 0:\n",
    "        performance_summary = {\n",
    "            'total_windows': len(cv_splits),\n",
    "            'successful_windows': len(summary_df),\n",
    "            'success_rate': len(summary_df) / len(cv_splits) * 100,\n",
    "            'avg_test_rmse': summary_df['Test_RMSE'].mean(),\n",
    "            'std_test_rmse': summary_df['Test_RMSE'].std(),\n",
    "            'avg_test_mae': summary_df['Test_MAE'].mean(),\n",
    "            'avg_r2': summary_df['Test_R2'].mean(),\n",
    "            'avg_direction_accuracy': summary_df['Direction_Accuracy'].mean(),\n",
    "            'avg_epochs': summary_df['Epochs'].mean()\n",
    "        }\n",
    "    else:\n",
    "        performance_summary = None\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{asset_name.upper()} LSTM CROSS-VALIDATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if performance_summary:\n",
    "        print(f\"âœ… Successfully processed {performance_summary['successful_windows']}/\"\n",
    "              f\"{performance_summary['total_windows']} windows\")\n",
    "        print(f\"ðŸ“Š Average Test RMSE: {performance_summary['avg_test_rmse']:.6f} Â± \"\n",
    "              f\"{performance_summary['std_test_rmse']:.6f}\")\n",
    "        print(f\"ðŸ“Š Average RÂ²: {performance_summary['avg_r2']:.4f}\")\n",
    "        print(f\"ðŸŽ¯ Average Direction Accuracy: {performance_summary['avg_direction_accuracy']:.2f}%\")\n",
    "        print(f\"â±ï¸  Average Epochs: {performance_summary['avg_epochs']:.1f}\")\n",
    "    else:\n",
    "        print(\"âŒ No successful model fits achieved\")\n",
    "    \n",
    "    return {\n",
    "        'asset_name': asset_name,\n",
    "        'all_results': all_results,\n",
    "        'summary_df': summary_df,\n",
    "        'performance_summary': performance_summary,\n",
    "        'methodology': {\n",
    "            'model_type': 'LSTM Neural Network',\n",
    "            'architecture': f'{len(lstm_units)}-layer LSTM',\n",
    "            'lookback_window': lookback_window,\n",
    "            'volatility_window': volatility_window,\n",
    "            'target': 'Realized Volatility',\n",
    "            'validation': '3-fold temporal validation'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== CROSS-VALIDATION INTEGRATION ===\\n\")\n",
    "print(\"âœ“ run_lstm_cross_validation(): Complete LSTM pipeline\")\n",
    "print(\"âœ“ Integrates with existing CV splits\")\n",
    "print(\"âœ“ Automated training, validation, and testing\")\n",
    "print(\"\\nðŸš€ Ready to run LSTM analysis on both assets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c3422",
   "metadata": {},
   "source": [
    "# LSTM: Test 3 windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f4628e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ STARTING LSTM VOLATILITY FORECASTING ANALYSIS\n",
      "====================================================================================================\n",
      "Implementing LSTM neural network for realized volatility prediction\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“‹ LSTM Configuration:\n",
      "   lookback_window: 20\n",
      "   volatility_window: 5\n",
      "   lstm_units: [64, 32]\n",
      "   dropout_rate: 0.2\n",
      "   learning_rate: 0.001\n",
      "   epochs: 100\n",
      "   batch_size: 32\n",
      "\n",
      "ðŸ”µ PHASE 1: S&P 500 ANALYSIS (First 3 Windows)\n",
      "\n",
      "================================================================================\n",
      "S&P 500 LSTM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running LSTM across 3 windows...\n",
      "Architecture: 2-layer LSTM with [64, 32] units\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/3...\n",
      "   Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "   Test:  2007-01-03 to 2008-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009414, RÂ²=0.0888, Direction Acc=47.5%\n",
      "\n",
      "ðŸ”„ Processing Window 2/3...\n",
      "   Train: 2003-01-03 to 2006-01-02 (767 obs)\n",
      "   Test:  2008-01-03 to 2009-01-02 (253 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.035664, RÂ²=-0.0226, Direction Acc=44.2%\n",
      "\n",
      "ðŸ”„ Processing Window 3/3...\n",
      "   Train: 2004-01-03 to 2007-01-02 (767 obs)\n",
      "   Test:  2009-01-03 to 2010-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.020071, RÂ²=-0.4404, Direction Acc=53.6%\n",
      "\n",
      "================================================================================\n",
      "S&P 500 LSTM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 3/3 windows\n",
      "ðŸ“Š Average Test RMSE: 0.021716 Â± 0.013202\n",
      "ðŸ“Š Average RÂ²: -0.1247\n",
      "ðŸŽ¯ Average Direction Accuracy: 48.44%\n",
      "â±ï¸  Average Epochs: 32.0\n"
     ]
    }
   ],
   "source": [
    "# Execute LSTM Analysis on S&P 500\n",
    "# Run complete analysis on first few windows to demonstrate methodology\n",
    "\n",
    "print(\"ðŸš€ STARTING LSTM VOLATILITY FORECASTING ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(\"Implementing LSTM neural network for realized volatility prediction\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Configuration for LSTM\n",
    "LSTM_CONFIG = {\n",
    "    'lookback_window': 20,      # Use 20 days of past returns\n",
    "    'volatility_window': 5,     # Calculate 5-day realized volatility\n",
    "    'lstm_units': [64, 32],     # 2-layer LSTM with 64 and 32 units\n",
    "    'dropout_rate': 0.2,        # 20% dropout for regularization\n",
    "    'learning_rate': 0.001,     # Adam optimizer learning rate\n",
    "    'epochs': 100,              # Maximum epochs (early stopping will apply)\n",
    "    'batch_size': 32            # Training batch size\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“‹ LSTM Configuration:\")\n",
    "for key, value in LSTM_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Run S&P 500 analysis (first 3 windows for demonstration)\n",
    "print(\"\\nðŸ”µ PHASE 1: S&P 500 ANALYSIS (First 3 Windows)\")\n",
    "sp500_lstm_results = run_lstm_cross_validation(\n",
    "    cv_splits=sp500_cv_splits[:3],  # Limit to first 3 windows for demonstration\n",
    "    data_clean=sp500_clean,\n",
    "    asset_name='S&P 500',\n",
    "    **LSTM_CONFIG,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00053e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¡ PHASE 2: BITCOIN ANALYSIS (First 3 Windows)\n",
      "\n",
      "================================================================================\n",
      "BITCOIN LSTM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running LSTM across 3 windows...\n",
      "Architecture: 2-layer LSTM with [64, 32] units\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/3...\n",
      "   Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "   Test:  2018-01-01 to 2018-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002596B0AB420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "   âœ… Test RMSE=0.050445, RÂ²=-0.3224, Direction Acc=40.1%\n",
      "\n",
      "ðŸ”„ Processing Window 2/3...\n",
      "   Train: 2015-07-01 to 2017-06-30 (731 obs)\n",
      "   Test:  2018-07-01 to 2018-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002596EB7F600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "   âœ… Test RMSE=0.036063, RÂ²=0.3059, Direction Acc=43.9%\n",
      "\n",
      "ðŸ”„ Processing Window 3/3...\n",
      "   Train: 2016-01-01 to 2017-12-31 (731 obs)\n",
      "   Test:  2019-01-01 to 2019-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.049177, RÂ²=-0.0515, Direction Acc=47.4%\n",
      "\n",
      "================================================================================\n",
      "BITCOIN LSTM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 3/3 windows\n",
      "ðŸ“Š Average Test RMSE: 0.045228 Â± 0.007963\n",
      "ðŸ“Š Average RÂ²: -0.0226\n",
      "ðŸŽ¯ Average Direction Accuracy: 43.79%\n",
      "â±ï¸  Average Epochs: 36.3\n"
     ]
    }
   ],
   "source": [
    "# Execute LSTM Analysis on Bitcoin\n",
    "# Run analysis on Bitcoin data\n",
    "\n",
    "print(\"\\nðŸŸ¡ PHASE 2: BITCOIN ANALYSIS (First 3 Windows)\")\n",
    "bitcoin_lstm_results = run_lstm_cross_validation(\n",
    "    cv_splits=bitcoin_cv_splits[:3],  # Limit to first 3 windows for demonstration\n",
    "    data_clean=bitcoin_clean,\n",
    "    asset_name='Bitcoin',\n",
    "    **LSTM_CONFIG,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc3639",
   "metadata": {},
   "source": [
    "# LSTM: End test 3 windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c6c1d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FULL S&P 500 Analysis (all windows)...\n",
      "\n",
      "================================================================================\n",
      "S&P 500 LSTM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running LSTM across 16 windows...\n",
      "Architecture: 2-layer LSTM with [64, 32] units\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/16...\n",
      "   Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "   Test:  2007-01-03 to 2008-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.010066, RÂ²=-0.0416, Direction Acc=51.1%\n",
      "\n",
      "ðŸ”„ Processing Window 2/16...\n",
      "   Train: 2003-01-03 to 2006-01-02 (767 obs)\n",
      "   Test:  2008-01-03 to 2009-01-02 (253 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.036860, RÂ²=-0.0924, Direction Acc=42.9%\n",
      "\n",
      "ðŸ”„ Processing Window 3/16...\n",
      "   Train: 2004-01-03 to 2007-01-02 (767 obs)\n",
      "   Test:  2009-01-03 to 2010-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.020142, RÂ²=-0.4506, Direction Acc=50.9%\n",
      "\n",
      "ðŸ”„ Processing Window 4/16...\n",
      "   Train: 2005-01-03 to 2008-01-02 (768 obs)\n",
      "   Test:  2010-01-03 to 2011-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009506, RÂ²=0.3754, Direction Acc=53.4%\n",
      "\n",
      "ðŸ”„ Processing Window 5/16...\n",
      "   Train: 2006-01-03 to 2009-01-02 (768 obs)\n",
      "   Test:  2011-01-03 to 2012-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.016327, RÂ²=0.1219, Direction Acc=45.3%\n",
      "\n",
      "ðŸ”„ Processing Window 6/16...\n",
      "   Train: 2007-01-03 to 2010-01-02 (767 obs)\n",
      "   Test:  2012-01-03 to 2013-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.008401, RÂ²=-0.4973, Direction Acc=45.9%\n",
      "\n",
      "ðŸ”„ Processing Window 7/16...\n",
      "   Train: 2008-01-03 to 2011-01-02 (768 obs)\n",
      "   Test:  2013-01-03 to 2014-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007761, RÂ²=-0.5672, Direction Acc=49.3%\n",
      "\n",
      "ðŸ”„ Processing Window 8/16...\n",
      "   Train: 2009-01-03 to 2012-01-02 (768 obs)\n",
      "   Test:  2014-01-03 to 2015-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007510, RÂ²=-0.1014, Direction Acc=48.4%\n",
      "\n",
      "ðŸ”„ Processing Window 9/16...\n",
      "   Train: 2010-01-03 to 2013-01-02 (768 obs)\n",
      "   Test:  2015-01-03 to 2016-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009950, RÂ²=0.1318, Direction Acc=54.5%\n",
      "\n",
      "ðŸ”„ Processing Window 10/16...\n",
      "   Train: 2011-01-03 to 2014-01-02 (768 obs)\n",
      "   Test:  2016-01-03 to 2017-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007817, RÂ²=0.1160, Direction Acc=53.4%\n",
      "\n",
      "ðŸ”„ Processing Window 11/16...\n",
      "   Train: 2012-01-03 to 2015-01-02 (767 obs)\n",
      "   Test:  2017-01-03 to 2018-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007112, RÂ²=-1.7795, Direction Acc=59.6%\n",
      "\n",
      "ðŸ”„ Processing Window 12/16...\n",
      "   Train: 2013-01-03 to 2016-01-02 (767 obs)\n",
      "   Test:  2018-01-03 to 2019-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009405, RÂ²=0.4200, Direction Acc=47.3%\n",
      "\n",
      "ðŸ”„ Processing Window 13/16...\n",
      "   Train: 2014-01-03 to 2017-01-02 (767 obs)\n",
      "   Test:  2019-01-03 to 2020-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006242, RÂ²=0.3948, Direction Acc=61.9%\n",
      "\n",
      "ðŸ”„ Processing Window 14/16...\n",
      "   Train: 2015-01-03 to 2018-01-02 (768 obs)\n",
      "   Test:  2020-01-03 to 2021-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.034652, RÂ²=0.0238, Direction Acc=48.9%\n",
      "\n",
      "ðŸ”„ Processing Window 15/16...\n",
      "   Train: 2016-01-03 to 2019-01-02 (768 obs)\n",
      "   Test:  2021-01-03 to 2022-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007407, RÂ²=0.1301, Direction Acc=51.6%\n",
      "\n",
      "ðŸ”„ Processing Window 16/16...\n",
      "   Train: 2017-01-03 to 2020-01-02 (767 obs)\n",
      "   Test:  2022-01-03 to 2023-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.012528, RÂ²=-0.2798, Direction Acc=47.7%\n",
      "\n",
      "================================================================================\n",
      "S&P 500 LSTM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 16/16 windows\n",
      "ðŸ“Š Average Test RMSE: 0.013230 Â± 0.009521\n",
      "ðŸ“Š Average RÂ²: -0.1310\n",
      "ðŸŽ¯ Average Direction Accuracy: 50.76%\n",
      "â±ï¸  Average Epochs: 32.3\n",
      "\\nRunning FULL Bitcoin Analysis (all windows)...\n",
      "\n",
      "================================================================================\n",
      "BITCOIN LSTM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running LSTM across 11 windows...\n",
      "Architecture: 2-layer LSTM with [64, 32] units\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/11...\n",
      "   Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "   Test:  2018-01-01 to 2018-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.050105, RÂ²=-0.3046, Direction Acc=42.8%\n",
      "\n",
      "ðŸ”„ Processing Window 2/11...\n",
      "   Train: 2015-07-01 to 2017-06-30 (731 obs)\n",
      "   Test:  2018-07-01 to 2018-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.035822, RÂ²=0.3152, Direction Acc=47.1%\n",
      "\n",
      "ðŸ”„ Processing Window 3/11...\n",
      "   Train: 2016-01-01 to 2017-12-31 (731 obs)\n",
      "   Test:  2019-01-01 to 2019-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.048998, RÂ²=-0.0439, Direction Acc=46.7%\n",
      "\n",
      "ðŸ”„ Processing Window 4/11...\n",
      "   Train: 2016-07-01 to 2018-06-30 (730 obs)\n",
      "   Test:  2019-07-01 to 2019-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.042613, RÂ²=-0.5963, Direction Acc=44.5%\n",
      "\n",
      "ðŸ”„ Processing Window 5/11...\n",
      "   Train: 2017-01-01 to 2018-12-31 (730 obs)\n",
      "   Test:  2020-01-01 to 2020-06-30 (182 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.079213, RÂ²=0.0466, Direction Acc=45.8%\n",
      "\n",
      "ðŸ”„ Processing Window 6/11...\n",
      "   Train: 2017-07-01 to 2019-06-30 (730 obs)\n",
      "   Test:  2020-07-01 to 2020-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.030326, RÂ²=-0.0539, Direction Acc=49.7%\n",
      "\n",
      "ðŸ”„ Processing Window 7/11...\n",
      "   Train: 2018-01-01 to 2019-12-31 (730 obs)\n",
      "   Test:  2021-01-01 to 2021-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.042380, RÂ²=-0.2214, Direction Acc=53.9%\n",
      "\n",
      "ðŸ”„ Processing Window 8/11...\n",
      "   Train: 2018-07-01 to 2020-06-30 (731 obs)\n",
      "   Test:  2021-07-01 to 2021-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.028100, RÂ²=-0.5741, Direction Acc=45.2%\n",
      "\n",
      "ðŸ”„ Processing Window 9/11...\n",
      "   Train: 2019-01-01 to 2020-12-31 (731 obs)\n",
      "   Test:  2022-01-01 to 2022-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.039997, RÂ²=-0.0685, Direction Acc=46.1%\n",
      "\n",
      "ðŸ”„ Processing Window 10/11...\n",
      "   Train: 2019-07-01 to 2021-06-30 (731 obs)\n",
      "   Test:  2022-07-01 to 2022-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.045564, RÂ²=-0.3477, Direction Acc=46.5%\n",
      "\n",
      "ðŸ”„ Processing Window 11/11...\n",
      "   Train: 2020-01-01 to 2021-12-31 (731 obs)\n",
      "   Test:  2023-01-01 to 2023-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ§  Building LSTM model...\n",
      "   ðŸ‹ï¸  Training model (max 100 epochs)...\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.036604, RÂ²=-1.1054, Direction Acc=55.3%\n",
      "\n",
      "================================================================================\n",
      "BITCOIN LSTM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 11/11 windows\n",
      "ðŸ“Š Average Test RMSE: 0.043611 Â± 0.013729\n",
      "ðŸ“Š Average RÂ²: -0.2685\n",
      "ðŸŽ¯ Average Direction Accuracy: 47.58%\n",
      "â±ï¸  Average Epochs: 32.6\n"
     ]
    }
   ],
   "source": [
    "# Optional: Run Full Analysis on All Windows\n",
    "# Uncomment and run this cell to process all CV windows (will take longer)\n",
    "\n",
    "\n",
    "# Full S&P 500 Analysis (all 16 windows)\n",
    "print(\"Running FULL S&P 500 Analysis (all windows)...\")\n",
    "sp500_lstm_full = run_lstm_cross_validation(\n",
    "    cv_splits=sp500_cv_splits,  # All windows\n",
    "    data_clean=sp500_clean,\n",
    "    asset_name='S&P 500',\n",
    "    **LSTM_CONFIG,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Full Bitcoin Analysis (all 11 windows)\n",
    "print(\"\\\\nRunning FULL Bitcoin Analysis (all windows)...\")\n",
    "bitcoin_lstm_full = run_lstm_cross_validation(\n",
    "    cv_splits=bitcoin_cv_splits,  # All windows\n",
    "    data_clean=bitcoin_clean,\n",
    "    asset_name='Bitcoin',\n",
    "    **LSTM_CONFIG,\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb817c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e110ccff",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc4620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM MODEL FOR VOLATILITY FORECASTING ===\n",
      "\n",
      "Support Vector Regression (SVR) with RBF Kernel\n",
      "Captures non-linear patterns in volatility dynamics\n",
      "\n",
      "âœ“ Libraries imported successfully\n",
      "âœ“ Random seed set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# SVM Model Implementation for Volatility Forecasting\n",
    "# Support Vector Machines with RBF kernel for non-linear pattern recognition\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== SVM MODEL FOR VOLATILITY FORECASTING ===\\n\")\n",
    "print(\"Support Vector Regression (SVR) with RBF Kernel\")\n",
    "print(\"Captures non-linear patterns in volatility dynamics\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\nâœ“ Libraries imported successfully\")\n",
    "print(\"âœ“ Random seed set for reproducibility\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b7d1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPARATION FUNCTIONS ===\n",
      "\n",
      "âœ“ create_svm_features(): Transform time series into feature vectors\n",
      "âœ“ calculate_technical_features(): Compute additional technical indicators\n",
      "âœ“ prepare_svm_data(): Complete data pipeline with scaling\n",
      "\n",
      "ðŸ“Š Ready to prepare data for SVM training\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation Functions for SVM\n",
    "# Transform time series data into feature vectors\n",
    "\n",
    "def create_svm_features(data, lookback_window=20):\n",
    "    \"\"\"\n",
    "    Create feature vectors for SVM training.\n",
    "    \n",
    "    Unlike LSTM which uses 3D sequences, SVM uses 2D feature matrices.\n",
    "    Each sample is a flattened vector of past observations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Time series data (e.g., log returns)\n",
    "    lookback_window : int\n",
    "        Number of past time steps to use as features\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : np.array\n",
    "        Feature matrix of shape (samples, lookback_window)\n",
    "    y : np.array\n",
    "        Target values of shape (samples,)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(lookback_window, len(data)):\n",
    "        X.append(data[i-lookback_window:i])\n",
    "        y.append(data[i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def calculate_technical_features(returns, window=5):\n",
    "    \"\"\"\n",
    "    Calculate additional technical features for SVM.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.Series\n",
    "        Log returns series\n",
    "    window : int\n",
    "        Window size for feature calculation\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with technical features\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    # Realized volatility (5-day)\n",
    "    features['realized_vol'] = np.sqrt((returns ** 2).rolling(window=window).sum())\n",
    "    \n",
    "    # Moving average of returns\n",
    "    features['ma_returns'] = returns.rolling(window=window).mean()\n",
    "    \n",
    "    # Rolling standard deviation\n",
    "    features['rolling_std'] = returns.rolling(window=window).std()\n",
    "    \n",
    "    # Exponential moving average\n",
    "    features['ema_returns'] = returns.ewm(span=window).mean()\n",
    "    \n",
    "    # Squared returns (proxy for volatility)\n",
    "    features['squared_returns'] = returns ** 2\n",
    "    \n",
    "    # Return momentum\n",
    "    features['momentum'] = returns.rolling(window=window).sum()\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def prepare_svm_data(data, lookback_window=20, volatility_window=5, \n",
    "                    use_technical_features=False, target_type='volatility'):\n",
    "    \"\"\"\n",
    "    Prepare complete dataset for SVM training.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame with 'Log_Returns' column\n",
    "    lookback_window : int\n",
    "        Number of past observations to use as features\n",
    "    volatility_window : int\n",
    "        Window size for realized volatility calculation\n",
    "    use_technical_features : bool\n",
    "        Whether to add technical features\n",
    "    target_type : str\n",
    "        'volatility' for volatility forecasting or 'returns' for return forecasting\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing X, y, scaler, and metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract log returns\n",
    "    returns = data['Log_Returns'].values\n",
    "    \n",
    "    if target_type == 'volatility':\n",
    "        # Calculate realized volatility as target\n",
    "        realized_vol = calculate_realized_volatility(data['Log_Returns'], \n",
    "                                                     window=volatility_window)\n",
    "        target_data = realized_vol.values\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_idx = ~np.isnan(target_data)\n",
    "        target_data = target_data[valid_idx]\n",
    "        returns = returns[valid_idx]\n",
    "        \n",
    "    else:  # returns forecasting\n",
    "        target_data = returns\n",
    "    \n",
    "    # Create basic features from returns\n",
    "    X, y = create_svm_features(returns, lookback_window)\n",
    "    \n",
    "    # Adjust target for volatility forecasting\n",
    "    if target_type == 'volatility':\n",
    "        vol_start_idx = lookback_window + volatility_window - 1\n",
    "        y_vol = target_data[vol_start_idx:vol_start_idx+len(y)]\n",
    "        \n",
    "        min_len = min(len(X), len(y_vol))\n",
    "        X = X[:min_len]\n",
    "        y = y_vol[:min_len]\n",
    "    \n",
    "    # Add technical features if requested\n",
    "    if use_technical_features and target_type == 'volatility':\n",
    "        # This would require more complex feature engineering\n",
    "        # For now, we keep it simple with lagged returns\n",
    "        pass\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler_X = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    \n",
    "    # Normalize targets\n",
    "    scaler_y = StandardScaler()\n",
    "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return {\n",
    "        'X': X_scaled,\n",
    "        'y': y_scaled,\n",
    "        'X_original': X,\n",
    "        'y_original': y,\n",
    "        'scaler_X': scaler_X,\n",
    "        'scaler_y': scaler_y,\n",
    "        'lookback_window': lookback_window,\n",
    "        'volatility_window': volatility_window,\n",
    "        'target_type': target_type,\n",
    "        'n_samples': len(X_scaled),\n",
    "        'n_features': X_scaled.shape[1]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== DATA PREPARATION FUNCTIONS ===\\n\")\n",
    "print(\"âœ“ create_svm_features(): Transform time series into feature vectors\")\n",
    "print(\"âœ“ calculate_technical_features(): Compute additional technical indicators\")\n",
    "print(\"âœ“ prepare_svm_data(): Complete data pipeline with scaling\")\n",
    "print(\"\\nðŸ“Š Ready to prepare data for SVM training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033c8633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVM MODEL ARCHITECTURE ===\n",
      "\n",
      "âœ“ build_svm_model(): SVR with multiple kernel options\n",
      "âœ“ perform_hyperparameter_search(): Grid search for optimal parameters\n",
      "âœ“ train_svm_model(): Training pipeline with validation\n",
      "\n",
      "ðŸ¤– SVM architecture ready for training\n",
      "\n",
      "ðŸ“š Reference: Cocco et al. (2021) - Linear, Polynomial, and RBF kernels\n"
     ]
    }
   ],
   "source": [
    "# SVM Model Architecture and Training\n",
    "# Build and train Support Vector Regression models\n",
    "\n",
    "def build_svm_model(kernel='rbf', C=1.0, epsilon=0.1, gamma='scale'):\n",
    "    \"\"\"\n",
    "    Build Support Vector Regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    kernel : str\n",
    "        Kernel type: 'linear', 'poly', 'rbf', 'sigmoid'\n",
    "        RBF (Radial Basis Function) is best for non-linear patterns\n",
    "    C : float\n",
    "        Regularization parameter (controls overfitting)\n",
    "        Larger C = less regularization\n",
    "    epsilon : float\n",
    "        Epsilon in epsilon-SVR model (epsilon-tube)\n",
    "        Specifies epsilon-insensitive loss function\n",
    "    gamma : str or float\n",
    "        Kernel coefficient for 'rbf', 'poly', 'sigmoid'\n",
    "        'scale' = 1/(n_features * X.var())\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    model : SVR\n",
    "        Support Vector Regression model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = SVR(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        epsilon=epsilon,\n",
    "        gamma=gamma,\n",
    "        cache_size=500,  # Larger cache for faster training\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def perform_hyperparameter_search(X_train, y_train, search_type='fast'):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter search for SVM.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : np.array\n",
    "        Training features\n",
    "    y_train : np.array\n",
    "        Training targets\n",
    "    search_type : str\n",
    "        'fast' for quick search, 'thorough' for comprehensive search\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Best hyperparameters and search results\n",
    "    \"\"\"\n",
    "    \n",
    "    if search_type == 'fast':\n",
    "        # Fast grid search with fewer options\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'epsilon': [0.01, 0.1],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "        cv_folds = 3\n",
    "    else:\n",
    "        # Thorough search with more options\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1.0, 10.0, 100.0],\n",
    "            'epsilon': [0.01, 0.05, 0.1, 0.2],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "        }\n",
    "        cv_folds = 5\n",
    "    \n",
    "    # Create base model\n",
    "    base_model = SVR(kernel='rbf', cache_size=500)\n",
    "    \n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid,\n",
    "        cv=cv_folds,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,  # Use all CPU cores\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Fit grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'best_score': -grid_search.best_score_,  # Convert back to MSE\n",
    "        'best_model': grid_search.best_estimator_,\n",
    "        'cv_results': grid_search.cv_results_\n",
    "    }\n",
    "\n",
    "\n",
    "def train_svm_model(X_train, y_train, X_val, y_val, \n",
    "                   use_hyperparameter_search=False, \n",
    "                   C=1.0, epsilon=0.1, gamma='scale',\n",
    "                   verbose=False):\n",
    "    \"\"\"\n",
    "    Train SVM model with optional hyperparameter optimization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.array\n",
    "        Training data\n",
    "    X_val, y_val : np.array\n",
    "        Validation data (for performance monitoring)\n",
    "    use_hyperparameter_search : bool\n",
    "        Whether to perform grid search for hyperparameters\n",
    "    C, epsilon, gamma : float\n",
    "        Default hyperparameters if not using search\n",
    "    verbose : bool\n",
    "        Print training information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Trained model and training information\n",
    "    \"\"\"\n",
    "    \n",
    "    if use_hyperparameter_search:\n",
    "        if verbose:\n",
    "            print(\"   Performing hyperparameter search...\")\n",
    "        \n",
    "        search_results = perform_hyperparameter_search(X_train, y_train, search_type='fast')\n",
    "        model = search_results['best_model']\n",
    "        best_params = search_results['best_params']\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"   Best parameters: C={best_params['C']}, \"\n",
    "                  f\"epsilon={best_params['epsilon']}, gamma={best_params['gamma']}\")\n",
    "    else:\n",
    "        # Use provided hyperparameters\n",
    "        model = build_svm_model(kernel='rbf', C=C, epsilon=epsilon, gamma=gamma)\n",
    "        model.fit(X_train, y_train)\n",
    "        best_params = {'C': C, 'epsilon': epsilon, 'gamma': gamma}\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_mse = mean_squared_error(y_train, train_pred)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_mse = mean_squared_error(y_val, val_pred)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'best_params': best_params,\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse,\n",
    "        'n_support_vectors': len(model.support_) if hasattr(model, 'support_') else 0\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== SVM MODEL ARCHITECTURE ===\\n\")\n",
    "print(\"âœ“ build_svm_model(): SVR with multiple kernel options\")\n",
    "print(\"âœ“ perform_hyperparameter_search(): Grid search for optimal parameters\")\n",
    "print(\"âœ“ train_svm_model(): Training pipeline with validation\")\n",
    "print(\"\\nðŸ¤– SVM architecture ready for training\")\n",
    "print(\"\\nðŸ“š Reference: Cocco et al. (2021) - Linear, Polynomial, and RBF kernels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25f4f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MULTI-KERNEL COMPARISON (Cocco et al., 2021) ===\n",
      "\n",
      "âœ“ train_svm_multi_kernel(): Test Linear, Polynomial, and RBF kernels\n",
      "âœ“ compare_kernel_performance(): Generate kernel comparison table\n",
      "\n",
      "ðŸ“š Implements methodology from Cocco et al. (2021)\n",
      "   â€¢ Linear kernel: Models linear relationships\n",
      "   â€¢ Polynomial kernel: Models polynomial relationships (degree 2 and 3)\n",
      "   â€¢ RBF kernel: Models complex non-linear patterns\n",
      "=== EVALUATION FUNCTIONS ===\n",
      "\n",
      "âœ“ evaluate_svm_predictions(): Comprehensive performance assessment\n",
      "âœ“ Metrics: RMSE, MAE, MAPE, RÂ², Direction Accuracy\n",
      "\n",
      "ðŸ“ˆ Ready to evaluate SVM predictions\n"
     ]
    }
   ],
   "source": [
    "# Multi-Kernel Comparison Framework\n",
    "# Compare Linear, Polynomial, and RBF kernels (Cocco et al., 2021)\n",
    "\n",
    "def train_svm_multi_kernel(X_train, y_train, X_val, y_val, verbose=False):\n",
    "    \"\"\"\n",
    "    Train SVM models with different kernel functions and compare performance.\n",
    "    \n",
    "    Following Cocco et al. (2021), we evaluate three kernel types:\n",
    "    1. Linear kernel: For linear relationships\n",
    "    2. Polynomial kernel: For polynomial relationships (degree 2 and 3)\n",
    "    3. RBF kernel: For complex non-linear relationships\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train, y_train : np.array\n",
    "        Training data\n",
    "    X_val, y_val : np.array\n",
    "        Validation data\n",
    "    verbose : bool\n",
    "        Print detailed information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results for all kernel types\n",
    "    \"\"\"\n",
    "    \n",
    "    kernel_results = {}\n",
    "    \n",
    "    # Define kernel configurations\n",
    "    kernel_configs = {\n",
    "        'Linear': {'kernel': 'linear', 'C': [0.1, 1.0, 10.0]},\n",
    "        'Polynomial (degree=2)': {'kernel': 'poly', 'degree': 2, 'C': [0.1, 1.0, 10.0]},\n",
    "        'Polynomial (degree=3)': {'kernel': 'poly', 'degree': 3, 'C': [0.1, 1.0, 10.0]},\n",
    "        'RBF': {'kernel': 'rbf', 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"   Testing multiple kernel functions...\")\n",
    "    \n",
    "    for kernel_name, config in kernel_configs.items():\n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"      - Training {kernel_name} kernel...\")\n",
    "            \n",
    "            # Prepare parameter grid\n",
    "            if config['kernel'] == 'linear':\n",
    "                param_grid = {\n",
    "                    'kernel': ['linear'],\n",
    "                    'C': config['C'],\n",
    "                    'epsilon': [0.01, 0.1]\n",
    "                }\n",
    "            elif config['kernel'] == 'poly':\n",
    "                param_grid = {\n",
    "                    'kernel': ['poly'],\n",
    "                    'degree': [config['degree']],\n",
    "                    'C': config['C'],\n",
    "                    'epsilon': [0.01, 0.1],\n",
    "                    'gamma': ['scale']\n",
    "                }\n",
    "            else:  # RBF\n",
    "                param_grid = {\n",
    "                    'kernel': ['rbf'],\n",
    "                    'C': config['C'],\n",
    "                    'epsilon': [0.01, 0.1],\n",
    "                    'gamma': config['gamma']\n",
    "                }\n",
    "            \n",
    "            # Grid search\n",
    "            base_model = SVR(cache_size=500)\n",
    "            grid_search = GridSearchCV(\n",
    "                base_model,\n",
    "                param_grid,\n",
    "                cv=3,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            # Get best model\n",
    "            best_model = grid_search.best_estimator_\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_pred = best_model.predict(X_val)\n",
    "            val_mse = mean_squared_error(y_val, val_pred)\n",
    "            val_rmse = np.sqrt(val_mse)\n",
    "            \n",
    "            # Store results\n",
    "            kernel_results[kernel_name] = {\n",
    "                'model': best_model,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'val_mse': val_mse,\n",
    "                'val_rmse': val_rmse,\n",
    "                'best_cv_score': -grid_search.best_score_,\n",
    "                'n_support_vectors': len(best_model.support_) if hasattr(best_model, 'support_') else 0\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"         Validation RMSE: {val_rmse:.6f}, Support Vectors: {kernel_results[kernel_name]['n_support_vectors']}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"         Failed: {str(e)}\")\n",
    "            kernel_results[kernel_name] = None\n",
    "    \n",
    "    # Find best kernel\n",
    "    valid_results = {k: v for k, v in kernel_results.items() if v is not None}\n",
    "    if valid_results:\n",
    "        best_kernel = min(valid_results.keys(), key=lambda k: valid_results[k]['val_rmse'])\n",
    "        if verbose:\n",
    "            print(f\"   âœ“ Best kernel: {best_kernel} (RMSE: {valid_results[best_kernel]['val_rmse']:.6f})\")\n",
    "    else:\n",
    "        best_kernel = None\n",
    "    \n",
    "    return {\n",
    "        'kernel_results': kernel_results,\n",
    "        'best_kernel': best_kernel,\n",
    "        'best_model': kernel_results[best_kernel]['model'] if best_kernel else None\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_kernel_performance(kernel_comparison_results):\n",
    "    \"\"\"\n",
    "    Create summary DataFrame comparing different kernel types.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    kernel_comparison_results : dict\n",
    "        Results from train_svm_multi_kernel\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Summary comparison table\n",
    "    \"\"\"\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for kernel_name, results in kernel_comparison_results['kernel_results'].items():\n",
    "        if results is not None:\n",
    "            comparison_data.append({\n",
    "                'Kernel': kernel_name,\n",
    "                'Validation_RMSE': results['val_rmse'],\n",
    "                'Validation_MSE': results['val_mse'],\n",
    "                'CV_Score': results['best_cv_score'],\n",
    "                'Support_Vectors': results['n_support_vectors'],\n",
    "                'C': results['best_params']['C'],\n",
    "                'Epsilon': results['best_params']['epsilon']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(comparison_data).sort_values('Validation_RMSE')\n",
    "\n",
    "\n",
    "print(\"=== MULTI-KERNEL COMPARISON (Cocco et al., 2021) ===\\n\")\n",
    "print(\"âœ“ train_svm_multi_kernel(): Test Linear, Polynomial, and RBF kernels\")\n",
    "print(\"âœ“ compare_kernel_performance(): Generate kernel comparison table\")\n",
    "print(\"\\nðŸ“š Implements methodology from Cocco et al. (2021)\")\n",
    "print(\"   â€¢ Linear kernel: Models linear relationships\")\n",
    "print(\"   â€¢ Polynomial kernel: Models polynomial relationships (degree 2 and 3)\")\n",
    "print(\"   â€¢ RBF kernel: Models complex non-linear patterns\")\n",
    "\n",
    "\n",
    "# Evaluation and Prediction Functions for SVM\n",
    "# Assess model performance on test data\n",
    "\n",
    "def evaluate_svm_predictions(model, X_test, y_test, scaler_y):\n",
    "    \"\"\"\n",
    "    Generate predictions and calculate performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : SVR\n",
    "        Trained SVM model\n",
    "    X_test : np.array\n",
    "        Test input features\n",
    "    y_test : np.array\n",
    "        True test values (scaled)\n",
    "    scaler_y : StandardScaler\n",
    "        Scaler used for target variable\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing predictions and metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "    y_true = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    \n",
    "    # Direction accuracy (for volatility changes)\n",
    "    if len(y_true) > 1:\n",
    "        direction_true = np.sign(np.diff(y_true))\n",
    "        direction_pred = np.sign(np.diff(y_pred))\n",
    "        direction_accuracy = np.mean(direction_true == direction_pred) * 100\n",
    "    else:\n",
    "        direction_accuracy = 0\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    return {\n",
    "        'predictions': y_pred,\n",
    "        'true_values': y_true,\n",
    "        'predictions_scaled': y_pred_scaled,\n",
    "        'true_values_scaled': y_test,\n",
    "        'residuals': residuals,\n",
    "        'metrics': {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'r2': r2,\n",
    "            'direction_accuracy': direction_accuracy\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== EVALUATION FUNCTIONS ===\\n\")\n",
    "print(\"âœ“ evaluate_svm_predictions(): Comprehensive performance assessment\")\n",
    "print(\"âœ“ Metrics: RMSE, MAE, MAPE, RÂ², Direction Accuracy\")\n",
    "print(\"\\nðŸ“ˆ Ready to evaluate SVM predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a473279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CROSS-VALIDATION INTEGRATION ===\n",
      "\n",
      "âœ“ run_svm_cross_validation(): Complete SVM pipeline\n",
      "âœ“ Integrates with existing CV splits\n",
      "âœ“ Automated training, validation, and testing\n",
      "\n",
      "ðŸš€ Ready to run SVM analysis on both assets\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation Integration for SVM\n",
    "# Run SVM training and evaluation across all CV windows\n",
    "\n",
    "def run_svm_cross_validation(cv_splits, data_clean, asset_name,\n",
    "                             lookback_window=20, volatility_window=5,\n",
    "                             use_hyperparameter_search=True,\n",
    "                             C=1.0, epsilon=0.1, gamma='scale',\n",
    "                             verbose=True):\n",
    "    \"\"\"\n",
    "    Run SVM volatility forecasting across all cross-validation windows.\n",
    "    \n",
    "    This function implements the complete SVM methodology:\n",
    "    1. Prepare data for each window (train, validation, test)\n",
    "    2. Hyperparameter optimization using grid search (optional)\n",
    "    3. Train SVM model on training data\n",
    "    4. Evaluate on out-of-sample test data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    cv_splits : list\n",
    "        Cross-validation splits\n",
    "    data_clean : pd.DataFrame\n",
    "        Clean data with log returns\n",
    "    asset_name : str\n",
    "        Name of the asset ('S&P 500' or 'Bitcoin')\n",
    "    lookback_window : int\n",
    "        Number of past time steps for features\n",
    "    volatility_window : int\n",
    "        Window for realized volatility calculation\n",
    "    use_hyperparameter_search : bool\n",
    "        Whether to perform grid search for optimal parameters\n",
    "    C, epsilon, gamma : float\n",
    "        Default hyperparameters if not using search\n",
    "    verbose : bool\n",
    "        Print progress information\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Comprehensive results dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{asset_name.upper()} SVM CROSS-VALIDATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Running SVM across {len(cv_splits)} windows...\")\n",
    "    print(f\"Model: Support Vector Regression with RBF kernel\")\n",
    "    print(f\"Lookback window: {lookback_window} days\")\n",
    "    print(f\"Volatility window: {volatility_window} days\")\n",
    "    print(f\"Hyperparameter search: {'Enabled' if use_hyperparameter_search else 'Disabled'}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_results = []\n",
    "    model_summary = []\n",
    "    \n",
    "    for window_idx, split in enumerate(cv_splits):\n",
    "        window_id = split['window_id']\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nðŸ”„ Processing Window {window_id}/{len(cv_splits)}...\")\n",
    "            print(f\"   Train: {split['train']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{split['train']['end'].strftime('%Y-%m-%d')} ({split['train']['size']} obs)\")\n",
    "            print(f\"   Test:  {split['test']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{split['test']['end'].strftime('%Y-%m-%d')} ({split['test']['size']} obs)\")\n",
    "        \n",
    "        try:\n",
    "            # STEP 1: Prepare training data\n",
    "            if verbose:\n",
    "                print(f\"   ðŸ“Š Preparing data with lookback={lookback_window}...\")\n",
    "            \n",
    "            train_prepared = prepare_svm_data(\n",
    "                split['train']['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # STEP 2: Prepare validation data (use fold 3 - longest validation period)\n",
    "            val_fold = split['validation'][2]\n",
    "            val_prepared = prepare_svm_data(\n",
    "                val_fold['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # Use training scaler for validation data\n",
    "            X_val_scaled = train_prepared['scaler_X'].transform(val_prepared['X_original'])\n",
    "            y_val_scaled = train_prepared['scaler_y'].transform(\n",
    "                val_prepared['y_original'].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            \n",
    "            # STEP 3: Prepare test data\n",
    "            test_prepared = prepare_svm_data(\n",
    "                split['test']['data'],\n",
    "                lookback_window=lookback_window,\n",
    "                volatility_window=volatility_window,\n",
    "                target_type='volatility'\n",
    "            )\n",
    "            \n",
    "            # Use training scaler for test data\n",
    "            X_test_scaled = train_prepared['scaler_X'].transform(test_prepared['X_original'])\n",
    "            y_test_scaled = train_prepared['scaler_y'].transform(\n",
    "                test_prepared['y_original'].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   ðŸ¤– Training SVM model...\")\n",
    "            \n",
    "            # STEP 4: Train SVM model\n",
    "            training_result = train_svm_model(\n",
    "                train_prepared['X'], train_prepared['y'],\n",
    "                X_val_scaled, y_val_scaled,\n",
    "                use_hyperparameter_search=use_hyperparameter_search,\n",
    "                C=C, epsilon=epsilon, gamma=gamma,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            model = training_result['model']\n",
    "            \n",
    "            # STEP 5: Evaluate on test data\n",
    "            if verbose:\n",
    "                print(f\"   ðŸ“ˆ Evaluating on test data...\")\n",
    "            \n",
    "            evaluation = evaluate_svm_predictions(\n",
    "                model,\n",
    "                X_test_scaled,\n",
    "                y_test_scaled,\n",
    "                train_prepared['scaler_y']\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            window_result = {\n",
    "                'window_id': window_id,\n",
    "                'asset': asset_name,\n",
    "                'train_period': f\"{split['train']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                               f\"{split['train']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'test_period': f\"{split['test']['start'].strftime('%Y-%m-%d')} to \"\n",
    "                              f\"{split['test']['end'].strftime('%Y-%m-%d')}\",\n",
    "                'train_size': train_prepared['n_samples'],\n",
    "                'val_size': len(X_val_scaled),\n",
    "                'test_size': len(X_test_scaled),\n",
    "                'hyperparameters': training_result['best_params'],\n",
    "                'training': {\n",
    "                    'train_mse': training_result['train_mse'],\n",
    "                    'val_mse': training_result['val_mse'],\n",
    "                    'n_support_vectors': training_result['n_support_vectors']\n",
    "                },\n",
    "                'evaluation': evaluation,\n",
    "                'model': model\n",
    "            }\n",
    "            \n",
    "            all_results.append(window_result)\n",
    "            \n",
    "            # Summary for quick reference\n",
    "            model_summary.append({\n",
    "                'Window': window_id,\n",
    "                'Train_Samples': train_prepared['n_samples'],\n",
    "                'Test_Samples': len(X_test_scaled),\n",
    "                'C': training_result['best_params']['C'],\n",
    "                'Epsilon': training_result['best_params']['epsilon'],\n",
    "                'Gamma': training_result['best_params']['gamma'],\n",
    "                'N_Support_Vectors': training_result['n_support_vectors'],\n",
    "                'Train_MSE': training_result['train_mse'],\n",
    "                'Val_MSE': training_result['val_mse'],\n",
    "                'Test_RMSE': evaluation['metrics']['rmse'],\n",
    "                'Test_MAE': evaluation['metrics']['mae'],\n",
    "                'Test_R2': evaluation['metrics']['r2'],\n",
    "                'Direction_Accuracy': evaluation['metrics']['direction_accuracy']\n",
    "            })\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   âœ… Test RMSE={evaluation['metrics']['rmse']:.6f}, \"\n",
    "                      f\"RÂ²={evaluation['metrics']['r2']:.4f}, \"\n",
    "                      f\"Direction Acc={evaluation['metrics']['direction_accuracy']:.1f}%\")\n",
    "                print(f\"   â„¹ï¸  Support Vectors: {training_result['n_support_vectors']}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Window {window_id} failed: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    summary_df = pd.DataFrame(model_summary)\n",
    "    \n",
    "    # Calculate overall performance statistics\n",
    "    if len(summary_df) > 0:\n",
    "        performance_summary = {\n",
    "            'total_windows': len(cv_splits),\n",
    "            'successful_windows': len(summary_df),\n",
    "            'success_rate': len(summary_df) / len(cv_splits) * 100,\n",
    "            'avg_test_rmse': summary_df['Test_RMSE'].mean(),\n",
    "            'std_test_rmse': summary_df['Test_RMSE'].std(),\n",
    "            'avg_test_mae': summary_df['Test_MAE'].mean(),\n",
    "            'avg_r2': summary_df['Test_R2'].mean(),\n",
    "            'avg_direction_accuracy': summary_df['Direction_Accuracy'].mean(),\n",
    "            'avg_support_vectors': summary_df['N_Support_Vectors'].mean()\n",
    "        }\n",
    "    else:\n",
    "        performance_summary = None\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{asset_name.upper()} SVM CROSS-VALIDATION COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if performance_summary:\n",
    "        print(f\"âœ… Successfully processed {performance_summary['successful_windows']}/\"\n",
    "              f\"{performance_summary['total_windows']} windows\")\n",
    "        print(f\"ðŸ“Š Average Test RMSE: {performance_summary['avg_test_rmse']:.6f} Â± \"\n",
    "              f\"{performance_summary['std_test_rmse']:.6f}\")\n",
    "        print(f\"ðŸ“Š Average RÂ²: {performance_summary['avg_r2']:.4f}\")\n",
    "        print(f\"ðŸŽ¯ Average Direction Accuracy: {performance_summary['avg_direction_accuracy']:.2f}%\")\n",
    "        print(f\"â„¹ï¸  Average Support Vectors: {performance_summary['avg_support_vectors']:.0f}\")\n",
    "    else:\n",
    "        print(\"âŒ No successful model fits achieved\")\n",
    "    \n",
    "    return {\n",
    "        'asset_name': asset_name,\n",
    "        'all_results': all_results,\n",
    "        'summary_df': summary_df,\n",
    "        'performance_summary': performance_summary,\n",
    "        'methodology': {\n",
    "            'model_type': 'Support Vector Regression',\n",
    "            'kernel': 'RBF (Radial Basis Function)',\n",
    "            'lookback_window': lookback_window,\n",
    "            'volatility_window': volatility_window,\n",
    "            'target': 'Realized Volatility',\n",
    "            'hyperparameter_search': use_hyperparameter_search,\n",
    "            'validation': '3-fold temporal validation'\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"=== CROSS-VALIDATION INTEGRATION ===\\n\")\n",
    "print(\"âœ“ run_svm_cross_validation(): Complete SVM pipeline\")\n",
    "print(\"âœ“ Integrates with existing CV splits\")\n",
    "print(\"âœ“ Automated training, validation, and testing\")\n",
    "print(\"\\nðŸš€ Ready to run SVM analysis on both assets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0c9b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "KERNEL COMPARISON ANALYSIS (Following Cocco et al., 2021)\n",
      "====================================================================================================\n",
      "Testing multiple kernel functions: Linear, Polynomial (deg 2,3), and RBF\n",
      "This analysis demonstrates the comparative performance of different kernel types\n",
      "\n",
      "Demo Window: 2002-01-03 to 2008-01-02\n",
      "\n",
      "ðŸ“Š Preparing data...\n",
      "\n",
      "ðŸ”¬ Testing kernel functions...\n",
      "   Testing multiple kernel functions...\n",
      "      - Training Linear kernel...\n",
      "         Validation RMSE: 0.621791, Support Vectors: 638\n",
      "      - Training Polynomial (degree=2) kernel...\n",
      "         Validation RMSE: 0.458727, Support Vectors: 716\n",
      "      - Training Polynomial (degree=3) kernel...\n",
      "         Validation RMSE: 0.607460, Support Vectors: 717\n",
      "      - Training RBF kernel...\n",
      "         Validation RMSE: 0.377091, Support Vectors: 711\n",
      "   âœ“ Best kernel: RBF (RMSE: 0.377091)\n",
      "\n",
      "====================================================================================================\n",
      "KERNEL PERFORMANCE COMPARISON\n",
      "====================================================================================================\n",
      "               Kernel  Validation_RMSE  Validation_MSE  CV_Score  Support_Vectors        C  Epsilon\n",
      "                  RBF         0.377091        0.142197  0.607623              711 1.000000 0.010000\n",
      "Polynomial (degree=2)         0.458727        0.210430  0.710939              716 0.100000 0.010000\n",
      "Polynomial (degree=3)         0.607460        0.369008  1.295695              717 0.100000 0.010000\n",
      "               Linear         0.621791        0.386624  1.367373              638 0.100000 0.100000\n",
      "\n",
      "ðŸ† Best Performing Kernel: RBF\n",
      "   Validation RMSE: 0.377091\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“š INTERPRETATION (Cocco et al., 2021):\n",
      "\n",
      "â€¢ Linear Kernel: Best for data with linear relationships\n",
      "  - Fastest training time\n",
      "  - Most interpretable\n",
      "  - Limited to linear patterns\n",
      "\n",
      "â€¢ Polynomial Kernel: Models polynomial relationships\n",
      "  - Degree 2: Quadratic patterns\n",
      "  - Degree 3: Cubic patterns\n",
      "  - More flexible than linear, less than RBF\n",
      "\n",
      "â€¢ RBF Kernel: Models complex non-linear patterns\n",
      "  - Most flexible\n",
      "  - Can capture intricate relationships\n",
      "  - Risk of overfitting with improper parameters\n",
      "\n",
      "The kernel with lowest validation RMSE provides the best fit for this data.\n",
      "Support vector count indicates model complexity (fewer = more generalized).\n",
      "\n",
      "âœ“ Kernel comparison complete - Proceeding with full SVM analysis\n",
      "\n",
      "ðŸš€ STARTING SVM VOLATILITY FORECASTING ANALYSIS\n",
      "====================================================================================================\n",
      "Implementing Support Vector Regression for realized volatility prediction\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“‹ SVM Configuration:\n",
      "   lookback_window: 20\n",
      "   volatility_window: 5\n",
      "   use_hyperparameter_search: True\n",
      "   C: 1.0\n",
      "   epsilon: 0.1\n",
      "   gamma: scale\n",
      "\n",
      "ðŸ”µ PHASE 1: S&P 500 ANALYSIS (First 3 Windows)\n",
      "\n",
      "================================================================================\n",
      "S&P 500 SVM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running SVM across 3 windows...\n",
      "Model: Support Vector Regression with RBF kernel\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "Hyperparameter search: Enabled\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/3...\n",
      "   Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "   Test:  2007-01-03 to 2008-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009303, RÂ²=0.1102, Direction Acc=47.5%\n",
      "   â„¹ï¸  Support Vectors: 711\n",
      "\n",
      "ðŸ”„ Processing Window 2/3...\n",
      "   Train: 2003-01-03 to 2006-01-02 (767 obs)\n",
      "   Test:  2008-01-03 to 2009-01-02 (253 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.044236, RÂ²=-0.5733, Direction Acc=43.8%\n",
      "   â„¹ï¸  Support Vectors: 670\n",
      "\n",
      "ðŸ”„ Processing Window 3/3...\n",
      "   Train: 2004-01-03 to 2007-01-02 (767 obs)\n",
      "   Test:  2009-01-03 to 2010-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.024129, RÂ²=-1.0817, Direction Acc=50.9%\n",
      "   â„¹ï¸  Support Vectors: 672\n",
      "\n",
      "================================================================================\n",
      "S&P 500 SVM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 3/3 windows\n",
      "ðŸ“Š Average Test RMSE: 0.025889 Â± 0.017533\n",
      "ðŸ“Š Average RÂ²: -0.5149\n",
      "ðŸŽ¯ Average Direction Accuracy: 47.39%\n",
      "â„¹ï¸  Average Support Vectors: 684\n"
     ]
    }
   ],
   "source": [
    "# Kernel Comparison Demonstration (Cocco et al., 2021)\n",
    "# Test Linear, Polynomial, and RBF kernels on one window\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"KERNEL COMPARISON ANALYSIS (Following Cocco et al., 2021)\")\n",
    "print(\"=\"*100)\n",
    "print(\"Testing multiple kernel functions: Linear, Polynomial (deg 2,3), and RBF\")\n",
    "print(\"This analysis demonstrates the comparative performance of different kernel types\\n\")\n",
    "\n",
    "# Use first window for demonstration\n",
    "demo_split = sp500_cv_splits[0]\n",
    "\n",
    "print(f\"Demo Window: {demo_split['train']['start'].strftime('%Y-%m-%d')} to {demo_split['test']['end'].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Prepare data\n",
    "print(\"\\nðŸ“Š Preparing data...\")\n",
    "demo_train = prepare_svm_data(\n",
    "    demo_split['train']['data'],\n",
    "    lookback_window=20,\n",
    "    volatility_window=5,\n",
    "    target_type='volatility'\n",
    ")\n",
    "\n",
    "demo_val = prepare_svm_data(\n",
    "    demo_split['validation'][2]['data'],\n",
    "    lookback_window=20,\n",
    "    volatility_window=5,\n",
    "    target_type='volatility'\n",
    ")\n",
    "\n",
    "# Use training scaler for validation\n",
    "X_val_demo = demo_train['scaler_X'].transform(demo_val['X_original'])\n",
    "y_val_demo = demo_train['scaler_y'].transform(demo_val['y_original'].reshape(-1, 1)).flatten()\n",
    "\n",
    "# Test multiple kernels\n",
    "print(\"\\nðŸ”¬ Testing kernel functions...\")\n",
    "kernel_comparison = train_svm_multi_kernel(\n",
    "    demo_train['X'], demo_train['y'],\n",
    "    X_val_demo, y_val_demo,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Display comparison table\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(\"KERNEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "kernel_summary = compare_kernel_performance(kernel_comparison)\n",
    "print(kernel_summary.to_string(index=False, float_format='%.6f'))\n",
    "\n",
    "print(f\"\\nðŸ† Best Performing Kernel: {kernel_comparison['best_kernel']}\")\n",
    "print(f\"   Validation RMSE: {kernel_comparison['kernel_results'][kernel_comparison['best_kernel']]['val_rmse']:.6f}\")\n",
    "\n",
    "# Visualize kernel comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Validation RMSE by kernel\n",
    "valid_kernels = kernel_summary['Kernel'].tolist()\n",
    "valid_rmse = kernel_summary['Validation_RMSE'].tolist()\n",
    "colors = ['blue' if 'Linear' in k else 'orange' if 'Polynomial' in k else 'green' for k in valid_kernels]\n",
    "\n",
    "axes[0].bar(range(len(valid_kernels)), valid_rmse, color=colors, alpha=0.7)\n",
    "axes[0].set_xticks(range(len(valid_kernels)))\n",
    "axes[0].set_xticklabels(valid_kernels, rotation=45, ha='right')\n",
    "axes[0].set_title('Validation RMSE by Kernel Type')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Support Vectors by kernel\n",
    "valid_sv = kernel_summary['Support_Vectors'].tolist()\n",
    "axes[1].bar(range(len(valid_kernels)), valid_sv, color=colors, alpha=0.7)\n",
    "axes[1].set_xticks(range(len(valid_kernels)))\n",
    "axes[1].set_xticklabels(valid_kernels, rotation=45, ha='right')\n",
    "axes[1].set_title('Number of Support Vectors')\n",
    "axes[1].set_ylabel('Support Vectors')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('SVM Kernel Comparison (Cocco et al., 2021 Methodology)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“š INTERPRETATION (Cocco et al., 2021):\n",
    "\n",
    "â€¢ Linear Kernel: Best for data with linear relationships\n",
    "  - Fastest training time\n",
    "  - Most interpretable\n",
    "  - Limited to linear patterns\n",
    "\n",
    "â€¢ Polynomial Kernel: Models polynomial relationships\n",
    "  - Degree 2: Quadratic patterns\n",
    "  - Degree 3: Cubic patterns\n",
    "  - More flexible than linear, less than RBF\n",
    "\n",
    "â€¢ RBF Kernel: Models complex non-linear patterns\n",
    "  - Most flexible\n",
    "  - Can capture intricate relationships\n",
    "  - Risk of overfitting with improper parameters\n",
    "\n",
    "The kernel with lowest validation RMSE provides the best fit for this data.\n",
    "Support vector count indicates model complexity (fewer = more generalized).\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ“ Kernel comparison complete - Proceeding with full SVM analysis\\n\")\n",
    "\n",
    "\n",
    "# Execute SVM Analysis on S&P 500\n",
    "# Run complete analysis on first few windows to demonstrate methodology\n",
    "\n",
    "print(\"ðŸš€ STARTING SVM VOLATILITY FORECASTING ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "print(\"Implementing Support Vector Regression for realized volatility prediction\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Configuration for SVM\n",
    "SVM_CONFIG = {\n",
    "    'lookback_window': 20,              # Use 20 days of past returns as features\n",
    "    'volatility_window': 5,             # Calculate 5-day realized volatility\n",
    "    'use_hyperparameter_search': True,  # Enable grid search for optimal parameters\n",
    "    'C': 1.0,                           # Default regularization (if search disabled)\n",
    "    'epsilon': 0.1,                     # Default epsilon (if search disabled)\n",
    "    'gamma': 'scale'                    # Default gamma (if search disabled)\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“‹ SVM Configuration:\")\n",
    "for key, value in SVM_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Run S&P 500 analysis (first 3 windows for demonstration)\n",
    "print(\"\\nðŸ”µ PHASE 1: S&P 500 ANALYSIS (First 3 Windows)\")\n",
    "sp500_svm_results = run_svm_cross_validation(\n",
    "    cv_splits=sp500_cv_splits[:3],  # Limit to first 3 windows for demonstration\n",
    "    data_clean=sp500_clean,\n",
    "    asset_name='S&P 500',\n",
    "    **SVM_CONFIG,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd13b3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŸ¡ PHASE 2: BITCOIN ANALYSIS (First 3 Windows)\n",
      "\n",
      "================================================================================\n",
      "BITCOIN SVM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running SVM across 3 windows...\n",
      "Model: Support Vector Regression with RBF kernel\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "Hyperparameter search: Enabled\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/3...\n",
      "   Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "   Test:  2018-01-01 to 2018-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.054165, RÂ²=-0.5246, Direction Acc=42.8%\n",
      "   â„¹ï¸  Support Vectors: 607\n",
      "\n",
      "ðŸ”„ Processing Window 2/3...\n",
      "   Train: 2015-07-01 to 2017-06-30 (731 obs)\n",
      "   Test:  2018-07-01 to 2018-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.042960, RÂ²=0.0151, Direction Acc=41.9%\n",
      "   â„¹ï¸  Support Vectors: 592\n",
      "\n",
      "ðŸ”„ Processing Window 3/3...\n",
      "   Train: 2016-01-01 to 2017-12-31 (731 obs)\n",
      "   Test:  2019-01-01 to 2019-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.049400, RÂ²=-0.0611, Direction Acc=47.4%\n",
      "   â„¹ï¸  Support Vectors: 580\n",
      "\n",
      "================================================================================\n",
      "BITCOIN SVM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 3/3 windows\n",
      "ðŸ“Š Average Test RMSE: 0.048842 Â± 0.005624\n",
      "ðŸ“Š Average RÂ²: -0.1902\n",
      "ðŸŽ¯ Average Direction Accuracy: 44.02%\n",
      "â„¹ï¸  Average Support Vectors: 593\n"
     ]
    }
   ],
   "source": [
    "# Execute SVM Analysis on Bitcoin\n",
    "# Run analysis on Bitcoin data\n",
    "\n",
    "print(\"\\nðŸŸ¡ PHASE 2: BITCOIN ANALYSIS (First 3 Windows)\")\n",
    "bitcoin_svm_results = run_svm_cross_validation(\n",
    "    cv_splits=bitcoin_cv_splits[:3],  # Limit to first 3 windows for demonstration\n",
    "    data_clean=bitcoin_clean,\n",
    "    asset_name='Bitcoin',\n",
    "    **SVM_CONFIG,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "443201df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FULL S&P 500 SVM Analysis (all windows)...\n",
      "\n",
      "================================================================================\n",
      "S&P 500 SVM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running SVM across 16 windows...\n",
      "Model: Support Vector Regression with RBF kernel\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "Hyperparameter search: Enabled\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/16...\n",
      "   Train: 2002-01-03 to 2005-01-02 (755 obs)\n",
      "   Test:  2007-01-03 to 2008-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009303, RÂ²=0.1102, Direction Acc=47.5%\n",
      "   â„¹ï¸  Support Vectors: 711\n",
      "\n",
      "ðŸ”„ Processing Window 2/16...\n",
      "   Train: 2003-01-03 to 2006-01-02 (767 obs)\n",
      "   Test:  2008-01-03 to 2009-01-02 (253 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.044236, RÂ²=-0.5733, Direction Acc=43.8%\n",
      "   â„¹ï¸  Support Vectors: 670\n",
      "\n",
      "ðŸ”„ Processing Window 3/16...\n",
      "   Train: 2004-01-03 to 2007-01-02 (767 obs)\n",
      "   Test:  2009-01-03 to 2010-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.024129, RÂ²=-1.0817, Direction Acc=50.9%\n",
      "   â„¹ï¸  Support Vectors: 672\n",
      "\n",
      "ðŸ”„ Processing Window 4/16...\n",
      "   Train: 2005-01-03 to 2008-01-02 (768 obs)\n",
      "   Test:  2010-01-03 to 2011-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.010967, RÂ²=0.1687, Direction Acc=49.8%\n",
      "   â„¹ï¸  Support Vectors: 653\n",
      "\n",
      "ðŸ”„ Processing Window 5/16...\n",
      "   Train: 2006-01-03 to 2009-01-02 (768 obs)\n",
      "   Test:  2011-01-03 to 2012-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=10.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.017546, RÂ²=-0.0141, Direction Acc=46.2%\n",
      "   â„¹ï¸  Support Vectors: 723\n",
      "\n",
      "ðŸ”„ Processing Window 6/16...\n",
      "   Train: 2007-01-03 to 2010-01-02 (767 obs)\n",
      "   Test:  2012-01-03 to 2013-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006845, RÂ²=0.0060, Direction Acc=55.9%\n",
      "   â„¹ï¸  Support Vectors: 604\n",
      "\n",
      "ðŸ”„ Processing Window 7/16...\n",
      "   Train: 2008-01-03 to 2011-01-02 (768 obs)\n",
      "   Test:  2013-01-03 to 2014-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006804, RÂ²=-0.2045, Direction Acc=54.3%\n",
      "   â„¹ï¸  Support Vectors: 732\n",
      "\n",
      "ðŸ”„ Processing Window 8/16...\n",
      "   Train: 2009-01-03 to 2012-01-02 (768 obs)\n",
      "   Test:  2014-01-03 to 2015-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006876, RÂ²=0.0767, Direction Acc=53.8%\n",
      "   â„¹ï¸  Support Vectors: 639\n",
      "\n",
      "ðŸ”„ Processing Window 9/16...\n",
      "   Train: 2010-01-03 to 2013-01-02 (768 obs)\n",
      "   Test:  2015-01-03 to 2016-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.009883, RÂ²=0.1435, Direction Acc=48.6%\n",
      "   â„¹ï¸  Support Vectors: 658\n",
      "\n",
      "ðŸ”„ Processing Window 10/16...\n",
      "   Train: 2011-01-03 to 2014-01-02 (768 obs)\n",
      "   Test:  2016-01-03 to 2017-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.008096, RÂ²=0.0518, Direction Acc=48.0%\n",
      "   â„¹ï¸  Support Vectors: 640\n",
      "\n",
      "ðŸ”„ Processing Window 11/16...\n",
      "   Train: 2012-01-03 to 2015-01-02 (767 obs)\n",
      "   Test:  2017-01-03 to 2018-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006075, RÂ²=-1.0279, Direction Acc=58.7%\n",
      "   â„¹ï¸  Support Vectors: 686\n",
      "\n",
      "ðŸ”„ Processing Window 12/16...\n",
      "   Train: 2013-01-03 to 2016-01-02 (767 obs)\n",
      "   Test:  2018-01-03 to 2019-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.010735, RÂ²=0.2444, Direction Acc=47.3%\n",
      "   â„¹ï¸  Support Vectors: 658\n",
      "\n",
      "ðŸ”„ Processing Window 13/16...\n",
      "   Train: 2014-01-03 to 2017-01-02 (767 obs)\n",
      "   Test:  2019-01-03 to 2020-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.006676, RÂ²=0.3076, Direction Acc=55.6%\n",
      "   â„¹ï¸  Support Vectors: 654\n",
      "\n",
      "ðŸ”„ Processing Window 14/16...\n",
      "   Train: 2015-01-03 to 2018-01-02 (768 obs)\n",
      "   Test:  2020-01-03 to 2021-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.037291, RÂ²=-0.1305, Direction Acc=45.3%\n",
      "   â„¹ï¸  Support Vectors: 725\n",
      "\n",
      "ðŸ”„ Processing Window 15/16...\n",
      "   Train: 2016-01-03 to 2019-01-02 (768 obs)\n",
      "   Test:  2021-01-03 to 2022-01-02 (252 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.007962, RÂ²=-0.0051, Direction Acc=40.4%\n",
      "   â„¹ï¸  Support Vectors: 729\n",
      "\n",
      "ðŸ”„ Processing Window 16/16...\n",
      "   Train: 2017-01-03 to 2020-01-02 (767 obs)\n",
      "   Test:  2022-01-03 to 2023-01-02 (251 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.014682, RÂ²=-0.7578, Direction Acc=45.5%\n",
      "   â„¹ï¸  Support Vectors: 726\n",
      "\n",
      "================================================================================\n",
      "S&P 500 SVM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 16/16 windows\n",
      "ðŸ“Š Average Test RMSE: 0.014257 Â± 0.011465\n",
      "ðŸ“Š Average RÂ²: -0.1679\n",
      "ðŸŽ¯ Average Direction Accuracy: 49.47%\n",
      "â„¹ï¸  Average Support Vectors: 680\n",
      "\\nRunning FULL Bitcoin SVM Analysis (all windows)...\n",
      "\n",
      "================================================================================\n",
      "BITCOIN SVM CROSS-VALIDATION\n",
      "================================================================================\n",
      "Running SVM across 11 windows...\n",
      "Model: Support Vector Regression with RBF kernel\n",
      "Lookback window: 20 days\n",
      "Volatility window: 5 days\n",
      "Hyperparameter search: Enabled\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”„ Processing Window 1/11...\n",
      "   Train: 2015-01-01 to 2016-12-31 (730 obs)\n",
      "   Test:  2018-01-01 to 2018-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.054165, RÂ²=-0.5246, Direction Acc=42.8%\n",
      "   â„¹ï¸  Support Vectors: 607\n",
      "\n",
      "ðŸ”„ Processing Window 2/11...\n",
      "   Train: 2015-07-01 to 2017-06-30 (731 obs)\n",
      "   Test:  2018-07-01 to 2018-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.042960, RÂ²=0.0151, Direction Acc=41.9%\n",
      "   â„¹ï¸  Support Vectors: 592\n",
      "\n",
      "ðŸ”„ Processing Window 3/11...\n",
      "   Train: 2016-01-01 to 2017-12-31 (731 obs)\n",
      "   Test:  2019-01-01 to 2019-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.049400, RÂ²=-0.0611, Direction Acc=47.4%\n",
      "   â„¹ï¸  Support Vectors: 580\n",
      "\n",
      "ðŸ”„ Processing Window 4/11...\n",
      "   Train: 2016-07-01 to 2018-06-30 (730 obs)\n",
      "   Test:  2019-07-01 to 2019-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.043004, RÂ²=-0.6257, Direction Acc=38.7%\n",
      "   â„¹ï¸  Support Vectors: 626\n",
      "\n",
      "ðŸ”„ Processing Window 5/11...\n",
      "   Train: 2017-01-01 to 2018-12-31 (730 obs)\n",
      "   Test:  2020-01-01 to 2020-06-30 (182 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.079973, RÂ²=0.0282, Direction Acc=35.3%\n",
      "   â„¹ï¸  Support Vectors: 625\n",
      "\n",
      "ðŸ”„ Processing Window 6/11...\n",
      "   Train: 2017-07-01 to 2019-06-30 (730 obs)\n",
      "   Test:  2020-07-01 to 2020-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.033597, RÂ²=-0.2936, Direction Acc=40.6%\n",
      "   â„¹ï¸  Support Vectors: 625\n",
      "\n",
      "ðŸ”„ Processing Window 7/11...\n",
      "   Train: 2018-01-01 to 2019-12-31 (730 obs)\n",
      "   Test:  2021-01-01 to 2021-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.041264, RÂ²=-0.1579, Direction Acc=44.7%\n",
      "   â„¹ï¸  Support Vectors: 619\n",
      "\n",
      "ðŸ”„ Processing Window 8/11...\n",
      "   Train: 2018-07-01 to 2020-06-30 (731 obs)\n",
      "   Test:  2021-07-01 to 2021-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.030525, RÂ²=-0.8575, Direction Acc=41.3%\n",
      "   â„¹ï¸  Support Vectors: 607\n",
      "\n",
      "ðŸ”„ Processing Window 9/11...\n",
      "   Train: 2019-01-01 to 2020-12-31 (731 obs)\n",
      "   Test:  2022-01-01 to 2022-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.01, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.044594, RÂ²=-0.3282, Direction Acc=46.7%\n",
      "   â„¹ï¸  Support Vectors: 693\n",
      "\n",
      "ðŸ”„ Processing Window 10/11...\n",
      "   Train: 2019-07-01 to 2021-06-30 (731 obs)\n",
      "   Test:  2022-07-01 to 2022-12-31 (184 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=0.1, epsilon=0.1, gamma=auto\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.041819, RÂ²=-0.1353, Direction Acc=45.2%\n",
      "   â„¹ï¸  Support Vectors: 596\n",
      "\n",
      "ðŸ”„ Processing Window 11/11...\n",
      "   Train: 2020-01-01 to 2021-12-31 (731 obs)\n",
      "   Test:  2023-01-01 to 2023-06-30 (181 obs)\n",
      "   ðŸ“Š Preparing data with lookback=20...\n",
      "   ðŸ¤– Training SVM model...\n",
      "   Performing hyperparameter search...\n",
      "   Best parameters: C=1.0, epsilon=0.1, gamma=scale\n",
      "   ðŸ“ˆ Evaluating on test data...\n",
      "   âœ… Test RMSE=0.031294, RÂ²=-0.5389, Direction Acc=42.8%\n",
      "   â„¹ï¸  Support Vectors: 594\n",
      "\n",
      "================================================================================\n",
      "BITCOIN SVM CROSS-VALIDATION COMPLETE\n",
      "================================================================================\n",
      "âœ… Successfully processed 11/11 windows\n",
      "ðŸ“Š Average Test RMSE: 0.044781 Â± 0.013732\n",
      "ðŸ“Š Average RÂ²: -0.3163\n",
      "ðŸŽ¯ Average Direction Accuracy: 42.49%\n",
      "â„¹ï¸  Average Support Vectors: 615\n"
     ]
    }
   ],
   "source": [
    "# Optional: Run Full Analysis on All Windows\n",
    "# Uncomment and run this cell to process all CV windows (will take longer)\n",
    "\n",
    "\n",
    "# Full S&P 500 Analysis (all 16 windows)\n",
    "print(\"Running FULL S&P 500 SVM Analysis (all windows)...\")\n",
    "sp500_svm_full = run_svm_cross_validation(\n",
    "    cv_splits=sp500_cv_splits,  # All windows\n",
    "    data_clean=sp500_clean,\n",
    "    asset_name='S&P 500',\n",
    "    **SVM_CONFIG,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Full Bitcoin Analysis (all 11 windows)\n",
    "print(\"\\\\nRunning FULL Bitcoin SVM Analysis (all windows)...\")\n",
    "bitcoin_svm_full = run_svm_cross_validation(\n",
    "    cv_splits=bitcoin_cv_splits,  # All windows\n",
    "    data_clean=bitcoin_clean,\n",
    "    asset_name='Bitcoin',\n",
    "    **SVM_CONFIG,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e79799",
   "metadata": {},
   "source": [
    "# Model Comparison: ARIMA vs LSTM vs SVM (error metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79948a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "GENERATING MODEL COMPARISONS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "S&P 500: COMPREHENSIVE MODEL COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š PERFORMANCE METRICS COMPARISON\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model             Type  Avg_RMSE  Avg_MAE    Avg_R2  Direction_Acc_%  Windows\n",
      "ARIMA      Statistical  0.011733 0.008303  1.000000        52.239941       16\n",
      " LSTM    Deep Learning  0.013100 0.009400 -0.129912        50.336185       16\n",
      "  SVM Machine Learning  0.014257 0.009877 -0.167879        49.468735       16\n",
      "\n",
      "ðŸ† BEST MODEL (Lowest RMSE): ARIMA with RMSE = 0.011733\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "BITCOIN: COMPREHENSIVE MODEL COMPARISON\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ“Š PERFORMANCE METRICS COMPARISON\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model             Type  Avg_RMSE  Avg_MAE    Avg_R2  Direction_Acc_%  Windows\n",
      "ARIMA      Statistical  0.037140 0.025308  1.000000        51.307880       11\n",
      " LSTM    Deep Learning  0.043729 0.032228 -0.267714        46.518385       11\n",
      "  SVM Machine Learning  0.044781 0.030897 -0.316306        42.488923       11\n",
      "\n",
      "ðŸ† BEST MODEL (Lowest RMSE): ARIMA with RMSE = 0.037140\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Comprehensive model comparison complete!\n",
      "âœ“ Use these results to select the best model for your specific use case\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“š SVM KERNEL THEORY SUMMARY (Cocco et al., 2021)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison: ARIMA vs LSTM vs SVM\n",
    "# Compare all three forecasting approaches\n",
    "\n",
    "def create_model_comparison_table(arima_results, lstm_results, svm_results, asset_name):\n",
    "    \"\"\"\n",
    "    Create comprehensive comparison of all three models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    arima_results : dict\n",
    "        ARIMA model results\n",
    "    lstm_results : dict\n",
    "        LSTM model results\n",
    "    svm_results : dict\n",
    "        SVM model results\n",
    "    asset_name : str\n",
    "        'S&P 500' or 'Bitcoin'\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{asset_name.upper()}: COMPREHENSIVE MODEL COMPARISON\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Model': ['ARIMA', 'LSTM', 'SVM'],\n",
    "        'Type': ['Statistical', 'Deep Learning', 'Machine Learning'],\n",
    "        'Avg_RMSE': [\n",
    "            arima_results['performance_summary']['avg_test_rmse'],\n",
    "            lstm_results['performance_summary']['avg_test_rmse'],\n",
    "            svm_results['performance_summary']['avg_test_rmse']\n",
    "        ],\n",
    "        'Avg_MAE': [\n",
    "            arima_results['summary_df']['Test_MAE'].mean() if 'Test_MAE' in arima_results['summary_df'].columns else np.nan,\n",
    "            lstm_results['performance_summary']['avg_test_mae'],\n",
    "            svm_results['performance_summary']['avg_test_mae']\n",
    "        ],\n",
    "        'Avg_R2': [\n",
    "            arima_results['performance_summary']['avg_r2'],\n",
    "            lstm_results['performance_summary']['avg_r2'],\n",
    "            svm_results['performance_summary']['avg_r2']\n",
    "        ],\n",
    "        'Direction_Acc_%': [\n",
    "            arima_results['performance_summary']['avg_direction_accuracy'],\n",
    "            lstm_results['performance_summary']['avg_direction_accuracy'],\n",
    "            svm_results['performance_summary']['avg_direction_accuracy']\n",
    "        ],\n",
    "        'Windows': [\n",
    "            arima_results['performance_summary']['successful_windows'],\n",
    "            lstm_results['performance_summary']['successful_windows'],\n",
    "            svm_results['performance_summary']['successful_windows']\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    print(\"\\nðŸ“Š PERFORMANCE METRICS COMPARISON\")\n",
    "    print(\"-\" * 100)\n",
    "    print(comparison_df.to_string(index=False, float_format='%.6f'))\n",
    "    \n",
    "    # Determine best model by RMSE\n",
    "    best_idx = comparison_df['Avg_RMSE'].idxmin()\n",
    "    best_model = comparison_df.loc[best_idx, 'Model']\n",
    "    best_rmse = comparison_df.loc[best_idx, 'Avg_RMSE']\n",
    "    \n",
    "    print(f\"\\nðŸ† BEST MODEL (Lowest RMSE): {best_model} with RMSE = {best_rmse:.6f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    models = comparison_df['Model']\n",
    "    \n",
    "    # Plot 1: RMSE Comparison\n",
    "    axes[0].bar(models, comparison_df['Avg_RMSE'], color=['blue', 'red', 'green'], alpha=0.7)\n",
    "    axes[0].set_title('Average Test RMSE')\n",
    "    axes[0].set_ylabel('RMSE')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Direction Accuracy Comparison\n",
    "    axes[1].bar(models, comparison_df['Direction_Acc_%'], color=['blue', 'red', 'green'], alpha=0.7)\n",
    "    axes[1].axhline(y=50, color='black', linestyle='--', label='Random (50%)')\n",
    "    axes[1].set_title('Direction Accuracy')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: RÂ² Score Comparison (All Models)\n",
    "    r2_models = ['ARIMA', 'LSTM', 'SVM']\n",
    "    r2_values = [\n",
    "        arima_results['performance_summary']['avg_r2'],\n",
    "        lstm_results['performance_summary']['avg_r2'],\n",
    "        svm_results['performance_summary']['avg_r2']\n",
    "    ]\n",
    "    axes[2].bar(r2_models, r2_values, color=['blue', 'red', 'green'], alpha=0.7)\n",
    "    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    axes[2].set_title('RÂ² Score (Coefficient of Determination)')\n",
    "    axes[2].set_ylabel('RÂ²')\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle(f'{asset_name}: Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return comparison_df, fig\n",
    "\n",
    "\n",
    "# Compare models for S&P 500\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"GENERATING MODEL COMPARISONS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "sp500_comparison, sp500_fig = create_model_comparison_table(\n",
    "    sp500_arima_results,\n",
    "    sp500_lstm_full,\n",
    "    sp500_svm_full,\n",
    "    'S&P 500'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Compare models for Bitcoin\n",
    "bitcoin_comparison, bitcoin_fig = create_model_comparison_table(\n",
    "    bitcoin_arima_results,\n",
    "    bitcoin_lstm_full,\n",
    "    bitcoin_svm_full,\n",
    "    'Bitcoin'\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nâœ“ Comprehensive model comparison complete!\")\n",
    "print(\"âœ“ Use these results to select the best model for your specific use case\")\n",
    "\n",
    "\n",
    "# Final Summary: Kernel Functions and Theoretical Foundation\n",
    "# Following Cocco et al. (2021)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"ðŸ“š SVM KERNEL THEORY SUMMARY (Cocco et al., 2021)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8f84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c74239",
   "metadata": {},
   "source": [
    "# Model Comparison: ARIMA vs LSTM vs SVM (performance indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73022ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# TRADING_DAYS = 252  # standard convention\n",
    "# RISK_FREE_RATE = 0.0  # set if you have T-bill data\n",
    "\n",
    "\n",
    "# def annualized_return(daily_returns):\n",
    "#     \"\"\"ARC: Annualized return.\"\"\"\n",
    "#     cumulative = (1 + daily_returns).prod()\n",
    "#     n = daily_returns.shape[0]\n",
    "#     return cumulative ** (TRADING_DAYS / n) - 1\n",
    "\n",
    "\n",
    "# def annualized_std(daily_returns):\n",
    "#     \"\"\"ASD: Annualized standard deviation.\"\"\"\n",
    "#     return daily_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "\n",
    "# def max_drawdown(daily_returns):\n",
    "#     \"\"\"MD: Maximum drawdown from equity curve.\"\"\"\n",
    "#     equity = (1 + daily_returns).cumprod()\n",
    "#     peak = equity.cummax()\n",
    "#     drawdown = (equity - peak) / peak\n",
    "#     return drawdown.min()  # negative value\n",
    "\n",
    "\n",
    "# def information_ratio(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"\n",
    "#     IR: Information ratio relative to benchmark.\n",
    "#     \"\"\"\n",
    "#     active_returns = strategy_returns - benchmark_returns\n",
    "#     tracking_error = active_returns.std()\n",
    "#     if tracking_error == 0:\n",
    "#         return np.nan\n",
    "#     return active_returns.mean() / tracking_error\n",
    "\n",
    "\n",
    "# def modified_information_ratio(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"\n",
    "#     IR*: Annualized Information Ratio (reduces autocorrelation issues).\n",
    "#     \"\"\"\n",
    "#     active_daily = strategy_returns - benchmark_returns\n",
    "\n",
    "#     # Annualized active return\n",
    "#     ann_active_return = annualized_return(active_daily)\n",
    "\n",
    "#     # Annualized tracking error\n",
    "#     ann_tracking_error = annualized_std(active_daily)\n",
    "\n",
    "#     if ann_tracking_error == 0:\n",
    "#         return np.nan\n",
    "#     return ann_active_return / ann_tracking_error\n",
    "\n",
    "\n",
    "# def sharpe_ratio(daily_returns, risk_free_rate=RISK_FREE_RATE):\n",
    "#     \"\"\"SR: Sharpe ratio.\"\"\"\n",
    "#     excess = daily_returns - (risk_free_rate / TRADING_DAYS)\n",
    "#     denom = daily_returns.std()\n",
    "#     if denom == 0:\n",
    "#         return np.nan\n",
    "#     return excess.mean() / denom * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "# def compute_performance_indicators(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"\n",
    "#     Compute ARC, ASD, MD, IR, IR*, SR for a model's trading strategy.\n",
    "#     \"\"\"\n",
    "\n",
    "#     return {\n",
    "#         \"ARC\": annualized_return(strategy_returns),\n",
    "#         \"ASD\": annualized_std(strategy_returns),\n",
    "#         \"MD\": max_drawdown(strategy_returns),  # will return negative drawdown\n",
    "#         \"IR\": information_ratio(strategy_returns, benchmark_returns),\n",
    "#         \"IR*\": modified_information_ratio(strategy_returns, benchmark_returns),\n",
    "#         \"SR\": sharpe_ratio(strategy_returns)\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16e5fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatility_predictions_to_returns(predictions, true_values, actual_returns):\n",
    "    \"\"\"\n",
    "    Convert volatility predictions into trading returns.\n",
    "    \n",
    "    Strategy: Go long when predicted volatility is below median (low risk),\n",
    "              go short when predicted volatility is above median (high risk).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : np.array\n",
    "        Predicted volatility values\n",
    "    true_values : np.array\n",
    "        Actual volatility values\n",
    "    actual_returns : pd.Series or np.array\n",
    "        Actual market returns aligned with predictions\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : Strategy returns based on volatility forecasts\n",
    "    \"\"\"\n",
    "    \n",
    "    # # Ensure we have the same length\n",
    "    # min_len = min(len(predictions), len(true_values), len(actual_returns))\n",
    "    # predictions = predictions[:min_len]\n",
    "    # true_values = true_values[:min_len]\n",
    "    # actual_returns = actual_returns[:min_len] if isinstance(actual_returns, np.ndarray) else actual_returns.iloc[:min_len]\n",
    "    \n",
    "    # # Calculate prediction median\n",
    "    # pred_median = np.median(predictions)\n",
    "    \n",
    "    # # Trading signal: +1 when low predicted volatility, -1 when high\n",
    "    # # Rationale: Low volatility â†’ favorable conditions â†’ go long\n",
    "    # #            High volatility â†’ unfavorable conditions â†’ go short or defensive\n",
    "    # signals = np.where(predictions < pred_median, 1, -1)\n",
    "    \n",
    "    # # Strategy returns = signal * actual_returns\n",
    "    # strategy_returns = signals * actual_returns\n",
    "    \n",
    "    # return pd.Series(strategy_returns)\n",
    "    \n",
    "    min_len = min(len(predictions), len(true_values), len(actual_returns))\n",
    "    predictions = predictions[:min_len]\n",
    "    true_values = true_values[:min_len]\n",
    "    actual_returns = (actual_returns.iloc[:min_len] \n",
    "                     if isinstance(actual_returns, pd.Series) \n",
    "                     else actual_returns[:min_len])\n",
    "    \n",
    "    # Convert to numpy arrays for consistency\n",
    "    actual_returns_array = (actual_returns.values \n",
    "                           if isinstance(actual_returns, pd.Series) \n",
    "                           else actual_returns)\n",
    "    \n",
    "    # Calculate median volatility as threshold\n",
    "    pred_median = np.median(predictions)\n",
    "    \n",
    "    # === SIGNAL GENERATION: -1, 1 STRUCTURE ===\n",
    "    # Base signals based on volatility threshold\n",
    "    # +1: Low volatility (predicted < median) â†’ Favorable for LONG positions\n",
    "    # -1: High volatility (predicted > median) â†’ Favorable for SHORT positions\n",
    "    signals = np.where(predictions < pred_median, 1, -1)\n",
    "    \n",
    "    # === STRATEGY RETURNS ===\n",
    "    # Returns = Signal Ã— Actual Returns\n",
    "    # +1 signal: captures full upside (goes long when low vol predicted)\n",
    "    # -1 signal: captures short side (goes short when high vol predicted)\n",
    "    strategy_returns = signals * actual_returns_array\n",
    "    \n",
    "    return pd.Series(strategy_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "647e8f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volatility_predictions_to_returns_new(predictions, true_values, actual_returns, transaction_costs=0.0):\n",
    "    \"\"\"\n",
    "    Convert volatility predictions into trading returns using -1, 0, 1 long-short signals.\n",
    "    \n",
    "    Implements sections 4.5 and 4.6 methodology from the paper.\n",
    "    \n",
    "    Strategy:\n",
    "    - Signal = +1 when predicted volatility < median (low risk, favorable to go LONG)\n",
    "    - Signal = -1 when predicted volatility > median (high risk, favorable to go SHORT)\n",
    "    - Signal = 0 when position should be neutral (within transaction cost threshold)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predictions : np.array\n",
    "        Predicted volatility values from model\n",
    "    true_values : np.array\n",
    "        Actual volatility values (for reference)\n",
    "    actual_returns : pd.Series or np.array\n",
    "        Actual market returns aligned with predictions\n",
    "    transaction_costs : float, optional\n",
    "        Transaction costs in decimal form (e.g., 0.005 = 0.5%)\n",
    "        Default: 0.0 (no transaction costs)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series : Strategy returns based on volatility forecasts with -1, 0, 1 signals\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> strategy_returns = volatility_predictions_to_returns(\n",
    "    ...     predictions=volatility_preds,\n",
    "    ...     true_values=actual_volatility,\n",
    "    ...     actual_returns=market_returns,\n",
    "    ...     transaction_costs=0.005\n",
    "    ... )\n",
    "    >>> metrics = compute_performance_indicators(strategy_returns, benchmark_returns)\n",
    "    \"\"\"\n",
    "    # Ensure all arrays have matching length\n",
    "    min_len = min(len(predictions), len(true_values), len(actual_returns))\n",
    "    predictions = predictions[:min_len]\n",
    "    true_values = true_values[:min_len]\n",
    "    actual_returns = (actual_returns.iloc[:min_len] \n",
    "                     if isinstance(actual_returns, pd.Series) \n",
    "                     else actual_returns[:min_len])\n",
    "    \n",
    "    # Convert to numpy arrays for consistency\n",
    "    actual_returns_array = (actual_returns.values \n",
    "                           if isinstance(actual_returns, pd.Series) \n",
    "                           else actual_returns)\n",
    "    \n",
    "    # Calculate median volatility as threshold\n",
    "    pred_median = np.median(predictions)\n",
    "    \n",
    "    # === SIGNAL GENERATION: -1, 0, 1 STRUCTURE ===\n",
    "    # Base signals based on volatility threshold\n",
    "    # +1: Low volatility (predicted < median) â†’ Favorable for LONG positions\n",
    "    # -1: High volatility (predicted > median) â†’ Favorable for SHORT positions\n",
    "    signals = np.where(predictions < pred_median, 1, -1)\n",
    "    \n",
    "    # Apply transaction cost filter\n",
    "    # Only trade if expected return magnitude exceeds transaction costs\n",
    "    # Otherwise, maintain neutral position (signal = 0)\n",
    "    if transaction_costs > 0.0:\n",
    "        signals = np.where(np.abs(actual_returns_array) > transaction_costs, signals, 0)\n",
    "    \n",
    "    # === STRATEGY RETURNS ===\n",
    "    # Returns = Signal Ã— Actual Returns\n",
    "    # +1 signal: captures full upside (goes long when low vol predicted)\n",
    "    # -1 signal: captures short side (goes short when high vol predicted)\n",
    "    # 0 signal: no position, zero return contribution\n",
    "    strategy_returns = signals * actual_returns_array\n",
    "    \n",
    "    return pd.Series(strategy_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "497cc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_returns_from_results_fixed(model_results, data_clean, model_type=\"S&P\", window_indices=None):\n",
    "    \"\"\"\n",
    "    Extract and aggregate returns from model cross-validation results.\n",
    "    FIXED VERSION: Handles different structures for ARIMA vs LSTM/SVM.\n",
    "    \"\"\"\n",
    "    if model_type == \"S&P\":\n",
    "        cost = 0.005\n",
    "    elif model_type == \"Bitcoin\":\n",
    "        cost = 0.01\n",
    "    all_strategy_returns = []\n",
    "    \n",
    "    windows_to_use = model_results['all_results']\n",
    "    if window_indices is not None:\n",
    "        windows_to_use = [w for w in windows_to_use if w['window_id'] in window_indices]\n",
    "    \n",
    "    for window_result in windows_to_use:\n",
    "        try:\n",
    "            # Get test period dates\n",
    "            test_start = window_result['test_period'].split(' to ')[0]\n",
    "            test_end = window_result['test_period'].split(' to ')[1]\n",
    "            \n",
    "            # Get actual returns during test period\n",
    "            test_data = data_clean[test_start:test_end]\n",
    "            \n",
    "            # Get predictions - handle different model structures\n",
    "            evaluation = window_result['evaluation']\n",
    "            \n",
    "            # ARIMA uses 'forecasts' (pandas Series), LSTM/SVM use 'predictions' (numpy arrays)\n",
    "            if 'forecasts' in evaluation:\n",
    "                # ARIMA model - predicts returns directly\n",
    "                predictions = evaluation['forecasts'].values\n",
    "                true_values = test_data['Log_Returns'].values[-len(predictions):]\n",
    "            elif 'predictions' in evaluation:\n",
    "                # LSTM or SVM model - predicts volatility\n",
    "                predictions = evaluation['predictions']\n",
    "                true_values = evaluation['true_values']\n",
    "            else:\n",
    "                print(f\"âš ï¸  Warning: Unknown evaluation structure for window {window_result['window_id']}\")\n",
    "                continue\n",
    "            \n",
    "            # Align returns with predictions\n",
    "            actual_returns = test_data['Log_Returns'].iloc[-len(predictions):]\n",
    "            \n",
    "            # Generate strategy returns for this window\n",
    "            # window_returns = volatility_predictions_to_returns(\n",
    "            #     predictions, true_values, actual_returns.values\n",
    "            # )\n",
    "            window_returns = volatility_predictions_to_returns_new(\n",
    "                predictions, true_values, actual_returns.values, transaction_costs= cost\n",
    "            )\n",
    "            \n",
    "            all_strategy_returns.append(window_returns)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Warning: Failed to process window {window_result.get('window_id', '?')}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Concatenate all returns\n",
    "    if all_strategy_returns:\n",
    "        return pd.concat(all_strategy_returns, ignore_index=True)\n",
    "    else:\n",
    "        return pd.Series([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "789b53db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  â€¢ Trading days per year: 252\n",
      "  â€¢ Risk-free rate: 0.0\n",
      "  â€¢ Transaction costs: {'sp500': 0.005, 'bitcoin': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "TRADING_DAYS = 252  # Standard convention for annual calculations\n",
    "RISK_FREE_RATE = 0.0  # Set to actual T-bill rate if available\n",
    "\n",
    "# Asset-specific transaction costs\n",
    "TRANSACTION_COSTS = {\n",
    "    'sp500': 0.005,      # 0.5% for S&P 500\n",
    "    'bitcoin': 0.01      # 1.0% for Bitcoin\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  â€¢ Trading days per year: {TRADING_DAYS}\")\n",
    "print(f\"  â€¢ Risk-free rate: {RISK_FREE_RATE}\")\n",
    "print(f\"  â€¢ Transaction costs: {TRANSACTION_COSTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a624581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Metric functions defined (ARC, ASD, MD, IR, IR*, SR)\n"
     ]
    }
   ],
   "source": [
    "def annualized_return(daily_returns):\n",
    "    \"\"\"ARC: Annualized return from daily returns.\"\"\"\n",
    "    cumulative = (1 + daily_returns).prod()\n",
    "    n = daily_returns.shape[0]\n",
    "    return cumulative ** (TRADING_DAYS / n) - 1\n",
    "\n",
    "\n",
    "def annualized_std(daily_returns):\n",
    "    \"\"\"ASD: Annualized standard deviation from daily returns.\"\"\"\n",
    "    return daily_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "\n",
    "def max_drawdown(daily_returns):\n",
    "    \"\"\"MD: Maximum drawdown from equity curve (Eq 24).\"\"\"\n",
    "    equity = (1 + daily_returns).cumprod()\n",
    "    peak = equity.cummax()\n",
    "    drawdown = (equity - peak) / peak\n",
    "    return np.abs(drawdown.min())  # Paper uses absolute value\n",
    "\n",
    "\n",
    "def information_ratio(strategy_returns, benchmark_returns):\n",
    "    \"\"\"IR: Information ratio (Paper definition: Eq 25).\"\"\"\n",
    "    # Paper defines IR = ARC / ASD\n",
    "    # It does NOT use benchmark tracking error\n",
    "    arc = annualized_return(strategy_returns)\n",
    "    asd = annualized_std(strategy_returns)\n",
    "    \n",
    "    if asd == 0:\n",
    "        return np.nan\n",
    "    return arc / asd\n",
    "\n",
    "\n",
    "def modified_information_ratio(strategy_returns, benchmark_returns):\n",
    "    \"\"\"IR*: Adjusted Information Ratio (Paper definition: Eq 26).\"\"\"\n",
    "    # Paper defines IR* = (ARC^2 * sign(ARC)) / (ASD * MD)\n",
    "    # Simplified: IR * (ARC / MD)\n",
    "    arc = annualized_return(strategy_returns)\n",
    "    asd = annualized_std(strategy_returns)\n",
    "    md = max_drawdown(strategy_returns)\n",
    "    \n",
    "    if asd == 0 or md == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    return (arc * np.sign(arc) * arc) / (asd * md)\n",
    "\n",
    "\n",
    "def sortino_ratio(daily_returns, risk_free_rate=0):\n",
    "    \"\"\"SR: Sortino Ratio (Paper definition: Eq 27).\"\"\"\n",
    "    # Paper defines SR = ARC / Downside Deviation\n",
    "    # Paper does NOT subtract risk_free_rate from ARC\n",
    "    \n",
    "    # Identify negative returns\n",
    "    negative_returns = daily_returns[daily_returns < 0]\n",
    "    \n",
    "    if len(negative_returns) == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    # Calculate downside deviation (annualized)\n",
    "    downside_std = np.std(negative_returns, ddof=1)\n",
    "    asd_downside = downside_std * np.sqrt(TRADING_DAYS)\n",
    "    \n",
    "    arc = annualized_return(daily_returns)\n",
    "    \n",
    "    if asd_downside == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    return arc / asd_downside\n",
    "\n",
    "\n",
    "def compute_performance_indicators(strategy_returns, benchmark_returns):\n",
    "    \"\"\"Compute all 6 metrics at once.\"\"\"\n",
    "    return {\n",
    "        \"ARC\": annualized_return(strategy_returns),\n",
    "        \"ASD\": annualized_std(strategy_returns),\n",
    "        \"MD\": abs(max_drawdown(strategy_returns)),\n",
    "        \"IR\": information_ratio(strategy_returns, benchmark_returns),\n",
    "        \"IR*\": modified_information_ratio(strategy_returns, benchmark_returns),\n",
    "        \"SR\": sortino_ratio(strategy_returns)\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def annualized_return(daily_returns):\n",
    "#     \"\"\"ARC: Annualized return from daily returns (Eq 22).\"\"\"\n",
    "#     if isinstance(daily_returns, pd.Series):\n",
    "#         daily_returns = daily_returns.values\n",
    "    \n",
    "#     # NOTE: If ARC is negative, your strategy lost money\n",
    "#     # This is CORRECT - don't artificially make it positive\n",
    "#     cumulative = np.prod(1 + daily_returns)\n",
    "#     n = len(daily_returns)\n",
    "#     arc = (cumulative ** (TRADING_DAYS / n)) - 1\n",
    "#     return arc\n",
    "\n",
    "\n",
    "# def annualized_std(daily_returns):\n",
    "#     \"\"\"ASD: Annualized standard deviation from daily returns (Eq 23).\"\"\"\n",
    "#     if isinstance(daily_returns, pd.Series):\n",
    "#         daily_returns = daily_returns.values\n",
    "#     return np.std(daily_returns, ddof=1) * np.sqrt(TRADING_DAYS)\n",
    "\n",
    "\n",
    "# def max_drawdown(daily_returns):\n",
    "#     \"\"\"MD: Maximum drawdown from equity curve (Eq 24).\"\"\"\n",
    "#     if isinstance(daily_returns, pd.Series):\n",
    "#         daily_returns = daily_returns.values\n",
    "    \n",
    "#     equity = np.cumprod(1 + daily_returns)\n",
    "#     peak = np.maximum.accumulate(equity)\n",
    "#     drawdown = (equity - peak) / peak\n",
    "#     return np.abs(np.min(drawdown))\n",
    "\n",
    "\n",
    "# def information_ratio(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"IR: Information ratio (Paper definition: Eq 25) - Raw value, NO % conversion.\"\"\"\n",
    "#     if isinstance(strategy_returns, pd.Series):\n",
    "#         strategy_returns = strategy_returns.values\n",
    "    \n",
    "#     arc = annualized_return(strategy_returns)\n",
    "#     asd = annualized_std(strategy_returns)\n",
    "    \n",
    "#     if asd == 0:\n",
    "#         return np.nan\n",
    "#     return arc / asd\n",
    "\n",
    "\n",
    "# def modified_information_ratio(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"IR*: Adjusted Information Ratio (Paper definition: Eq 26) - Raw value, NO % conversion.\"\"\"\n",
    "#     if isinstance(strategy_returns, pd.Series):\n",
    "#         strategy_returns = strategy_returns.values\n",
    "    \n",
    "#     arc = annualized_return(strategy_returns)\n",
    "#     asd = annualized_std(strategy_returns)\n",
    "#     md = max_drawdown(strategy_returns)\n",
    "    \n",
    "#     if asd == 0 or md == 0:\n",
    "#         return np.nan\n",
    "        \n",
    "#     return (arc * np.sign(arc) * arc) / (asd * md)\n",
    "\n",
    "\n",
    "# def sortino_ratio(daily_returns, risk_free_rate=0):\n",
    "#     \"\"\"SR: Sortino Ratio (Paper definition: Eq 27) - Raw value, NO % conversion.\"\"\"\n",
    "#     if isinstance(daily_returns, pd.Series):\n",
    "#         daily_returns = daily_returns.values\n",
    "    \n",
    "#     # Identify negative returns\n",
    "#     negative_returns = daily_returns[daily_returns < 0]\n",
    "    \n",
    "#     if len(negative_returns) == 0:\n",
    "#         return np.nan\n",
    "        \n",
    "#     # Calculate downside deviation (annualized)\n",
    "#     downside_std = np.std(negative_returns, ddof=1)\n",
    "#     asd_downside = downside_std * np.sqrt(TRADING_DAYS)\n",
    "    \n",
    "#     arc = annualized_return(daily_returns)\n",
    "    \n",
    "#     if asd_downside == 0:\n",
    "#         return np.nan\n",
    "        \n",
    "#     return arc / asd_downside\n",
    "\n",
    "\n",
    "# def compute_performance_indicators(strategy_returns, benchmark_returns):\n",
    "#     \"\"\"\n",
    "#     Compute all 6 metrics at once (Paper Methodology).\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     dict with keys: ARC, ASD, MD, IR, IR*, SR\n",
    "#     - ARC, ASD, MD are stored as decimals (to be formatted as % later)\n",
    "#     - IR, IR*, SR are stored as raw decimal values\n",
    "#     \"\"\"\n",
    "    \n",
    "#     arc = annualized_return(strategy_returns)\n",
    "#     asd = annualized_std(strategy_returns)\n",
    "#     md = max_drawdown(strategy_returns)\n",
    "#     ir = information_ratio(strategy_returns, benchmark_returns)\n",
    "#     ir_star = modified_information_ratio(strategy_returns, benchmark_returns)\n",
    "#     sr = sortino_ratio(strategy_returns)\n",
    "    \n",
    "#     return {\n",
    "#         \"ARC\": arc,\n",
    "#         \"ASD\": asd,\n",
    "#         \"MD\": md,\n",
    "#         \"IR\": ir,\n",
    "#         \"IR*\": ir_star,\n",
    "#         \"SR\": sr\n",
    "#     }\n",
    "\n",
    "print(\"âœ“ Metric functions defined (ARC, ASD, MD, IR, IR*, SR)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "237968e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S&P 500 Data Check:\n",
      "  â€¢ sp500_clean shape: (5536, 6)\n",
      "  â€¢ sp500_clean columns: [('Adj Close', '^GSPC'), ('High', '^GSPC'), ('Low', '^GSPC'), ('Open', '^GSPC'), ('Volume', '^GSPC'), ('Log_Returns', '')]\n",
      "  â€¢ Has 'Log_Returns': True\n",
      "  â€¢ BNH returns shape: (5536,)\n",
      "  â€¢ BNH mean return: 0.000256\n",
      "  â€¢ BNH std return: 0.012244\n",
      "\n",
      "âœ“ Data loaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Verify data is loaded\n",
    "print(\"S&P 500 Data Check:\")\n",
    "print(f\"  â€¢ sp500_clean shape: {sp500_clean.shape}\")\n",
    "print(f\"  â€¢ sp500_clean columns: {list(sp500_clean.columns)}\")\n",
    "print(f\"  â€¢ Has 'Log_Returns': {'Log_Returns' in sp500_clean.columns}\")\n",
    "\n",
    "# Get benchmark\n",
    "sp500_bnh_returns = sp500_clean['Log_Returns'].values\n",
    "print(f\"  â€¢ BNH returns shape: {sp500_bnh_returns.shape}\")\n",
    "print(f\"  â€¢ BNH mean return: {sp500_bnh_returns.mean():.6f}\")\n",
    "print(f\"  â€¢ BNH std return: {sp500_bnh_returns.std():.6f}\")\n",
    "\n",
    "print(\"\\nâœ“ Data loaded and verified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d77718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting S&P 500 model returns...\n",
      "\n",
      "  â€¢ Processing ARIMA predictions...\n",
      "    â†’ Shape: (4028,)\n",
      "    â†’ Mean: -0.000199\n",
      "\n",
      "  â€¢ Processing LSTM predictions...\n",
      "    â†’ Shape: (3580,)\n",
      "    â†’ Mean: -0.000475\n",
      "\n",
      "  â€¢ Processing SVM predictions...\n",
      "    â†’ Shape: (3580,)\n",
      "    â†’ Mean: -0.000440\n",
      "\n",
      "âœ“ All S&P 500 model returns extracted\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting S&P 500 model returns...\\n\")\n",
    "\n",
    "print(\"  â€¢ Processing ARIMA predictions...\")\n",
    "sp500_arima_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_arima_results, sp500_clean, \"S&P\"\n",
    ")\n",
    "print(f\"    â†’ Shape: {sp500_arima_returns.shape}\")\n",
    "print(f\"    â†’ Mean: {sp500_arima_returns.mean():.6f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Processing LSTM predictions...\")\n",
    "sp500_lstm_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_lstm_full, sp500_clean, \"S&P\"\n",
    ")\n",
    "print(f\"    â†’ Shape: {sp500_lstm_returns.shape}\")\n",
    "print(f\"    â†’ Mean: {sp500_lstm_returns.mean():.6f}\")\n",
    "\n",
    "print(\"\\n  â€¢ Processing SVM predictions...\")\n",
    "sp500_svm_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_svm_full, sp500_clean, \"S&P\"\n",
    ")\n",
    "print(f\"    â†’ Shape: {sp500_svm_returns.shape}\")\n",
    "print(f\"    â†’ Mean: {sp500_svm_returns.mean():.6f}\")\n",
    "\n",
    "print(\"\\nâœ“ All S&P 500 model returns extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e0c2f2",
   "metadata": {},
   "source": [
    "## S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "097452a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asset_name': 'S&P 500',\n",
       " 'all_results': [{'window_id': 1,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2002-01-03 to 2005-01-02',\n",
       "   'test_period': '2007-01-03 to 2008-01-02',\n",
       "   'train_size': 755,\n",
       "   'test_size': 252,\n",
       "   'best_order': (0, 0, 1),\n",
       "   'model_selection': {'best_order': (0, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516041a0>,\n",
       "    'best_ic_value': np.float64(-4531.000985726117),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -4531.000986 -4517.120832 -4525.654328  2268.500493      False\n",
       "    1   (0, 0, 2) -4528.999742 -4510.492871 -4521.870865  2268.499871       True\n",
       "    2   (0, 0, 3) -4527.283066 -4504.149478 -4518.371970  2268.641533       True\n",
       "    3   (0, 1, 0) -3968.306035 -3963.680642 -3966.524215  1985.153017       True\n",
       "    4   (0, 1, 1) -4517.905978 -4508.655193 -4514.342340  2260.952989       True\n",
       "    5   (0, 1, 2) -4517.744187 -4503.868010 -4512.398729  2261.872093       True\n",
       "    6   (0, 1, 3) -4515.758244 -4497.256674 -4508.630967  2261.879122       True\n",
       "    7   (1, 0, 0) -4530.997463 -4517.117310 -4525.650805  2268.498731       True\n",
       "    8   (1, 0, 1) -4528.999519 -4510.492648 -4521.870642  2268.499760      False\n",
       "    9   (1, 0, 2) -4527.016800 -4503.883212 -4518.105704  2268.508400       True\n",
       "    10  (1, 0, 3) -4525.183948 -4497.423641 -4514.490632  2268.591974       True\n",
       "    11  (1, 1, 0) -4207.561769 -4198.310984 -4203.998131  2105.780885       True\n",
       "    12  (1, 1, 1) -4517.741703 -4503.865526 -4512.396246  2261.870852       True\n",
       "    13  (1, 1, 2) -4517.393907 -4498.892337 -4510.266630  2262.696953       True\n",
       "    14  (1, 1, 3) -4515.778688 -4492.651726 -4506.869592  2262.889344      False\n",
       "    15  (2, 0, 0) -4528.998482 -4510.491611 -4521.869605  2268.499241       True\n",
       "    16  (2, 0, 1) -4526.998592 -4503.865003 -4518.087496  2268.499296       True\n",
       "    17  (2, 0, 2) -4524.997041 -4497.236735 -4514.303726  2268.498521       True\n",
       "    18  (2, 0, 3) -4523.182494 -4490.795469 -4510.706959  2268.591247       True\n",
       "    19  (2, 1, 0) -4294.070759 -4280.194582 -4288.725301  2150.035379       True\n",
       "    20  (2, 1, 1) -4515.749466 -4497.247896 -4508.622189  2261.874733      False\n",
       "    21  (2, 1, 2) -4515.659086 -4492.532124 -4506.749990  2262.829543       True\n",
       "    22  (2, 1, 3) -4511.115864 -4483.363510 -4500.424949  2261.557932       True\n",
       "    23  (3, 0, 0) -4527.212438 -4504.078849 -4518.301342  2268.606219       True\n",
       "    24  (3, 0, 1) -4525.226785 -4497.466479 -4514.533470  2268.613393       True\n",
       "    25  (3, 0, 2) -4523.225628 -4490.838603 -4510.750093  2268.612814       True\n",
       "    26  (3, 0, 3) -4521.240848 -4484.227106 -4506.983094  2268.620424       True\n",
       "    27  (3, 1, 0) -4338.803427 -4320.301857 -4331.676150  2173.401713       True\n",
       "    28  (3, 1, 1) -4506.125643 -4482.998681 -4497.216547  2258.062822      False\n",
       "    29  (3, 1, 2) -4513.686100 -4485.933746 -4502.995185  2262.843050       True\n",
       "    30  (3, 1, 3) -4510.006515 -4477.628768 -4497.533780  2262.003257      False,\n",
       "    'successful_fits': 25,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 80.64516129032258},\n",
       "   'validation_scores': [np.float64(0.0064632937552913435),\n",
       "    np.float64(0.006309317665816522),\n",
       "    np.float64(0.006389684860913499)],\n",
       "   'avg_validation_rmse': np.float64(0.006387432094007121),\n",
       "   'evaluation': {'model_order': (0, 0, 1),\n",
       "    'forecasts': 755     0.000129\n",
       "    756     0.000061\n",
       "    757     0.000061\n",
       "    758     0.000061\n",
       "    759     0.000061\n",
       "              ...   \n",
       "    1002    0.000061\n",
       "    1003    0.000061\n",
       "    1004    0.000061\n",
       "    1005    0.000061\n",
       "    1006    0.000061\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    755           -0.023363           0.023621\n",
       "    756           -0.023459           0.023581\n",
       "    757           -0.023459           0.023581\n",
       "    758           -0.023459           0.023581\n",
       "    759           -0.023459           0.023581\n",
       "    ...                 ...                ...\n",
       "    1002          -0.023459           0.023581\n",
       "    1003          -0.023459           0.023581\n",
       "    1004          -0.023459           0.023581\n",
       "    1005          -0.023459           0.023581\n",
       "    1006          -0.023459           0.023581\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00010190442995133982,\n",
       "     'rmse': np.float64(0.010094772407109525),\n",
       "     'mae': 0.00721471449383421,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(54.581673306772906)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(9.881159245069316),\n",
       "     'ljung_box_pvalue': np.float64(0.4509808259306125),\n",
       "     'jarque_bera_stat': np.float64(135.02946180917988),\n",
       "     'jarque_bera_pvalue': np.float64(4.772269057696577e-30),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2002-01-03    0.009077\n",
       "    2002-01-04    0.006573\n",
       "    2002-01-07   -0.006262\n",
       "    2002-01-08   -0.003960\n",
       "    2002-01-09   -0.005064\n",
       "                    ...   \n",
       "    2004-12-27   -0.004347\n",
       "    2004-12-28    0.006856\n",
       "    2004-12-29    0.000198\n",
       "    2004-12-30    0.000031\n",
       "    2004-12-31   -0.001404\n",
       "    Length: 755, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259515db150>},\n",
       "  {'window_id': 2,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2003-01-03 to 2006-01-02',\n",
       "   'test_period': '2008-01-03 to 2009-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 253,\n",
       "   'best_order': (0, 0, 1),\n",
       "   'model_selection': {'best_order': (0, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595163e350>,\n",
       "    'best_ic_value': np.float64(-5169.6912836692845),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5169.691284 -5155.763823 -5164.330365  2587.845642       True\n",
       "    1   (0, 0, 2) -5167.651680 -5149.081733 -5160.503788  2587.825840      False\n",
       "    2   (0, 0, 3) -5165.623842 -5142.411408 -5156.688978  2587.811921       True\n",
       "    3   (0, 1, 0) -4563.456460 -4558.815278 -4561.669880  2282.728230      False\n",
       "    4   (0, 1, 1) -5076.341452 -5067.059087 -5072.768292  2540.170726       True\n",
       "    5   (0, 1, 2) -5088.058810 -5074.135264 -5082.699070  2547.029405      False\n",
       "    6   (0, 1, 3) -5103.903084 -5085.338355 -5096.756764  2555.951542       True\n",
       "    7   (1, 0, 0) -5169.585156 -5155.657695 -5164.224237  2587.792578       True\n",
       "    8   (1, 0, 1) -5167.678739 -5149.108792 -5160.530848  2587.839370      False\n",
       "    9   (1, 0, 2) -5165.675278 -5142.462844 -5156.740414  2587.837639       True\n",
       "    10  (1, 0, 3) -5163.671502 -5135.816581 -5152.949665  2587.835751      False\n",
       "    11  (1, 1, 0) -4824.641878 -4815.359514 -4821.068719  2414.320939       True\n",
       "    12  (1, 1, 1) -5154.902086 -5140.978540 -5149.542347  2580.451043       True\n",
       "    13  (1, 1, 2) -5094.466020 -5075.901291 -5087.319700  2551.233010       True\n",
       "    14  (1, 1, 3) -5157.568975 -5134.363064 -5148.636075  2583.784488      False\n",
       "    15  (2, 0, 0) -5167.693105 -5149.123158 -5160.545214  2587.846553       True\n",
       "    16  (2, 0, 1) -5165.673887 -5142.461453 -5156.739022  2587.836943      False\n",
       "    17  (2, 0, 2) -5163.690060 -5135.835139 -5152.968223  2587.845030      False\n",
       "    18  (2, 0, 3) -5161.701485 -5129.204077 -5149.192675  2587.850742       True\n",
       "    19  (2, 1, 0) -4925.932882 -4912.009336 -4920.573142  2465.966441       True\n",
       "    20  (2, 1, 1) -5152.937708 -5134.372980 -5145.791388  2580.468854      False\n",
       "    21  (2, 1, 2) -5157.350165 -5134.144254 -5148.417265  2583.675082      False\n",
       "    22  (2, 1, 3) -5145.957762 -5118.110669 -5135.238282  2578.978881      False\n",
       "    23  (3, 0, 0) -5165.681800 -5142.469366 -5156.746936  2587.840900       True\n",
       "    24  (3, 0, 1) -5163.676909 -5135.821989 -5152.955072  2587.838455       True\n",
       "    25  (3, 0, 2) -5161.691371 -5129.193963 -5149.182561  2587.845685      False\n",
       "    26  (3, 0, 3) -5159.704499 -5122.564605 -5145.408717  2587.852250       True\n",
       "    27  (3, 1, 0) -4989.653891 -4971.089162 -4982.507571  2498.826945       True\n",
       "    28  (3, 1, 1) -5149.632897 -5126.426986 -5140.699997  2579.816449      False\n",
       "    29  (3, 1, 2) -5156.886560 -5129.039467 -5146.167080  2584.443280      False\n",
       "    30  (3, 1, 3) -5151.865603 -5119.377328 -5139.359543  2582.932802      False,\n",
       "    'successful_fits': 16,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 51.61290322580645},\n",
       "   'validation_scores': [np.float64(0.0069270944294433714),\n",
       "    np.float64(0.006495438002559856),\n",
       "    np.float64(0.008418708516953198)],\n",
       "   'avg_validation_rmse': np.float64(0.0072804136496521414),\n",
       "   'evaluation': {'model_order': (0, 0, 1),\n",
       "    'forecasts': 767     0.000966\n",
       "    768     0.000437\n",
       "    769     0.000437\n",
       "    770     0.000437\n",
       "    771     0.000437\n",
       "              ...   \n",
       "    1015    0.000437\n",
       "    1016    0.000437\n",
       "    1017    0.000437\n",
       "    1018    0.000437\n",
       "    1019    0.000437\n",
       "    Name: predicted_mean, Length: 253, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.015275           0.017207\n",
       "    768           -0.015874           0.016749\n",
       "    769           -0.015874           0.016749\n",
       "    770           -0.015874           0.016749\n",
       "    771           -0.015874           0.016749\n",
       "    ...                 ...                ...\n",
       "    1015          -0.015874           0.016749\n",
       "    1016          -0.015874           0.016749\n",
       "    1017          -0.015874           0.016749\n",
       "    1018          -0.015874           0.016749\n",
       "    1019          -0.015874           0.016749\n",
       "    \n",
       "    [253 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.0006734668239352439,\n",
       "     'rmse': np.float64(0.025951239352586686),\n",
       "     'mae': 0.01748638572195571,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(50.39682539682539)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(12.670318044274149),\n",
       "     'ljung_box_pvalue': np.float64(0.24269317882716396),\n",
       "     'jarque_bera_stat': np.float64(55.28625077973354),\n",
       "     'jarque_bera_pvalue': np.float64(9.879686881046758e-13),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2002-12-16    0.022810\n",
       "    2002-12-17   -0.006496\n",
       "    2002-12-18   -0.014277\n",
       "    2002-12-19   -0.009511\n",
       "    2002-12-20    0.011606\n",
       "                    ...   \n",
       "    2005-12-23    0.000358\n",
       "    2005-12-27   -0.010003\n",
       "    2005-12-28   -0.000076\n",
       "    2005-12-29   -0.003429\n",
       "    2005-12-30   -0.005657\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595163d350>},\n",
       "  {'window_id': 3,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2004-01-03 to 2007-01-02',\n",
       "   'test_period': '2009-01-03 to 2010-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 251,\n",
       "   'best_order': (0, 0, 2),\n",
       "   'model_selection': {'best_order': (0, 0, 2),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259515ef0d0>,\n",
       "    'best_ic_value': np.float64(-5528.972653339179),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5526.087531 -5512.160071 -5520.726613  2766.043765       True\n",
       "    1   (0, 0, 2) -5528.972653 -5510.402706 -5521.824762  2768.486327      False\n",
       "    2   (0, 0, 3) -5527.127078 -5503.914644 -5518.192213  2768.563539       True\n",
       "    3   (0, 1, 0) -4968.429095 -4963.787913 -4966.642515  2485.214548       True\n",
       "    4   (0, 1, 1) -5512.202030 -5502.919666 -5508.628870  2758.101015       True\n",
       "    5   (0, 1, 2) -5510.937896 -5497.014350 -5505.578156  2758.468948       True\n",
       "    6   (0, 1, 3) -5462.799427 -5444.234699 -5455.653107  2735.399714       True\n",
       "    7   (1, 0, 0) -5525.978196 -5512.050736 -5520.617278  2765.989098       True\n",
       "    8   (1, 0, 1) -5524.731568 -5506.161621 -5517.583676  2766.365784       True\n",
       "    9   (1, 0, 2) -5527.353448 -5504.141014 -5518.418584  2768.676724       True\n",
       "    10  (1, 0, 3) -5525.578530 -5497.723610 -5514.856693  2768.789265       True\n",
       "    11  (1, 1, 0) -5163.242087 -5153.959723 -5159.668927  2583.621044       True\n",
       "    12  (1, 1, 1) -5510.819556 -5496.896010 -5505.459816  2758.409778      False\n",
       "    13  (1, 1, 2) -5491.539097 -5472.974368 -5484.392777  2749.769548       True\n",
       "    14  (1, 1, 3) -5466.722007 -5443.516096 -5457.789107  2738.361003       True\n",
       "    15  (2, 0, 0) -5528.752667 -5510.182720 -5521.604776  2768.376333       True\n",
       "    16  (2, 0, 1) -5526.870364 -5503.657930 -5517.935500  2768.435182       True\n",
       "    17  (2, 0, 2) -5526.209121 -5498.354200 -5515.487284  2769.104561       True\n",
       "    18  (2, 0, 3) -5524.221842 -5491.724434 -5511.713032  2769.110921       True\n",
       "    19  (2, 1, 0) -5281.408411 -5267.484864 -5276.048671  2643.704205       True\n",
       "    20  (2, 1, 1) -5513.459857 -5494.895128 -5506.313537  2760.729928      False\n",
       "    21  (2, 1, 2) -5455.770946 -5432.565035 -5446.838046  2732.885473       True\n",
       "    22  (2, 1, 3) -5499.039594 -5471.192501 -5488.320114  2755.519797       True\n",
       "    23  (3, 0, 0) -5526.814854 -5503.602420 -5517.879990  2768.407427       True\n",
       "    24  (3, 0, 1) -5524.807513 -5496.952592 -5514.085676  2768.403756       True\n",
       "    25  (3, 0, 2) -5524.200372 -5491.702965 -5511.691563  2769.100186       True\n",
       "    26  (3, 0, 3) -5522.208970 -5485.069076 -5507.913188  2769.104485       True\n",
       "    27  (3, 1, 0) -5326.840558 -5308.275829 -5319.694238  2667.420279      False\n",
       "    28  (3, 1, 1) -5504.967558 -5481.761647 -5496.034658  2757.483779      False\n",
       "    29  (3, 1, 2) -5509.200443 -5481.353350 -5498.480963  2760.600222      False\n",
       "    30  (3, 1, 3) -5459.251017 -5426.762742 -5446.744957  2736.625509       True,\n",
       "    'successful_fits': 25,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 80.64516129032258},\n",
       "   'validation_scores': [np.float64(0.009099467504556716),\n",
       "    np.float64(0.011321157997732863),\n",
       "    np.float64(0.01970085390051397)],\n",
       "   'avg_validation_rmse': np.float64(0.013373826467601184),\n",
       "   'evaluation': {'model_order': (0, 0, 2),\n",
       "    'forecasts': 767     0.000604\n",
       "    768     0.000732\n",
       "    769     0.000360\n",
       "    770     0.000360\n",
       "    771     0.000360\n",
       "              ...   \n",
       "    1013    0.000360\n",
       "    1014    0.000360\n",
       "    1015    0.000360\n",
       "    1016    0.000360\n",
       "    1017    0.000360\n",
       "    Name: predicted_mean, Length: 251, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.012224           0.013433\n",
       "    768           -0.012103           0.013566\n",
       "    769           -0.012520           0.013240\n",
       "    770           -0.012520           0.013240\n",
       "    771           -0.012520           0.013240\n",
       "    ...                 ...                ...\n",
       "    1013          -0.012520           0.013240\n",
       "    1014          -0.012520           0.013240\n",
       "    1015          -0.012520           0.013240\n",
       "    1016          -0.012520           0.013240\n",
       "    1017          -0.012520           0.013240\n",
       "    \n",
       "    [251 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00029146005309641014,\n",
       "     'rmse': np.float64(0.01707220117900472),\n",
       "     'mae': 0.012247354467930634,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(55.60000000000001)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(5.135000114273956),\n",
       "     'ljung_box_pvalue': np.float64(0.8819792321639176),\n",
       "     'jarque_bera_stat': np.float64(2.8715479533731525),\n",
       "     'jarque_bera_pvalue': np.float64(0.23793113957613082),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2003-12-15   -0.006055\n",
       "    2003-12-16    0.006095\n",
       "    2003-12-17    0.000564\n",
       "    2003-12-18    0.011897\n",
       "    2003-12-19   -0.000440\n",
       "                    ...   \n",
       "    2006-12-22   -0.005973\n",
       "    2006-12-26    0.003474\n",
       "    2006-12-27    0.006228\n",
       "    2006-12-28   -0.001363\n",
       "    2006-12-29   -0.004397\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595163f2d0>},\n",
       "  {'window_id': 4,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2005-01-03 to 2008-01-02',\n",
       "   'test_period': '2010-01-03 to 2011-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (0, 0, 1),\n",
       "   'model_selection': {'best_order': (0, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595166efd0>,\n",
       "    'best_ic_value': np.float64(-5285.4470569626355),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5285.447057 -5271.515688 -5280.084962  2645.723528       True\n",
       "    1   (0, 0, 2) -5284.192977 -5265.617818 -5277.043517  2646.096489       True\n",
       "    2   (0, 0, 3) -5282.586874 -5259.367925 -5273.650049  2646.293437       True\n",
       "    3   (0, 1, 0) -4657.889230 -4653.246744 -4656.102258  2329.944615      False\n",
       "    4   (0, 1, 1) -5261.882485 -5252.597511 -5258.308539  2632.941242       True\n",
       "    5   (0, 1, 2) -5270.566159 -5256.638699 -5265.205241  2638.283080       True\n",
       "    6   (0, 1, 3) -5205.273149 -5186.703202 -5198.125258  2606.636575       True\n",
       "    7   (1, 0, 0) -5284.615351 -5270.683981 -5279.253255  2645.307675       True\n",
       "    8   (1, 0, 1) -5283.979152 -5265.403993 -5276.829691  2645.989576      False\n",
       "    9   (1, 0, 2) -5283.196738 -5259.977790 -5274.259913  2646.598369       True\n",
       "    10  (1, 0, 3) -5279.515909 -5251.653171 -5268.791719  2645.757955       True\n",
       "    11  (1, 1, 0) -4914.997457 -4905.712484 -4911.423512  2459.498729       True\n",
       "    12  (1, 1, 1) -5269.758419 -5255.830959 -5264.397501  2637.879209      False\n",
       "    13  (1, 1, 2) -5258.065675 -5239.495728 -5250.917784  2633.032837      False\n",
       "    14  (1, 1, 3) -5202.098489 -5178.886055 -5193.163624  2606.049244       True\n",
       "    15  (2, 0, 0) -5284.461335 -5265.886176 -5277.311875  2646.230668       True\n",
       "    16  (2, 0, 1) -5283.905764 -5260.686815 -5274.968938  2646.952882       True\n",
       "    17  (2, 0, 2) -5281.156397 -5253.293659 -5270.432207  2646.578199       True\n",
       "    18  (2, 0, 3) -5278.795206 -5246.288678 -5266.283650  2646.397603       True\n",
       "    19  (2, 1, 0) -5044.776666 -5030.849206 -5039.415748  2525.388333       True\n",
       "    20  (2, 1, 1) -5269.035681 -5250.465734 -5261.887790  2638.517840      False\n",
       "    21  (2, 1, 2) -5266.669896 -5243.457462 -5257.735031  2638.334948       True\n",
       "    22  (2, 1, 3) -5250.785761 -5222.930840 -5240.063924  2631.392880       True\n",
       "    23  (3, 0, 0) -5283.088279 -5259.869331 -5274.151454  2646.544140       True\n",
       "    24  (3, 0, 1) -5280.966876 -5253.104137 -5270.242685  2646.483438       True\n",
       "    25  (3, 0, 2) -5279.017308 -5246.510780 -5266.505753  2646.508654       True\n",
       "    26  (3, 0, 3) -5276.918767 -5239.768449 -5262.619846  2646.459383       True\n",
       "    27  (3, 1, 0) -5085.830382 -5067.260435 -5078.682491  2546.915191       True\n",
       "    28  (3, 1, 1) -5268.051591 -5244.839157 -5259.116727  2639.025795      False\n",
       "    29  (3, 1, 2) -5263.752089 -5235.897168 -5253.030252  2637.876045      False\n",
       "    30  (3, 1, 3) -5261.530699 -5229.033292 -5249.021889  2637.765350      False,\n",
       "    'successful_fits': 23,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 74.19354838709677},\n",
       "   'validation_scores': [np.float64(0.013397862835355124),\n",
       "    np.float64(0.025568945906449574),\n",
       "    np.float64(0.02197447182797794)],\n",
       "   'avg_validation_rmse': np.float64(0.020313760189927546),\n",
       "   'evaluation': {'model_order': (0, 0, 1),\n",
       "    'forecasts': 768     0.002103\n",
       "    769     0.000243\n",
       "    770     0.000243\n",
       "    771     0.000243\n",
       "    772     0.000243\n",
       "              ...   \n",
       "    1015    0.000243\n",
       "    1016    0.000243\n",
       "    1017    0.000243\n",
       "    1018    0.000243\n",
       "    1019    0.000243\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.013022           0.017229\n",
       "    769           -0.014989           0.015476\n",
       "    770           -0.014989           0.015476\n",
       "    771           -0.014989           0.015476\n",
       "    772           -0.014989           0.015476\n",
       "    ...                 ...                ...\n",
       "    1015          -0.014989           0.015476\n",
       "    1016          -0.014989           0.015476\n",
       "    1017          -0.014989           0.015476\n",
       "    1018          -0.014989           0.015476\n",
       "    1019          -0.014989           0.015476\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00012877791532808693,\n",
       "     'rmse': np.float64(0.011348035747568251),\n",
       "     'mae': 0.00795641778155161,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(56.97211155378486)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(17.60623847645363),\n",
       "     'ljung_box_pvalue': np.float64(0.061980382702286736),\n",
       "     'jarque_bera_stat': np.float64(155.03812659670075),\n",
       "     'jarque_bera_pvalue': np.float64(2.1572405103663572e-34),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2004-12-14    0.003670\n",
       "    2004-12-15    0.002129\n",
       "    2004-12-16   -0.002074\n",
       "    2004-12-17   -0.008007\n",
       "    2004-12-20   -0.000819\n",
       "                    ...   \n",
       "    2007-12-26    0.001731\n",
       "    2007-12-27   -0.014423\n",
       "    2007-12-28   -0.000456\n",
       "    2007-12-31   -0.007173\n",
       "    2008-01-02   -0.015640\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516588d0>},\n",
       "  {'window_id': 5,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2006-01-03 to 2009-01-02',\n",
       "   'test_period': '2011-01-03 to 2012-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (2, 0, 1),\n",
       "   'model_selection': {'best_order': (2, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516dc450>,\n",
       "    'best_ic_value': np.float64(-4177.234164125555),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -4153.644777 -4139.713408 -4148.282682  2079.822389       True\n",
       "    1   (0, 0, 2) -4167.595909 -4149.020750 -4160.446448  2087.797954       True\n",
       "    2   (0, 0, 3) -4172.779368 -4149.560419 -4163.842542  2091.389684       True\n",
       "    3   (0, 1, 0) -3497.634323 -3492.991836 -3495.847350  1749.817161       True\n",
       "    4   (0, 1, 1) -4120.472512 -4111.187539 -4116.898566  2062.236256       True\n",
       "    5   (0, 1, 2) -4141.418047 -4127.490586 -4136.057128  2073.709023       True\n",
       "    6   (0, 1, 3) -4156.715957 -4138.146010 -4149.568066  2082.357978       True\n",
       "    7   (1, 0, 0) -4146.753137 -4132.821768 -4141.391042  2076.376569       True\n",
       "    8   (1, 0, 1) -4159.055023 -4140.479864 -4151.905562  2083.527511       True\n",
       "    9   (1, 0, 2) -4173.163539 -4149.944590 -4164.226713  2091.581769       True\n",
       "    10  (1, 0, 3) -4172.295573 -4144.432834 -4161.571382  2092.147786       True\n",
       "    11  (1, 1, 0) -3707.680788 -3698.395814 -3704.106842  1855.840394       True\n",
       "    12  (1, 1, 1) -4134.168903 -4120.241442 -4128.807984  2070.084451       True\n",
       "    13  (1, 1, 2) -4115.224728 -4096.654781 -4108.076837  2061.612364       True\n",
       "    14  (1, 1, 3) -4141.590519 -4118.378085 -4132.655655  2075.795260       True\n",
       "    15  (2, 0, 0) -4171.325757 -4152.750598 -4164.176296  2089.662878       True\n",
       "    16  (2, 0, 1) -4177.234164 -4154.015215 -4168.297339  2093.617082       True\n",
       "    17  (2, 0, 2) -4174.759274 -4146.896536 -4164.035084  2093.379637       True\n",
       "    18  (2, 0, 3) -4172.675199 -4140.168671 -4160.163644  2093.337600       True\n",
       "    19  (2, 1, 0) -3926.929223 -3913.001763 -3921.568304  1966.464611       True\n",
       "    20  (2, 1, 1) -4159.692756 -4141.122809 -4152.544865  2083.846378       True\n",
       "    21  (2, 1, 2) -4163.851783 -4140.639349 -4154.916919  2086.925891      False\n",
       "    22  (2, 1, 3) -4160.143492 -4132.288571 -4149.421655  2086.071746      False\n",
       "    23  (3, 0, 0) -4174.846178 -4151.627230 -4165.909353  2092.423089       True\n",
       "    24  (3, 0, 1) -4171.889029 -4144.026290 -4161.164838  2091.944514      False\n",
       "    25  (3, 0, 2) -4173.329471 -4140.822943 -4160.817915  2093.664735       True\n",
       "    26  (3, 0, 3) -4174.400197 -4137.249879 -4160.101276  2095.200098       True\n",
       "    27  (3, 1, 0) -3960.806702 -3942.236754 -3953.658810  1984.403351       True\n",
       "    28  (3, 1, 1) -4160.905461 -4137.693027 -4151.970597  2085.452730      False\n",
       "    29  (3, 1, 2) -4158.142038 -4130.287117 -4147.420201  2085.071019      False\n",
       "    30  (3, 1, 3) -4159.092843 -4126.595436 -4146.584034  2086.546422       True,\n",
       "    'successful_fits': 26,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 83.87096774193549},\n",
       "   'validation_scores': [np.float64(0.019739900883788918),\n",
       "    np.float64(0.015569620270383848),\n",
       "    np.float64(0.014551792372032215)],\n",
       "   'avg_validation_rmse': np.float64(0.01662043784206833),\n",
       "   'evaluation': {'model_order': (2, 0, 1),\n",
       "    'forecasts': 768    -0.005632\n",
       "    769    -0.005197\n",
       "    770     0.003693\n",
       "    771    -0.001642\n",
       "    772    -0.000718\n",
       "              ...   \n",
       "    1015   -0.000416\n",
       "    1016   -0.000416\n",
       "    1017   -0.000416\n",
       "    1018   -0.000416\n",
       "    1019   -0.000416\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.036673           0.025408\n",
       "    769           -0.036581           0.026187\n",
       "    770           -0.028087           0.035473\n",
       "    771           -0.033685           0.030401\n",
       "    772           -0.032782           0.031346\n",
       "    ...                 ...                ...\n",
       "    1015          -0.032486           0.031654\n",
       "    1016          -0.032486           0.031654\n",
       "    1017          -0.032486           0.031654\n",
       "    1018          -0.032486           0.031654\n",
       "    1019          -0.032486           0.031654\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.0002162910986272565,\n",
       "     'rmse': np.float64(0.014706838498714007),\n",
       "     'mae': 0.010444999415845951,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(45.41832669322709)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(15.779665240520869),\n",
       "     'ljung_box_pvalue': np.float64(0.10611584799362692),\n",
       "     'jarque_bera_stat': np.float64(2654.0783269133403),\n",
       "     'jarque_bera_pvalue': np.float64(0.0),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2005-12-14    0.004597\n",
       "    2005-12-15   -0.000348\n",
       "    2005-12-16   -0.001734\n",
       "    2005-12-19   -0.006367\n",
       "    2005-12-20   -0.000838\n",
       "                    ...   \n",
       "    2008-12-26    0.006618\n",
       "    2008-12-29   -0.001444\n",
       "    2008-12-30    0.024560\n",
       "    2008-12-31    0.017259\n",
       "    2009-01-02    0.038577\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516dd4d0>},\n",
       "  {'window_id': 6,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2007-01-03 to 2010-01-02',\n",
       "   'test_period': '2012-01-03 to 2013-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 251,\n",
       "   'best_order': (3, 0, 2),\n",
       "   'model_selection': {'best_order': (3, 0, 2),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516d3350>,\n",
       "    'best_ic_value': np.float64(-3948.9803282468556),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -3938.179552 -3924.252091 -3932.818633  1972.089776       True\n",
       "    1   (0, 0, 2) -3942.030025 -3923.460077 -3934.882133  1975.015012       True\n",
       "    2   (0, 0, 3) -3945.126298 -3921.913864 -3936.191434  1977.563149       True\n",
       "    3   (0, 1, 0) -3286.362455 -3281.721272 -3284.575875  1644.181227       True\n",
       "    4   (0, 1, 1) -3908.359063 -3899.076698 -3904.785903  1956.179531       True\n",
       "    5   (0, 1, 2) -3925.270139 -3911.346593 -3919.910399  1965.635070       True\n",
       "    6   (0, 1, 3) -3929.688849 -3911.124120 -3922.542529  1968.844424       True\n",
       "    7   (1, 0, 0) -3934.141963 -3920.214503 -3928.781045  1970.070982       True\n",
       "    8   (1, 0, 1) -3938.977367 -3920.407420 -3931.829476  1973.488684       True\n",
       "    9   (1, 0, 2) -3944.002650 -3920.790216 -3935.067786  1977.001325       True\n",
       "    10  (1, 0, 3) -3943.015734 -3915.160813 -3932.293897  1977.507867       True\n",
       "    11  (1, 1, 0) -3518.541960 -3509.259596 -3514.968801  1761.270980       True\n",
       "    12  (1, 1, 1) -3921.100196 -3907.176650 -3915.740456  1963.550098       True\n",
       "    13  (1, 1, 2) -3905.896795 -3887.332067 -3898.750475  1956.948398       True\n",
       "    14  (1, 1, 3) -3922.492540 -3899.286629 -3913.559640  1966.246270       True\n",
       "    15  (2, 0, 0) -3945.259010 -3926.689062 -3938.111118  1976.629505       True\n",
       "    16  (2, 0, 1) -3945.756125 -3922.543691 -3936.821261  1977.878062       True\n",
       "    17  (2, 0, 2) -3944.934935 -3917.080014 -3934.213098  1978.467467       True\n",
       "    18  (2, 0, 3) -3943.535539 -3911.038131 -3931.026729  1978.767770       True\n",
       "    19  (2, 1, 0) -3700.298667 -3686.375120 -3694.938927  1853.149333       True\n",
       "    20  (2, 1, 1) -3932.756974 -3914.192246 -3925.610655  1970.378487       True\n",
       "    21  (2, 1, 2) -3933.508395 -3910.302484 -3924.575495  1971.754197      False\n",
       "    22  (2, 1, 3) -3922.682360 -3894.835267 -3911.962880  1967.341180      False\n",
       "    23  (3, 0, 0) -3946.428811 -3923.216377 -3937.493947  1978.214406       True\n",
       "    24  (3, 0, 1) -3944.185370 -3916.330450 -3933.463533  1978.092685       True\n",
       "    25  (3, 0, 2) -3948.980328 -3916.482921 -3936.471518  1981.490164      False\n",
       "    26  (3, 0, 3) -3941.452951 -3904.313057 -3927.157168  1978.726475      False\n",
       "    27  (3, 1, 0) -3748.398120 -3729.833391 -3741.251800  1878.199060       True\n",
       "    28  (3, 1, 1) -3933.487565 -3910.281655 -3924.554666  1971.743783      False\n",
       "    29  (3, 1, 2) -3928.938391 -3901.091298 -3918.218911  1970.469195      False\n",
       "    30  (3, 1, 3) -3929.101626 -3896.613351 -3916.595566  1971.550813      False,\n",
       "    'successful_fits': 24,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 77.41935483870968},\n",
       "   'validation_scores': [np.float64(0.012764542379495855),\n",
       "    np.float64(0.010596618183743346),\n",
       "    np.float64(0.013137139684194615)],\n",
       "   'avg_validation_rmse': np.float64(0.012166100082477939),\n",
       "   'evaluation': {'model_order': (3, 0, 2),\n",
       "    'forecasts': 767    -0.000013\n",
       "    768     0.001756\n",
       "    769    -0.002103\n",
       "    770     0.000697\n",
       "    771    -0.000789\n",
       "              ...   \n",
       "    1013   -0.000318\n",
       "    1014   -0.000318\n",
       "    1015   -0.000318\n",
       "    1016   -0.000318\n",
       "    1017   -0.000318\n",
       "    Name: predicted_mean, Length: 251, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.035844           0.035818\n",
       "    768           -0.034419           0.037931\n",
       "    769           -0.038455           0.034250\n",
       "    770           -0.035810           0.037203\n",
       "    771           -0.037316           0.035739\n",
       "    ...                 ...                ...\n",
       "    1013          -0.037085           0.036449\n",
       "    1014          -0.037085           0.036449\n",
       "    1015          -0.037085           0.036449\n",
       "    1016          -0.037085           0.036449\n",
       "    1017          -0.037085           0.036449\n",
       "    \n",
       "    [251 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 6.737477454883858e-05,\n",
       "     'rmse': np.float64(0.008208213846436907),\n",
       "     'mae': 0.006030672696647634,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(47.199999999999996)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(1.464999306652927),\n",
       "     'ljung_box_pvalue': np.float64(0.9990402377817732),\n",
       "     'jarque_bera_stat': np.float64(790.8872252438578),\n",
       "     'jarque_bera_pvalue': np.float64(1.823984462130404e-172),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2006-12-14    0.008970\n",
       "    2006-12-15    0.002722\n",
       "    2006-12-18   -0.001640\n",
       "    2006-12-19    0.001674\n",
       "    2006-12-20   -0.000968\n",
       "                    ...   \n",
       "    2009-12-24    0.005140\n",
       "    2009-12-28    0.003491\n",
       "    2009-12-29   -0.001381\n",
       "    2009-12-30    0.001263\n",
       "    2009-12-31   -0.010776\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516dcf50>},\n",
       "  {'window_id': 7,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2008-01-03 to 2011-01-02',\n",
       "   'test_period': '2013-01-03 to 2014-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (3, 0, 0),\n",
       "   'model_selection': {'best_order': (3, 0, 0),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595166d050>,\n",
       "    'best_ic_value': np.float64(-3925.7240512799053),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -3917.860430 -3903.929060 -3912.498334  1961.930215       True\n",
       "    1   (0, 0, 2) -3922.000420 -3903.425261 -3914.850960  1965.000210       True\n",
       "    2   (0, 0, 3) -3924.720516 -3901.501567 -3915.783690  1967.360258       True\n",
       "    3   (0, 1, 0) -3279.602802 -3274.960315 -3277.815829  1640.801401       True\n",
       "    4   (0, 1, 1) -3892.355733 -3883.070760 -3888.781788  1948.177867       True\n",
       "    5   (0, 1, 2) -3905.785097 -3891.857637 -3900.424179  1955.892549       True\n",
       "    6   (0, 1, 3) -3910.433352 -3891.863404 -3903.285460  1959.216676       True\n",
       "    7   (1, 0, 0) -3914.716214 -3900.784845 -3909.354119  1960.358107       True\n",
       "    8   (1, 0, 1) -3918.683517 -3900.108358 -3911.534057  1963.341759       True\n",
       "    9   (1, 0, 2) -3922.790388 -3899.571440 -3913.853563  1966.395194       True\n",
       "    10  (1, 0, 3) -3922.769055 -3894.906317 -3912.044865  1967.384528       True\n",
       "    11  (1, 1, 0) -3505.907574 -3496.622600 -3502.333628  1754.953787       True\n",
       "    12  (1, 1, 1) -3902.453154 -3888.525694 -3897.092236  1954.226577       True\n",
       "    13  (1, 1, 2) -3889.278047 -3870.708100 -3882.130156  1948.639023       True\n",
       "    14  (1, 1, 3) -3907.881955 -3884.669521 -3898.947091  1958.940978      False\n",
       "    15  (2, 0, 0) -3924.727982 -3906.152823 -3917.578522  1966.363991       True\n",
       "    16  (2, 0, 1) -3924.957644 -3901.738695 -3916.020819  1967.478822       True\n",
       "    17  (2, 0, 2) -3924.131128 -3896.268389 -3913.406937  1968.065564       True\n",
       "    18  (2, 0, 3) -3922.468767 -3889.962239 -3909.957212  1968.234384       True\n",
       "    19  (2, 1, 0) -3681.807654 -3667.880193 -3676.446735  1843.903827       True\n",
       "    20  (2, 1, 1) -3913.036476 -3894.466529 -3905.888585  1960.518238       True\n",
       "    21  (2, 1, 2) -3912.194297 -3888.981863 -3903.259433  1961.097149      False\n",
       "    22  (2, 1, 3) -3905.258237 -3877.403316 -3894.536400  1958.629119      False\n",
       "    23  (3, 0, 0) -3925.724051 -3902.505103 -3916.787226  1967.862026       True\n",
       "    24  (3, 0, 1) -3923.552411 -3895.689673 -3912.828221  1967.776206       True\n",
       "    25  (3, 0, 2) -3921.728132 -3889.221604 -3909.216576  1967.864066       True\n",
       "    26  (3, 0, 3) -3920.414732 -3883.264414 -3906.115811  1968.207366       True\n",
       "    27  (3, 1, 0) -3730.555083 -3711.985135 -3723.407191  1869.277541       True\n",
       "    28  (3, 1, 1) -3913.697825 -3890.485391 -3904.762961  1961.848912       True\n",
       "    29  (3, 1, 2) -3909.302517 -3881.447596 -3898.580680  1960.651258      False\n",
       "    30  (3, 1, 3) -3907.835822 -3875.338414 -3895.327012  1960.917911      False,\n",
       "    'successful_fits': 26,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 83.87096774193549},\n",
       "   'validation_scores': [np.float64(0.013364179701835833),\n",
       "    np.float64(0.01319061308969391),\n",
       "    np.float64(0.011896439990543153)],\n",
       "   'avg_validation_rmse': np.float64(0.012817077594024298),\n",
       "   'evaluation': {'model_order': (3, 0, 0),\n",
       "    'forecasts': 768     0.000002\n",
       "    769    -0.000333\n",
       "    770    -0.000229\n",
       "    771    -0.000192\n",
       "    772    -0.000230\n",
       "              ...   \n",
       "    1015   -0.000220\n",
       "    1016   -0.000220\n",
       "    1017   -0.000220\n",
       "    1018   -0.000220\n",
       "    1019   -0.000220\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.036567           0.036572\n",
       "    769           -0.037222           0.036555\n",
       "    770           -0.037292           0.036834\n",
       "    771           -0.037403           0.037020\n",
       "    772           -0.037442           0.036983\n",
       "    ...                 ...                ...\n",
       "    1015          -0.037438           0.036999\n",
       "    1016          -0.037438           0.036999\n",
       "    1017          -0.037438           0.036999\n",
       "    1018          -0.037438           0.036999\n",
       "    1019          -0.037438           0.036999\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 4.776994904831261e-05,\n",
       "     'rmse': np.float64(0.006911580792287146),\n",
       "     'mae': 0.005378710295632934,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(41.832669322709165)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(3.771670472256611),\n",
       "     'ljung_box_pvalue': np.float64(0.9570600068819304),\n",
       "     'jarque_bera_stat': np.float64(793.1892831251147),\n",
       "     'jarque_bera_pvalue': np.float64(5.769465981743452e-173),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2007-12-14   -0.013622\n",
       "    2007-12-17   -0.016613\n",
       "    2007-12-18    0.002693\n",
       "    2007-12-19   -0.001160\n",
       "    2007-12-20    0.006639\n",
       "                    ...   \n",
       "    2010-12-27    0.000670\n",
       "    2010-12-28    0.000712\n",
       "    2010-12-29    0.001545\n",
       "    2010-12-30   -0.001064\n",
       "    2010-12-31   -0.000061\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595166c350>},\n",
       "  {'window_id': 8,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2009-01-03 to 2012-01-02',\n",
       "   'test_period': '2014-01-03 to 2015-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (1, 0, 1),\n",
       "   'model_selection': {'best_order': (1, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595166c450>,\n",
       "    'best_ic_value': np.float64(-4308.283438051686),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -4305.884635 -4291.953266 -4300.522540  2155.942318       True\n",
       "    1   (0, 0, 2) -4304.861046 -4286.285887 -4297.711586  2156.430523       True\n",
       "    2   (0, 0, 3) -4303.939853 -4280.720904 -4295.003028  2156.969927       True\n",
       "    3   (0, 1, 0) -3691.014347 -3686.371860 -3689.227374  1846.507174       True\n",
       "    4   (0, 1, 1) -4287.354593 -4278.069620 -4283.780647  2145.677297       True\n",
       "    5   (0, 1, 2) -4292.436726 -4278.509266 -4287.075808  2149.218363       True\n",
       "    6   (0, 1, 3) -4291.626595 -4273.056648 -4284.478704  2149.813298       True\n",
       "    7   (1, 0, 0) -4306.466981 -4292.535612 -4301.104886  2156.233491       True\n",
       "    8   (1, 0, 1) -4308.283438 -4289.708279 -4301.133978  2158.141719       True\n",
       "    9   (1, 0, 2) -4303.115042 -4279.896094 -4294.178217  2156.557521       True\n",
       "    10  (1, 0, 3) -4305.616018 -4277.753280 -4294.891828  2158.808009       True\n",
       "    11  (1, 1, 0) -3988.145557 -3978.860583 -3984.571611  1996.072778       True\n",
       "    12  (1, 1, 1) -4293.017487 -4279.090027 -4287.656569  2149.508744       True\n",
       "    13  (1, 1, 2) -4296.027289 -4277.457341 -4288.879397  2152.013644      False\n",
       "    14  (1, 1, 3) -4290.936780 -4267.724346 -4282.001916  2150.468390       True\n",
       "    15  (2, 0, 0) -4305.600041 -4287.024882 -4298.450581  2156.800020       True\n",
       "    16  (2, 0, 1) -4303.484884 -4280.265936 -4294.548059  2156.742442       True\n",
       "    17  (2, 0, 2) -4305.975990 -4278.113252 -4295.251800  2158.987995       True\n",
       "    18  (2, 0, 3) -4303.738947 -4271.232418 -4291.227391  2158.869473       True\n",
       "    19  (2, 1, 0) -4060.974078 -4047.046617 -4055.613159  2033.487039       True\n",
       "    20  (2, 1, 1) -4292.224563 -4273.654615 -4285.076671  2150.112281      False\n",
       "    21  (2, 1, 2) -4289.004797 -4265.792363 -4280.069933  2149.502399      False\n",
       "    22  (2, 1, 3) -4284.318441 -4256.463520 -4273.596604  2148.159220       True\n",
       "    23  (3, 0, 0) -4305.346634 -4282.127686 -4296.409809  2157.673317       True\n",
       "    24  (3, 0, 1) -4303.156652 -4275.293913 -4292.432461  2157.578326       True\n",
       "    25  (3, 0, 2) -4300.998037 -4268.491509 -4288.486482  2157.499019       True\n",
       "    26  (3, 0, 3) -4301.671234 -4264.520916 -4287.372314  2158.835617       True\n",
       "    27  (3, 1, 0) -4139.414390 -4120.844443 -4132.266499  2073.707195       True\n",
       "    28  (3, 1, 1) -4291.559626 -4268.347192 -4282.624762  2150.779813      False\n",
       "    29  (3, 1, 2) -4289.957678 -4262.102757 -4279.235841  2150.978839      False\n",
       "    30  (3, 1, 3) -4286.483513 -4253.986105 -4273.974703  2150.241756      False,\n",
       "    'successful_fits': 25,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 80.64516129032258},\n",
       "   'validation_scores': [np.float64(0.008118159809936085),\n",
       "    np.float64(0.007824273044596422),\n",
       "    np.float64(0.007517151028043815)],\n",
       "   'avg_validation_rmse': np.float64(0.007819861294192107),\n",
       "   'evaluation': {'model_order': (1, 0, 1),\n",
       "    'forecasts': 768     0.001653\n",
       "    769    -0.000246\n",
       "    770     0.000889\n",
       "    771     0.000211\n",
       "    772     0.000616\n",
       "              ...   \n",
       "    1015    0.000464\n",
       "    1016    0.000464\n",
       "    1017    0.000464\n",
       "    1018    0.000464\n",
       "    1019    0.000464\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.026897           0.030202\n",
       "    769           -0.028910           0.028419\n",
       "    770           -0.027816           0.029595\n",
       "    771           -0.028509           0.028931\n",
       "    772           -0.028109           0.029342\n",
       "    ...                 ...                ...\n",
       "    1015          -0.028264           0.029193\n",
       "    1016          -0.028264           0.029193\n",
       "    1017          -0.028264           0.029193\n",
       "    1018          -0.028264           0.029193\n",
       "    1019          -0.028264           0.029193\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 5.0852618980382744e-05,\n",
       "     'rmse': np.float64(0.007131102227593063),\n",
       "     'mae': 0.005199538653222245,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(57.76892430278885)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(9.690726113961327),\n",
       "     'ljung_box_pvalue': np.float64(0.4680329921810511),\n",
       "     'jarque_bera_stat': np.float64(198.45865515311414),\n",
       "     'jarque_bera_pvalue': np.float64(8.039898953835156e-44),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2008-12-15   -0.013231\n",
       "    2008-12-16    0.048348\n",
       "    2008-12-17   -0.004919\n",
       "    2008-12-18   -0.025398\n",
       "    2008-12-19    0.002301\n",
       "                    ...   \n",
       "    2011-12-23    0.009961\n",
       "    2011-12-27   -0.000345\n",
       "    2011-12-28   -0.013076\n",
       "    2011-12-29    0.009043\n",
       "    2011-12-30   -0.003269\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516d35d0>},\n",
       "  {'window_id': 9,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2010-01-03 to 2013-01-02',\n",
       "   'test_period': '2015-01-03 to 2016-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 251,\n",
       "   'best_order': (3, 0, 2),\n",
       "   'model_selection': {'best_order': (3, 0, 2),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516d2450>,\n",
       "    'best_ic_value': np.float64(-4664.412628201627),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -4658.023235 -4644.091865 -4652.661139  2332.011617       True\n",
       "    1   (0, 0, 2) -4657.501610 -4638.926451 -4650.352149  2332.750805       True\n",
       "    2   (0, 0, 3) -4661.319518 -4638.100569 -4652.382693  2335.659759       True\n",
       "    3   (0, 1, 0) -4071.434624 -4066.792138 -4069.647652  2036.717312       True\n",
       "    4   (0, 1, 1) -4642.992610 -4633.707636 -4639.418664  2323.496305       True\n",
       "    5   (0, 1, 2) -4644.173380 -4630.245920 -4638.812462  2325.086690      False\n",
       "    6   (0, 1, 3) -4643.772339 -4625.202392 -4636.624448  2325.886170       True\n",
       "    7   (1, 0, 0) -4658.348821 -4644.417452 -4652.986726  2332.174411       True\n",
       "    8   (1, 0, 1) -4656.176553 -4637.601394 -4649.027093  2332.088277       True\n",
       "    9   (1, 0, 2) -4661.690659 -4638.471710 -4652.753834  2335.845329       True\n",
       "    10  (1, 0, 3) -4660.502251 -4632.639512 -4649.778060  2336.251125       True\n",
       "    11  (1, 1, 0) -4356.391855 -4347.106882 -4352.817909  2180.195928       True\n",
       "    12  (1, 1, 1) -4644.487442 -4630.559981 -4639.126523  2325.243721      False\n",
       "    13  (1, 1, 2) -4651.280755 -4632.710808 -4644.132864  2329.640378      False\n",
       "    14  (1, 1, 3) -4646.413310 -4623.200876 -4637.478446  2328.206655      False\n",
       "    15  (2, 0, 0) -4658.396470 -4639.821311 -4651.247010  2333.198235       True\n",
       "    16  (2, 0, 1) -4663.175215 -4639.956266 -4654.238389  2336.587607      False\n",
       "    17  (2, 0, 2) -4653.913251 -4626.050513 -4643.189061  2332.956626       True\n",
       "    18  (2, 0, 3) -4664.209313 -4631.702785 -4651.697758  2339.104657       True\n",
       "    19  (2, 1, 0) -4408.349490 -4394.422029 -4402.988571  2207.174745       True\n",
       "    20  (2, 1, 1) -4642.950042 -4624.380095 -4635.802151  2325.475021      False\n",
       "    21  (2, 1, 2) -4647.160815 -4623.948381 -4638.225951  2328.580407       True\n",
       "    22  (2, 1, 3) -4643.075623 -4615.220703 -4632.353787  2327.537812       True\n",
       "    23  (3, 0, 0) -4662.962679 -4639.743730 -4654.025853  2336.481339       True\n",
       "    24  (3, 0, 1) -4660.902035 -4633.039296 -4650.177844  2336.451017       True\n",
       "    25  (3, 0, 2) -4664.412628 -4631.906100 -4651.901073  2339.206314      False\n",
       "    26  (3, 0, 3) -4662.319337 -4625.169019 -4648.020417  2339.159669       True\n",
       "    27  (3, 1, 0) -4475.009432 -4456.439485 -4467.861541  2241.504716       True\n",
       "    28  (3, 1, 1) -4646.944804 -4623.732370 -4638.009940  2328.472402      False\n",
       "    29  (3, 1, 2) -4644.941376 -4617.086455 -4634.219539  2328.470688      False\n",
       "    30  (3, 1, 3) -4643.415898 -4610.918490 -4630.907088  2328.707949      False,\n",
       "    'successful_fits': 21,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 67.74193548387096},\n",
       "   'validation_scores': [np.float64(0.0070793711591186),\n",
       "    np.float64(0.0070255139981631526),\n",
       "    np.float64(0.006990489378069793)],\n",
       "   'avg_validation_rmse': np.float64(0.00703179151178385),\n",
       "   'evaluation': {'model_order': (3, 0, 2),\n",
       "    'forecasts': 768     0.001109\n",
       "    769    -0.000908\n",
       "    770    -0.001259\n",
       "    771    -0.000280\n",
       "    772    -0.000323\n",
       "              ...   \n",
       "    1014    0.000352\n",
       "    1015    0.000352\n",
       "    1016    0.000352\n",
       "    1017    0.000352\n",
       "    1018    0.000352\n",
       "    Name: predicted_mean, Length: 251, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.021435           0.023653\n",
       "    769           -0.023491           0.021675\n",
       "    770           -0.023853           0.021335\n",
       "    771           -0.023015           0.022455\n",
       "    772           -0.023064           0.022419\n",
       "    ...                 ...                ...\n",
       "    1014          -0.022458           0.023162\n",
       "    1015          -0.022458           0.023162\n",
       "    1016          -0.022458           0.023162\n",
       "    1017          -0.022458           0.023162\n",
       "    1018          -0.022458           0.023162\n",
       "    \n",
       "    [251 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 9.579578125362623e-05,\n",
       "     'rmse': np.float64(0.009787531928613374),\n",
       "     'mae': 0.00723776241333717,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(47.599999999999994)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(10.013231720871124),\n",
       "     'ljung_box_pvalue': np.float64(0.4393331864637418),\n",
       "     'jarque_bera_stat': np.float64(350.8885710718395),\n",
       "     'jarque_bera_pvalue': np.float64(6.390206759669452e-77),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2009-12-14    0.006583\n",
       "    2009-12-15   -0.005452\n",
       "    2009-12-16    0.000093\n",
       "    2009-12-17   -0.011229\n",
       "    2009-12-18    0.003922\n",
       "                    ...   \n",
       "    2012-12-26   -0.003979\n",
       "    2012-12-27   -0.003118\n",
       "    2012-12-28   -0.011126\n",
       "    2012-12-31    0.014682\n",
       "    2013-01-02    0.026019\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516d1f50>},\n",
       "  {'window_id': 10,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2011-01-03 to 2014-01-02',\n",
       "   'test_period': '2016-01-03 to 2017-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (3, 0, 2),\n",
       "   'model_selection': {'best_order': (3, 0, 2),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259516d3150>,\n",
       "    'best_ic_value': np.float64(-4850.923323131974),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -4833.103750 -4819.172380 -4827.741654  2419.551875      False\n",
       "    1   (0, 0, 2) -4833.528064 -4814.952905 -4826.378603  2420.764032       True\n",
       "    2   (0, 0, 3) -4840.474053 -4817.255104 -4831.537227  2425.237026       True\n",
       "    3   (0, 1, 0) -4235.859830 -4231.217343 -4234.072857  2118.929915      False\n",
       "    4   (0, 1, 1) -4816.870244 -4807.585270 -4813.296298  2410.435122       True\n",
       "    5   (0, 1, 2) -4819.008382 -4805.080921 -4813.647463  2412.504191      False\n",
       "    6   (0, 1, 3) -4819.327015 -4800.757068 -4812.179124  2413.663507      False\n",
       "    7   (1, 0, 0) -4833.666933 -4819.735564 -4828.304838  2419.833467       True\n",
       "    8   (1, 0, 1) -4831.370870 -4812.795711 -4824.221410  2419.685435      False\n",
       "    9   (1, 0, 2) -4847.755492 -4824.536544 -4838.818667  2428.877746       True\n",
       "    10  (1, 0, 3) -4841.871113 -4814.008375 -4831.146923  2426.935557       True\n",
       "    11  (1, 1, 0) -4535.987709 -4526.702736 -4532.413764  2269.993855       True\n",
       "    12  (1, 1, 1) -4819.537837 -4805.610376 -4814.176918  2412.768918      False\n",
       "    13  (1, 1, 2) -4833.418305 -4814.848358 -4826.270414  2420.709153       True\n",
       "    14  (1, 1, 3) -4830.995357 -4807.782923 -4822.060493  2420.497679       True\n",
       "    15  (2, 0, 0) -4835.249170 -4816.674011 -4828.099710  2421.624585       True\n",
       "    16  (2, 0, 1) -4847.803974 -4824.585026 -4838.867149  2428.901987       True\n",
       "    17  (2, 0, 2) -4830.351575 -4802.488836 -4819.627384  2421.175787       True\n",
       "    18  (2, 0, 3) -4849.430706 -4816.924178 -4836.919150  2431.715353       True\n",
       "    19  (2, 1, 0) -4579.166619 -4565.239159 -4573.805701  2292.583310       True\n",
       "    20  (2, 1, 1) -4821.202947 -4802.633000 -4814.055056  2414.601474       True\n",
       "    21  (2, 1, 2) -4831.845339 -4808.632905 -4822.910474  2420.922669       True\n",
       "    22  (2, 1, 3) -4830.765492 -4802.910571 -4820.043655  2421.382746      False\n",
       "    23  (3, 0, 0) -4844.008433 -4820.789484 -4835.071607  2427.004216       True\n",
       "    24  (3, 0, 1) -4841.930837 -4814.068098 -4831.206646  2426.965418       True\n",
       "    25  (3, 0, 2) -4850.923323 -4818.416795 -4838.411768  2432.461662      False\n",
       "    26  (3, 0, 3) -4848.433468 -4811.283150 -4834.134547  2432.216734       True\n",
       "    27  (3, 1, 0) -4650.074947 -4631.505000 -4642.927056  2329.037473       True\n",
       "    28  (3, 1, 1) -4829.450394 -4806.237960 -4820.515530  2419.725197      False\n",
       "    29  (3, 1, 2) -4830.232015 -4802.377094 -4819.510178  2421.116007      False\n",
       "    30  (3, 1, 3) -4824.393284 -4791.895876 -4811.884474  2419.196642      False,\n",
       "    'successful_fits': 20,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 64.51612903225806},\n",
       "   'validation_scores': [np.float64(0.0064893534274383284),\n",
       "    np.float64(0.007396575544537776),\n",
       "    np.float64(0.008559296476427605)],\n",
       "   'avg_validation_rmse': np.float64(0.00748174181613457),\n",
       "   'evaluation': {'model_order': (3, 0, 2),\n",
       "    'forecasts': 768     0.000850\n",
       "    769    -0.000651\n",
       "    770     0.001692\n",
       "    771    -0.000223\n",
       "    772     0.001314\n",
       "              ...   \n",
       "    1015    0.000489\n",
       "    1016    0.000489\n",
       "    1017    0.000489\n",
       "    1018    0.000489\n",
       "    1019    0.000489\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.019120           0.020820\n",
       "    769           -0.020655           0.019354\n",
       "    770           -0.018328           0.021712\n",
       "    771           -0.020435           0.019989\n",
       "    772           -0.018907           0.021536\n",
       "    ...                 ...                ...\n",
       "    1015          -0.019883           0.020861\n",
       "    1016          -0.019883           0.020861\n",
       "    1017          -0.019883           0.020861\n",
       "    1018          -0.019883           0.020861\n",
       "    1019          -0.019883           0.020861\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 6.792984536224796e-05,\n",
       "     'rmse': np.float64(0.00824195640380656),\n",
       "     'mae': 0.005773871010678652,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(51.79282868525896)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(11.268974506650833),\n",
       "     'ljung_box_pvalue': np.float64(0.3369500388392987),\n",
       "     'jarque_bera_stat': np.float64(730.5464035021566),\n",
       "     'jarque_bera_pvalue': np.float64(2.311341368420726e-159),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2010-12-14    0.000422\n",
       "    2010-12-15   -0.005591\n",
       "    2010-12-16    0.005229\n",
       "    2010-12-17    0.001076\n",
       "    2010-12-20    0.000983\n",
       "                    ...   \n",
       "    2013-12-26    0.006121\n",
       "    2013-12-27   -0.000507\n",
       "    2013-12-30    0.000406\n",
       "    2013-12-31    0.004125\n",
       "    2014-01-02   -0.008632\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595172b850>},\n",
       "  {'window_id': 11,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2012-01-03 to 2015-01-02',\n",
       "   'test_period': '2017-01-03 to 2018-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 252,\n",
       "   'best_order': (1, 0, 0),\n",
       "   'model_selection': {'best_order': (1, 0, 0),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x2595178e950>,\n",
       "    'best_ic_value': np.float64(-5329.166301410496),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5329.155483 -5315.228022 -5323.794564  2667.577741       True\n",
       "    1   (0, 0, 2) -5327.354981 -5308.785034 -5320.207090  2667.677491       True\n",
       "    2   (0, 0, 3) -5325.428053 -5302.215619 -5316.493189  2667.714027       True\n",
       "    3   (0, 1, 0) -4778.707059 -4774.065877 -4776.920479  2390.353529       True\n",
       "    4   (0, 1, 1) -5316.016030 -5306.733666 -5312.442871  2660.008015       True\n",
       "    5   (0, 1, 2) -5230.539311 -5216.615764 -5225.179571  2618.269655       True\n",
       "    6   (0, 1, 3) -5288.119333 -5269.554605 -5280.973013  2648.059667       True\n",
       "    7   (1, 0, 0) -5329.166301 -5315.238841 -5323.805383  2667.583151       True\n",
       "    8   (1, 0, 1) -5327.640603 -5309.070656 -5320.492712  2667.820301       True\n",
       "    9   (1, 0, 2) -5324.802583 -5301.590149 -5315.867719  2667.401292       True\n",
       "    10  (1, 0, 3) -5325.565718 -5297.710797 -5314.843881  2668.782859       True\n",
       "    11  (1, 1, 0) -5015.889834 -5006.607469 -5012.316674  2509.944917       True\n",
       "    12  (1, 1, 1) -5314.338448 -5300.414902 -5308.978708  2660.169224      False\n",
       "    13  (1, 1, 2) -5312.107281 -5293.542553 -5304.960961  2660.053641      False\n",
       "    14  (1, 1, 3) -5310.471391 -5287.265480 -5301.538491  2660.235695      False\n",
       "    15  (2, 0, 0) -5327.342528 -5308.772581 -5320.194636  2667.671264      False\n",
       "    16  (2, 0, 1) -5325.688654 -5302.476220 -5316.753790  2667.844327       True\n",
       "    17  (2, 0, 2) -5322.802604 -5294.947683 -5312.080767  2667.401302       True\n",
       "    18  (2, 0, 3) -5323.889726 -5291.392318 -5311.380916  2668.944863       True\n",
       "    19  (2, 1, 0) -5098.326598 -5084.403051 -5092.966858  2552.163299       True\n",
       "    20  (2, 1, 1) -5312.442334 -5293.877605 -5305.296014  2660.221167      False\n",
       "    21  (2, 1, 2) -5311.543094 -5288.337183 -5302.610194  2660.771547      False\n",
       "    22  (2, 1, 3) -5308.274539 -5280.427446 -5297.555059  2660.137269       True\n",
       "    23  (3, 0, 0) -5325.448340 -5302.235906 -5316.513476  2667.724170       True\n",
       "    24  (3, 0, 1) -5323.461090 -5295.606169 -5312.739253  2667.730545      False\n",
       "    25  (3, 0, 2) -5320.802663 -5288.305256 -5308.293854  2667.401332      False\n",
       "    26  (3, 0, 3) -5321.363981 -5284.224087 -5307.068199  2668.681991       True\n",
       "    27  (3, 1, 0) -5127.423880 -5108.859151 -5120.277560  2567.711940      False\n",
       "    28  (3, 1, 1) -5298.337467 -5275.131556 -5289.404567  2654.168733      False\n",
       "    29  (3, 1, 2) -5308.096831 -5280.249738 -5297.377351  2660.048416       True\n",
       "    30  (3, 1, 3) -5307.376922 -5274.888647 -5294.870862  2660.688461      False,\n",
       "    'successful_fits': 20,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 64.51612903225806},\n",
       "   'validation_scores': [np.float64(0.009667734201730671),\n",
       "    np.float64(0.009963254465942277),\n",
       "    np.float64(0.009053671538963613)],\n",
       "   'avg_validation_rmse': np.float64(0.009561553402212186),\n",
       "   'evaluation': {'model_order': (1, 0, 0),\n",
       "    'forecasts': 767     0.000694\n",
       "    768     0.000671\n",
       "    769     0.000672\n",
       "    770     0.000672\n",
       "    771     0.000672\n",
       "              ...   \n",
       "    1014    0.000672\n",
       "    1015    0.000672\n",
       "    1016    0.000672\n",
       "    1017    0.000672\n",
       "    1018    0.000672\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.013941           0.015328\n",
       "    768           -0.013967           0.015309\n",
       "    769           -0.013966           0.015310\n",
       "    770           -0.013966           0.015310\n",
       "    771           -0.013966           0.015310\n",
       "    ...                 ...                ...\n",
       "    1014          -0.013966           0.015310\n",
       "    1015          -0.013966           0.015310\n",
       "    1016          -0.013966           0.015310\n",
       "    1017          -0.013966           0.015310\n",
       "    1018          -0.013966           0.015310\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 1.783440381947889e-05,\n",
       "     'rmse': np.float64(0.00422307989735914),\n",
       "     'mae': 0.002978806565919764,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(56.97211155378486)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(13.258111592085777),\n",
       "     'ljung_box_pvalue': np.float64(0.20959643971447434),\n",
       "     'jarque_bera_stat': np.float64(55.54642857396265),\n",
       "     'jarque_bera_pvalue': np.float64(8.674536733610115e-13),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2011-12-14   -0.012085\n",
       "    2011-12-15    0.002303\n",
       "    2011-12-16    0.002595\n",
       "    2011-12-19   -0.012419\n",
       "    2011-12-20    0.028446\n",
       "                    ...   \n",
       "    2014-12-26    0.002615\n",
       "    2014-12-29    0.000247\n",
       "    2014-12-30   -0.005568\n",
       "    2014-12-31   -0.011157\n",
       "    2015-01-02   -0.001252\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x25951815650>},\n",
       "  {'window_id': 12,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2013-01-03 to 2016-01-02',\n",
       "   'test_period': '2018-01-03 to 2019-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 251,\n",
       "   'best_order': (1, 0, 0),\n",
       "   'model_selection': {'best_order': (1, 0, 0),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259517c1250>,\n",
       "    'best_ic_value': np.float64(-5208.216381102231),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5208.215250 -5194.287789 -5202.854331  2607.107625       True\n",
       "    1   (0, 0, 2) -5207.778978 -5189.209030 -5200.631086  2607.889489       True\n",
       "    2   (0, 0, 3) -5206.095962 -5182.883528 -5197.161098  2608.047981       True\n",
       "    3   (0, 1, 0) -4679.999448 -4675.358266 -4678.212868  2340.999724       True\n",
       "    4   (0, 1, 1) -5195.745588 -5186.463224 -5192.172429  2599.872794       True\n",
       "    5   (0, 1, 2) -5193.803498 -5179.879951 -5188.443758  2599.901749      False\n",
       "    6   (0, 1, 3) -5157.254851 -5138.690122 -5150.108531  2582.627425      False\n",
       "    7   (1, 0, 0) -5208.216381 -5194.288921 -5202.855463  2607.108191       True\n",
       "    8   (1, 0, 1) -5206.121903 -5187.551956 -5198.974012  2607.060951       True\n",
       "    9   (1, 0, 2) -5208.025516 -5184.813082 -5199.090652  2609.012758       True\n",
       "    10  (1, 0, 3) -5205.336627 -5177.481706 -5194.614790  2608.668313       True\n",
       "    11  (1, 1, 0) -4874.380351 -4865.097986 -4870.807191  2439.190175       True\n",
       "    12  (1, 1, 1) -5193.798982 -5179.875435 -5188.439242  2599.899491       True\n",
       "    13  (1, 1, 2) -5191.747097 -5173.182368 -5184.600777  2599.873548       True\n",
       "    14  (1, 1, 3) -5189.542663 -5166.336752 -5180.609763  2599.771331      False\n",
       "    15  (2, 0, 0) -5207.521273 -5188.951326 -5200.373382  2607.760636       True\n",
       "    16  (2, 0, 1) -5206.911630 -5183.699196 -5197.976766  2608.455815       True\n",
       "    17  (2, 0, 2) -5207.319751 -5179.464830 -5196.597914  2609.659875      False\n",
       "    18  (2, 0, 3) -5204.419196 -5171.921788 -5191.910386  2609.209598      False\n",
       "    19  (2, 1, 0) -4965.506101 -4951.582554 -4960.146361  2485.753050      False\n",
       "    20  (2, 1, 1) -5193.043445 -5174.478716 -5185.897125  2600.521722       True\n",
       "    21  (2, 1, 2) -5189.818763 -5166.612853 -5180.885864  2599.909382       True\n",
       "    22  (2, 1, 3) -5191.719271 -5163.872178 -5180.999791  2601.859636      False\n",
       "    23  (3, 0, 0) -5205.748828 -5182.536394 -5196.813964  2607.874414       True\n",
       "    24  (3, 0, 1) -5203.742387 -5175.887466 -5193.020550  2607.871193       True\n",
       "    25  (3, 0, 2) -5205.341321 -5172.843913 -5192.832511  2609.670660       True\n",
       "    26  (3, 0, 3) -5202.425512 -5165.285617 -5188.129729  2609.212756       True\n",
       "    27  (3, 1, 0) -4993.318168 -4974.753439 -4986.171848  2500.659084       True\n",
       "    28  (3, 1, 1) -5174.024904 -5150.818993 -5165.092004  2592.012452      False\n",
       "    29  (3, 1, 2) -5189.367687 -5161.520594 -5178.648207  2600.683843       True\n",
       "    30  (3, 1, 3) -5181.352972 -5148.864697 -5168.846912  2597.676486       True,\n",
       "    'successful_fits': 23,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 74.19354838709677},\n",
       "   'validation_scores': [np.float64(0.008957798444945424),\n",
       "    np.float64(0.007452441957579611),\n",
       "    np.float64(0.006552044134453671)],\n",
       "   'avg_validation_rmse': np.float64(0.007654094845659568),\n",
       "   'evaluation': {'model_order': (1, 0, 0),\n",
       "    'forecasts': 767     0.000401\n",
       "    768     0.000473\n",
       "    769     0.000474\n",
       "    770     0.000474\n",
       "    771     0.000474\n",
       "              ...   \n",
       "    1013    0.000474\n",
       "    1014    0.000474\n",
       "    1015    0.000474\n",
       "    1016    0.000474\n",
       "    1017    0.000474\n",
       "    Name: predicted_mean, Length: 251, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.015440           0.016242\n",
       "    768           -0.015368           0.016315\n",
       "    769           -0.015368           0.016316\n",
       "    770           -0.015368           0.016316\n",
       "    771           -0.015368           0.016316\n",
       "    ...                 ...                ...\n",
       "    1013          -0.015368           0.016316\n",
       "    1014          -0.015368           0.016316\n",
       "    1015          -0.015368           0.016316\n",
       "    1016          -0.015368           0.016316\n",
       "    1017          -0.015368           0.016316\n",
       "    \n",
       "    [251 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00011585422480508903,\n",
       "     'rmse': np.float64(0.01076356004327049),\n",
       "     'mae': 0.007414298626849634,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(52.400000000000006)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(13.046024328837602),\n",
       "     'ljung_box_pvalue': np.float64(0.22110992143439523),\n",
       "     'jarque_bera_stat': np.float64(157.51065503606668),\n",
       "     'jarque_bera_pvalue': np.float64(6.266078602627274e-35),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2012-12-14   -0.004618\n",
       "    2012-12-17    0.011361\n",
       "    2012-12-18    0.010864\n",
       "    2012-12-19   -0.008173\n",
       "    2012-12-20    0.005059\n",
       "                    ...   \n",
       "    2015-12-24   -0.002161\n",
       "    2015-12-28   -0.002640\n",
       "    2015-12-29    0.010119\n",
       "    2015-12-30   -0.007792\n",
       "    2015-12-31   -0.009874\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259517c2650>},\n",
       "  {'window_id': 13,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2014-01-03 to 2017-01-02',\n",
       "   'test_period': '2019-01-03 to 2020-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 252,\n",
       "   'best_order': (1, 0, 1),\n",
       "   'model_selection': {'best_order': (1, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259518158d0>,\n",
       "    'best_ic_value': np.float64(-5145.007552150224),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5144.967157 -5131.039696 -5139.606238  2575.483578      False\n",
       "    1   (0, 0, 2) -5143.296906 -5124.726959 -5136.149014  2575.648453       True\n",
       "    2   (0, 0, 3) -5141.489658 -5118.277224 -5132.554794  2575.744829       True\n",
       "    3   (0, 1, 0) -4606.213298 -4601.572116 -4604.426718  2304.106649      False\n",
       "    4   (0, 1, 1) -5132.462690 -5123.180326 -5128.889530  2568.231345       True\n",
       "    5   (0, 1, 2) -5130.492287 -5116.568741 -5125.132547  2568.246144      False\n",
       "    6   (0, 1, 3) -5128.472996 -5109.908267 -5121.326676  2568.236498      False\n",
       "    7   (1, 0, 0) -5144.967289 -5131.039828 -5139.606370  2575.483644       True\n",
       "    8   (1, 0, 1) -5145.007552 -5126.437605 -5137.859661  2576.503776       True\n",
       "    9   (1, 0, 2) -5141.917653 -5118.705219 -5132.982789  2575.958826       True\n",
       "    10  (1, 0, 3) -5140.351255 -5112.496335 -5129.629418  2576.175628       True\n",
       "    11  (1, 1, 0) -4817.424059 -4808.141695 -4813.850900  2410.712030       True\n",
       "    12  (1, 1, 1) -5130.491274 -5116.567727 -5125.131534  2568.245637      False\n",
       "    13  (1, 1, 2) -5130.266447 -5111.701718 -5123.120127  2569.133223      False\n",
       "    14  (1, 1, 3) -5079.541196 -5056.335285 -5070.608296  2544.770598       True\n",
       "    15  (2, 0, 0) -5143.249730 -5124.679783 -5136.101839  2575.624865       True\n",
       "    16  (2, 0, 1) -5143.088800 -5119.876366 -5134.153936  2576.544400       True\n",
       "    17  (2, 0, 2) -5141.880151 -5114.025230 -5131.158314  2576.940075       True\n",
       "    18  (2, 0, 3) -5139.764931 -5107.267523 -5127.256121  2576.882465       True\n",
       "    19  (2, 1, 0) -4906.236861 -4892.313314 -4900.877121  2456.118430       True\n",
       "    20  (2, 1, 1) -5128.350434 -5109.785705 -5121.204114  2568.175217      False\n",
       "    21  (2, 1, 2) -5126.521360 -5103.315449 -5117.588460  2568.260680      False\n",
       "    22  (2, 1, 3) -5126.578508 -5098.731415 -5115.859028  2569.289254       True\n",
       "    23  (3, 0, 0) -5141.403427 -5118.190993 -5132.468563  2575.701713       True\n",
       "    24  (3, 0, 1) -5139.407953 -5111.553032 -5128.686116  2575.703976      False\n",
       "    25  (3, 0, 2) -5140.100104 -5107.602696 -5127.591294  2577.050052       True\n",
       "    26  (3, 0, 3) -5137.892075 -5100.752181 -5123.596293  2576.946038      False\n",
       "    27  (3, 1, 0) -4937.952719 -4919.387991 -4930.806399  2472.976360       True\n",
       "    28  (3, 1, 1) -5120.631914 -5097.426004 -5111.699015  2565.315957      False\n",
       "    29  (3, 1, 2) -5123.825588 -5095.978495 -5113.106108  2567.912794      False\n",
       "    30  (3, 1, 3) -5095.457936 -5062.969661 -5082.951876  2554.728968       True,\n",
       "    'successful_fits': 19,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 61.29032258064516},\n",
       "   'validation_scores': [np.float64(0.004521503586220895),\n",
       "    np.float64(0.0070055708939890625),\n",
       "    np.float64(0.008168714328336745)],\n",
       "   'avg_validation_rmse': np.float64(0.006565262936182234),\n",
       "   'evaluation': {'model_order': (1, 0, 1),\n",
       "    'forecasts': 767     0.000228\n",
       "    768     0.000230\n",
       "    769     0.000231\n",
       "    770     0.000232\n",
       "    771     0.000234\n",
       "              ...   \n",
       "    1014    0.000288\n",
       "    1015    0.000288\n",
       "    1016    0.000288\n",
       "    1017    0.000288\n",
       "    1018    0.000288\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.016249           0.016705\n",
       "    768           -0.016247           0.016707\n",
       "    769           -0.016246           0.016708\n",
       "    770           -0.016245           0.016710\n",
       "    771           -0.016244           0.016711\n",
       "    ...                 ...                ...\n",
       "    1014          -0.016193           0.016769\n",
       "    1015          -0.016193           0.016769\n",
       "    1016          -0.016193           0.016769\n",
       "    1017          -0.016193           0.016769\n",
       "    1018          -0.016193           0.016769\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 6.246010485585354e-05,\n",
       "     'rmse': np.float64(0.007903170557178527),\n",
       "     'mae': 0.005656759585935522,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(59.76095617529881)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(7.493754344941291),\n",
       "     'ljung_box_pvalue': np.float64(0.678152715150794),\n",
       "     'jarque_bera_stat': np.float64(187.69948825079646),\n",
       "     'jarque_bera_pvalue': np.float64(1.7441105066036715e-41),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2013-12-16    0.006012\n",
       "    2013-12-17   -0.003367\n",
       "    2013-12-18    0.016234\n",
       "    2013-12-19   -0.000785\n",
       "    2013-12-20    0.004597\n",
       "                    ...   \n",
       "    2016-12-23    0.001089\n",
       "    2016-12-27    0.002086\n",
       "    2016-12-28   -0.008544\n",
       "    2016-12-29   -0.000491\n",
       "    2016-12-30   -0.004850\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259518162d0>},\n",
       "  {'window_id': 14,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2015-01-03 to 2018-01-02',\n",
       "   'test_period': '2020-01-03 to 2021-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (2, 0, 1),\n",
       "   'model_selection': {'best_order': (2, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x25951852c50>,\n",
       "    'best_ic_value': np.float64(-5268.751387225891),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5266.922926 -5252.991557 -5261.560831  2636.461463       True\n",
       "    1   (0, 0, 2) -5267.141274 -5248.566115 -5259.991814  2637.570637       True\n",
       "    2   (0, 0, 3) -5266.341698 -5243.122749 -5257.404872  2638.170849       True\n",
       "    3   (0, 1, 0) -4728.810836 -4724.168349 -4727.023863  2365.405418       True\n",
       "    4   (0, 1, 1) -5254.317031 -5245.032057 -5250.743085  2629.158515       True\n",
       "    5   (0, 1, 2) -5198.612554 -5184.685094 -5193.251636  2602.306277       True\n",
       "    6   (0, 1, 3) -5219.833348 -5201.263401 -5212.685457  2613.916674       True\n",
       "    7   (1, 0, 0) -5266.921833 -5252.990464 -5261.559738  2636.460917       True\n",
       "    8   (1, 0, 1) -5265.669620 -5247.094461 -5258.520160  2636.834810       True\n",
       "    9   (1, 0, 2) -5267.671686 -5244.452737 -5258.734860  2638.835843       True\n",
       "    10  (1, 0, 3) -5266.234093 -5238.371354 -5255.509902  2639.117046       True\n",
       "    11  (1, 1, 0) -4924.859366 -4915.574393 -4921.285421  2464.429683       True\n",
       "    12  (1, 1, 1) -5252.325625 -5238.398165 -5246.964707  2629.162813      False\n",
       "    13  (1, 1, 2) -5252.032636 -5233.462689 -5244.884745  2630.016318      False\n",
       "    14  (1, 1, 3) -5211.111063 -5187.898629 -5202.176199  2610.555532       True\n",
       "    15  (2, 0, 0) -5266.863761 -5248.288602 -5259.714300  2637.431880      False\n",
       "    16  (2, 0, 1) -5268.751387 -5245.532439 -5259.814562  2639.375694       True\n",
       "    17  (2, 0, 2) -5266.689259 -5238.826520 -5255.965068  2639.344629       True\n",
       "    18  (2, 0, 3) -5265.067470 -5232.560942 -5252.555914  2639.533735       True\n",
       "    19  (2, 1, 0) -5012.601766 -4998.674306 -5007.240848  2509.300883       True\n",
       "    20  (2, 1, 1) -5252.179152 -5233.609204 -5245.031260  2630.089576      False\n",
       "    21  (2, 1, 2) -5249.458123 -5226.245689 -5240.523259  2629.729062      False\n",
       "    22  (2, 1, 3) -5248.007562 -5220.152641 -5237.285725  2630.003781       True\n",
       "    23  (3, 0, 0) -5265.890670 -5242.671721 -5256.953844  2637.945335       True\n",
       "    24  (3, 0, 1) -5263.905170 -5236.042432 -5253.180979  2637.952585       True\n",
       "    25  (3, 0, 2) -5265.006639 -5232.500111 -5252.495083  2639.503319      False\n",
       "    26  (3, 0, 3) -5263.091813 -5225.941495 -5248.792892  2639.545907       True\n",
       "    27  (3, 1, 0) -5047.857309 -5029.287362 -5040.709418  2527.928655       True\n",
       "    28  (3, 1, 1) -5251.036217 -5227.823783 -5242.101353  2630.518108      False\n",
       "    29  (3, 1, 2) -5246.807600 -5218.952680 -5236.085764  2629.403800      False\n",
       "    30  (3, 1, 3) -5234.075877 -5201.578470 -5221.567067  2624.037939      False,\n",
       "    'successful_fits': 22,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 70.96774193548387},\n",
       "   'validation_scores': [np.float64(0.0092746041834411),\n",
       "    np.float64(0.01008885758095481),\n",
       "    np.float64(0.009431793852826052)],\n",
       "   'avg_validation_rmse': np.float64(0.009598418539073986),\n",
       "   'evaluation': {'model_order': (2, 0, 1),\n",
       "    'forecasts': 768     0.000558\n",
       "    769     0.000168\n",
       "    770     0.000219\n",
       "    771     0.000273\n",
       "    772     0.000310\n",
       "              ...   \n",
       "    1015    0.000381\n",
       "    1016    0.000381\n",
       "    1017    0.000381\n",
       "    1018    0.000381\n",
       "    1019    0.000381\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.014694           0.015810\n",
       "    769           -0.015084           0.015420\n",
       "    770           -0.015049           0.015488\n",
       "    771           -0.015004           0.015550\n",
       "    772           -0.014971           0.015591\n",
       "    ...                 ...                ...\n",
       "    1015          -0.014902           0.015665\n",
       "    1016          -0.014902           0.015665\n",
       "    1017          -0.014902           0.015665\n",
       "    1018          -0.014902           0.015665\n",
       "    1019          -0.014902           0.015665\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00047727270388459736,\n",
       "     'rmse': np.float64(0.02184657190235112),\n",
       "     'mae': 0.013521644000716636,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(57.37051792828686)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(5.333954888174668),\n",
       "     'ljung_box_pvalue': np.float64(0.8677827881964442),\n",
       "     'jarque_bera_stat': np.float64(407.0877160305349),\n",
       "     'jarque_bera_pvalue': np.float64(3.999683612844094e-89),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2014-12-15   -0.006744\n",
       "    2014-12-16   -0.008914\n",
       "    2014-12-17    0.019459\n",
       "    2014-12-18    0.022792\n",
       "    2014-12-19    0.004705\n",
       "                    ...   \n",
       "    2017-12-26   -0.001315\n",
       "    2017-12-27    0.000458\n",
       "    2017-12-28    0.001426\n",
       "    2017-12-29   -0.005572\n",
       "    2018-01-02    0.007931\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259518513d0>},\n",
       "  {'window_id': 15,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2016-01-03 to 2019-01-02',\n",
       "   'test_period': '2021-01-03 to 2022-01-02',\n",
       "   'train_size': 768,\n",
       "   'test_size': 252,\n",
       "   'best_order': (0, 0, 1),\n",
       "   'model_selection': {'best_order': (0, 0, 1),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259518866d0>,\n",
       "    'best_ic_value': np.float64(-5186.633254728162),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5186.633255 -5172.701886 -5181.271159  2596.316627       True\n",
       "    1   (0, 0, 2) -5185.393085 -5166.817926 -5178.243625  2596.696543       True\n",
       "    2   (0, 0, 3) -5184.472262 -5161.253313 -5175.535436  2597.236131       True\n",
       "    3   (0, 1, 0) -4625.410435 -4620.767948 -4623.623462  2313.705218       True\n",
       "    4   (0, 1, 1) -5173.492765 -5164.207792 -5169.918820  2588.746383       True\n",
       "    5   (0, 1, 2) -5172.352480 -5158.425020 -5166.991561  2589.176240      False\n",
       "    6   (0, 1, 3) -5109.105782 -5090.535835 -5101.957890  2558.552891       True\n",
       "    7   (1, 0, 0) -5186.573833 -5172.642464 -5181.211738  2596.286916      False\n",
       "    8   (1, 0, 1) -5184.519032 -5165.943873 -5177.369572  2596.259516       True\n",
       "    9   (1, 0, 2) -5184.673441 -5161.454492 -5175.736616  2597.336721       True\n",
       "    10  (1, 0, 3) -5183.058539 -5155.195801 -5172.334349  2597.529270       True\n",
       "    11  (1, 1, 0) -4843.844644 -4834.559671 -4840.270699  2423.922322       True\n",
       "    12  (1, 1, 1) -5172.295837 -5158.368377 -5166.934919  2589.147919       True\n",
       "    13  (1, 1, 2) -5175.801554 -5157.231607 -5168.653663  2591.900777      False\n",
       "    14  (1, 1, 3) -5176.075228 -5152.862794 -5167.140364  2593.037614       True\n",
       "    15  (2, 0, 0) -5185.542463 -5166.967304 -5178.393003  2596.771232       True\n",
       "    16  (2, 0, 1) -5181.726967 -5158.508018 -5172.790141  2595.863483       True\n",
       "    17  (2, 0, 2) -5182.162391 -5154.299652 -5171.438200  2597.081195       True\n",
       "    18  (2, 0, 3) -5183.390714 -5150.884186 -5170.879158  2598.695357       True\n",
       "    19  (2, 1, 0) -4962.365013 -4948.437553 -4957.004095  2484.182507       True\n",
       "    20  (2, 1, 1) -5171.219421 -5152.649474 -5164.071530  2589.609711      False\n",
       "    21  (2, 1, 2) -5169.005023 -5145.792589 -5160.070158  2589.502511       True\n",
       "    22  (2, 1, 3) -5166.452403 -5138.597482 -5155.730566  2589.226202       True\n",
       "    23  (3, 0, 0) -5184.573987 -5161.355038 -5175.637161  2597.286993       True\n",
       "    24  (3, 0, 1) -5182.556820 -5154.694082 -5171.832630  2597.278410       True\n",
       "    25  (3, 0, 2) -5180.332663 -5147.826135 -5167.821107  2597.166331       True\n",
       "    26  (3, 0, 3) -5175.727215 -5138.576897 -5161.428295  2595.863608       True\n",
       "    27  (3, 1, 0) -5004.127467 -4985.557520 -4996.979576  2506.063734       True\n",
       "    28  (3, 1, 1) -5152.265567 -5129.053133 -5143.330703  2581.132784      False\n",
       "    29  (3, 1, 2) -5172.299380 -5144.444459 -5161.577543  2592.149690      False\n",
       "    30  (3, 1, 3) -5155.171584 -5122.674177 -5142.662774  2584.585792      False,\n",
       "    'successful_fits': 24,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 77.41935483870968},\n",
       "   'validation_scores': [np.float64(0.008751952473769602),\n",
       "    np.float64(0.018230611994274115),\n",
       "    np.float64(0.016427393980021986)],\n",
       "   'avg_validation_rmse': np.float64(0.014469986149355234),\n",
       "   'evaluation': {'model_order': (0, 0, 1),\n",
       "    'forecasts': 768     0.000237\n",
       "    769     0.000284\n",
       "    770     0.000284\n",
       "    771     0.000284\n",
       "    772     0.000284\n",
       "              ...   \n",
       "    1015    0.000284\n",
       "    1016    0.000284\n",
       "    1017    0.000284\n",
       "    1018    0.000284\n",
       "    1019    0.000284\n",
       "    Name: predicted_mean, Length: 252, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    768           -0.015900           0.016374\n",
       "    769           -0.015864           0.016432\n",
       "    770           -0.015864           0.016432\n",
       "    771           -0.015864           0.016432\n",
       "    772           -0.015864           0.016432\n",
       "    ...                 ...                ...\n",
       "    1015          -0.015864           0.016432\n",
       "    1016          -0.015864           0.016432\n",
       "    1017          -0.015864           0.016432\n",
       "    1018          -0.015864           0.016432\n",
       "    1019          -0.015864           0.016432\n",
       "    \n",
       "    [252 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 6.833074301755908e-05,\n",
       "     'rmse': np.float64(0.008266241166186666),\n",
       "     'mae': 0.0062655863160727444,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(56.97211155378486)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(11.85613957979163),\n",
       "     'ljung_box_pvalue': np.float64(0.2947999550037758),\n",
       "     'jarque_bera_stat': np.float64(774.5603232207618),\n",
       "     'jarque_bera_pvalue': np.float64(6.402695705143333e-169),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2015-12-14    0.004460\n",
       "    2015-12-15    0.010443\n",
       "    2015-12-16    0.014512\n",
       "    2015-12-17   -0.014903\n",
       "    2015-12-18   -0.018792\n",
       "                    ...   \n",
       "    2018-12-26    0.047064\n",
       "    2018-12-27    0.009980\n",
       "    2018-12-28   -0.001158\n",
       "    2018-12-31    0.008130\n",
       "    2019-01-02    0.001284\n",
       "    Length: 768, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259528f58d0>},\n",
       "  {'window_id': 16,\n",
       "   'asset': 'S&P 500',\n",
       "   'train_period': '2017-01-03 to 2020-01-02',\n",
       "   'test_period': '2022-01-03 to 2023-01-02',\n",
       "   'train_size': 767,\n",
       "   'test_size': 251,\n",
       "   'best_order': (2, 0, 2),\n",
       "   'model_selection': {'best_order': (2, 0, 2),\n",
       "    'best_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x259518865d0>,\n",
       "    'best_ic_value': np.float64(-5221.114447924112),\n",
       "    'information_criterion': 'aic',\n",
       "    'results_df':         order          aic          bic         hqic          llf  converged\n",
       "    0   (0, 0, 1) -5218.925940 -5204.998480 -5213.565022  2612.462970       True\n",
       "    1   (0, 0, 2) -5219.009553 -5200.439606 -5211.861661  2613.504776       True\n",
       "    2   (0, 0, 3) -5219.352014 -5196.139580 -5210.417150  2614.676007       True\n",
       "    3   (0, 1, 0) -4656.443171 -4651.801988 -4654.656591  2329.221585      False\n",
       "    4   (0, 1, 1) -5205.262256 -5195.979892 -5201.689096  2604.631128       True\n",
       "    5   (0, 1, 2) -5204.342445 -5190.418899 -5198.982705  2605.171223      False\n",
       "    6   (0, 1, 3) -5148.260876 -5129.696147 -5141.114556  2578.130438       True\n",
       "    7   (1, 0, 0) -5218.829255 -5204.901795 -5213.468337  2612.414628       True\n",
       "    8   (1, 0, 1) -5215.753581 -5197.183634 -5208.605690  2611.876791       True\n",
       "    9   (1, 0, 2) -5219.050004 -5195.837570 -5210.115140  2614.525002       True\n",
       "    10  (1, 0, 3) -5217.673714 -5189.818793 -5206.951877  2614.836857       True\n",
       "    11  (1, 1, 0) -4865.558529 -4856.276165 -4861.985369  2434.779264       True\n",
       "    12  (1, 1, 1) -5204.229681 -5190.306134 -5198.869941  2605.114840      False\n",
       "    13  (1, 1, 2) -5206.184730 -5187.620001 -5199.038410  2607.092365       True\n",
       "    14  (1, 1, 3) -5155.967394 -5132.761483 -5147.034494  2582.983697       True\n",
       "    15  (2, 0, 0) -5219.227925 -5200.657978 -5212.080034  2613.613963       True\n",
       "    16  (2, 0, 1) -5218.472348 -5195.259914 -5209.537484  2614.236174       True\n",
       "    17  (2, 0, 2) -5221.114448 -5193.259527 -5210.392611  2616.557224       True\n",
       "    18  (2, 0, 3) -5218.973013 -5186.475605 -5206.464203  2616.486506       True\n",
       "    19  (2, 1, 0) -4998.802579 -4984.879032 -4993.442839  2502.401289       True\n",
       "    20  (2, 1, 1) -5204.503195 -5185.938466 -5197.356875  2606.251597      False\n",
       "    21  (2, 1, 2) -5202.497321 -5179.291410 -5193.564421  2606.248661      False\n",
       "    22  (2, 1, 3) -5197.365018 -5169.517925 -5186.645538  2604.682509      False\n",
       "    23  (3, 0, 0) -5219.725672 -5196.513238 -5210.790808  2614.862836       True\n",
       "    24  (3, 0, 1) -5217.687593 -5189.832672 -5206.965756  2614.843797       True\n",
       "    25  (3, 0, 2) -5218.457782 -5185.960375 -5205.948972  2616.228891      False\n",
       "    26  (3, 0, 3) -5219.483324 -5182.343430 -5205.187542  2617.741662       True\n",
       "    27  (3, 1, 0) -5037.471664 -5018.906935 -5030.325344  2522.735832       True\n",
       "    28  (3, 1, 1) -5199.364949 -5176.159038 -5190.432049  2604.682475      False\n",
       "    29  (3, 1, 2) -5203.344765 -5175.497672 -5192.625285  2607.672383      False\n",
       "    30  (3, 1, 3) -5196.942388 -5164.454113 -5184.436329  2605.471194       True,\n",
       "    'successful_fits': 22,\n",
       "    'total_attempts': 31,\n",
       "    'success_rate': 70.96774193548387},\n",
       "   'validation_scores': [np.float64(0.025369467398744065),\n",
       "    np.float64(0.019522205771833882),\n",
       "    np.float64(0.016513211221884566)],\n",
       "   'avg_validation_rmse': np.float64(0.020468294797487505),\n",
       "   'evaluation': {'model_order': (2, 0, 2),\n",
       "    'forecasts': 767    -4.398760e-04\n",
       "    768     5.078240e-04\n",
       "    769     1.051812e-03\n",
       "    770    -2.565151e-07\n",
       "    771     4.227171e-04\n",
       "                ...     \n",
       "    1013    4.672428e-04\n",
       "    1014    4.672428e-04\n",
       "    1015    4.672428e-04\n",
       "    1016    4.672428e-04\n",
       "    1017    4.672428e-04\n",
       "    Name: predicted_mean, Length: 251, dtype: float64,\n",
       "    'forecast_ci':       lower Log_Returns  upper Log_Returns\n",
       "    767           -0.016086           0.015207\n",
       "    768           -0.015148           0.016163\n",
       "    769           -0.014624           0.016728\n",
       "    770           -0.015706           0.015706\n",
       "    771           -0.015284           0.016130\n",
       "    ...                 ...                ...\n",
       "    1013          -0.015265           0.016199\n",
       "    1014          -0.015265           0.016199\n",
       "    1015          -0.015265           0.016199\n",
       "    1016          -0.015265           0.016199\n",
       "    1017          -0.015265           0.016199\n",
       "    \n",
       "    [251 rows x 2 columns],\n",
       "    'performance_metrics': {'mse': 0.00023323912224394543,\n",
       "     'rmse': np.float64(0.01527216822340382),\n",
       "     'mae': 0.012033392058585899,\n",
       "     'mape': nan,\n",
       "     'r2': np.float64(1.0),\n",
       "     'direction_accuracy': np.float64(43.2)},\n",
       "    'diagnostic_tests': {'ljung_box_stat': np.float64(11.40090562969639),\n",
       "     'ljung_box_pvalue': np.float64(0.3271481674488661),\n",
       "     'jarque_bera_stat': np.float64(1001.9357350810429),\n",
       "     'jarque_bera_pvalue': np.float64(2.706571574137454e-218),\n",
       "     'arch_stat': 'lb_stat',\n",
       "     'arch_pvalue': 'lb_pvalue'},\n",
       "    'residuals': Date\n",
       "    2016-12-14   -0.008618\n",
       "    2016-12-15    0.003091\n",
       "    2016-12-16   -0.002580\n",
       "    2016-12-19    0.002157\n",
       "    2016-12-20    0.002784\n",
       "                    ...   \n",
       "    2019-12-26    0.004302\n",
       "    2019-12-27   -0.000008\n",
       "    2019-12-30   -0.006020\n",
       "    2019-12-31    0.001797\n",
       "    2020-01-02    0.007817\n",
       "    Length: 767, dtype: float64},\n",
       "   'final_model': <statsmodels.tsa.arima.model.ARIMAResultsWrapper at 0x25951887b50>}],\n",
       " 'summary_df':     Window      Best_Order          AIC  Validation_RMSE  Test_RMSE  Test_MAE  Test_R2  Direction_Accuracy  Ljung_Box_p\n",
       " 0        1  ARIMA(0, 0, 1) -4531.000986         0.006387   0.010095  0.007215      1.0           54.581673     0.450981\n",
       " 1        2  ARIMA(0, 0, 1) -5169.691284         0.007280   0.025951  0.017486      1.0           50.396825     0.242693\n",
       " 2        3  ARIMA(0, 0, 2) -5528.972653         0.013374   0.017072  0.012247      1.0           55.600000     0.881979\n",
       " 3        4  ARIMA(0, 0, 1) -5285.447057         0.020314   0.011348  0.007956      1.0           56.972112     0.061980\n",
       " 4        5  ARIMA(2, 0, 1) -4177.234164         0.016620   0.014707  0.010445      1.0           45.418327     0.106116\n",
       " 5        6  ARIMA(3, 0, 2) -3948.980328         0.012166   0.008208  0.006031      1.0           47.200000     0.999040\n",
       " 6        7  ARIMA(3, 0, 0) -3925.724051         0.012817   0.006912  0.005379      1.0           41.832669     0.957060\n",
       " 7        8  ARIMA(1, 0, 1) -4308.283438         0.007820   0.007131  0.005200      1.0           57.768924     0.468033\n",
       " 8        9  ARIMA(3, 0, 2) -4664.412628         0.007032   0.009788  0.007238      1.0           47.600000     0.439333\n",
       " 9       10  ARIMA(3, 0, 2) -4850.923323         0.007482   0.008242  0.005774      1.0           51.792829     0.336950\n",
       " 10      11  ARIMA(1, 0, 0) -5329.166301         0.009562   0.004223  0.002979      1.0           56.972112     0.209596\n",
       " 11      12  ARIMA(1, 0, 0) -5208.216381         0.007654   0.010764  0.007414      1.0           52.400000     0.221110\n",
       " 12      13  ARIMA(1, 0, 1) -5145.007552         0.006565   0.007903  0.005657      1.0           59.760956     0.678153\n",
       " 13      14  ARIMA(2, 0, 1) -5268.751387         0.009598   0.021847  0.013522      1.0           57.370518     0.867783\n",
       " 14      15  ARIMA(0, 0, 1) -5186.633255         0.014470   0.008266  0.006266      1.0           56.972112     0.294800\n",
       " 15      16  ARIMA(2, 0, 2) -5221.114448         0.020468   0.015272  0.012033      1.0           43.200000     0.327148,\n",
       " 'performance_summary': {'total_windows': 16,\n",
       "  'successful_windows': 16,\n",
       "  'success_rate': 100.0,\n",
       "  'avg_test_rmse': np.float64(0.011733016510841875),\n",
       "  'std_test_rmse': 0.0058537496225881305,\n",
       "  'avg_test_mae': np.float64(0.008302557131544808),\n",
       "  'avg_r2': np.float64(1.0),\n",
       "  'avg_direction_accuracy': np.float64(52.239941029532666),\n",
       "  'avg_validation_rmse': np.float64(0.011225628325739987),\n",
       "  'most_common_order': 'ARIMA(0, 0, 1)'},\n",
       " 'methodology': {'approach': 'AIC-based automated selection',\n",
       "  'information_criterion': 'aic',\n",
       "  'parameter_space': 'pâˆˆ[0,3], dâˆˆ[0,1], qâˆˆ[0,3]',\n",
       "  'cross_validation': '3-fold temporal validation',\n",
       "  'evaluation_metric': 'Out-of-sample RMSE and direction accuracy'}}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_arima_results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "142936be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING S&P 500 LONG-SHORT STRATEGY\n",
      "================================================================================\n",
      "\n",
      "âœ“ Buy-and-Hold baseline: 5536 days\n",
      "\n",
      "Extracting strategy returns from each model...\n",
      "Aligned length: 3580 days\n",
      "\n",
      "Computing performance metrics...\n",
      "  âœ“ ARIMA: ARC=-0.0534, IR=-0.2595\n",
      "  âœ“ LSTM: ARC=-0.1302, IR=-0.6257\n",
      "  âœ“ SVM: ARC=-0.1203, IR=-0.5783\n",
      "\n",
      "Generating Table 2...\n",
      "\n",
      "==========================================================================================\n",
      "TABLE 2: S&P 500 Long-Short Strategy Results\n",
      "==========================================================================================\n",
      "Model       ARC      ASD       MD        IR       IR*        SR\n",
      "ARIMA -0.053411 0.205842 0.783347 -0.259474 -0.017692 -0.304556\n",
      " LSTM -0.130172 0.208031 0.874702 -0.625734 -0.093121 -0.741568\n",
      "  SVM -0.120320 0.208055 0.860939 -0.578305 -0.080820 -0.679134\n",
      "\n",
      "âœ“ Results saved to 'table2_sp500.csv'\n",
      "\n",
      "âœ“ Best Model: ARIMA (IR = -0.2595)\n"
     ]
    }
   ],
   "source": [
    "# S&P 500 Evaluation - APPROACH A\n",
    "TRADING_DAYS = 252\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING S&P 500 LONG-SHORT STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get benchmark returns (Buy-and-Hold)\n",
    "sp500_bnh_returns = sp500_clean['Log_Returns'].values\n",
    "\n",
    "print(f\"\\nâœ“ Buy-and-Hold baseline: {len(sp500_bnh_returns)} days\")\n",
    "\n",
    "# Extract STRATEGY RETURNS (already has signals applied!)\n",
    "print(\"\\nExtracting strategy returns from each model...\")\n",
    "\n",
    "sp500_arima_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_arima_results, sp500_clean\n",
    ")\n",
    "sp500_lstm_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_lstm_full, sp500_clean\n",
    ")\n",
    "sp500_svm_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    sp500_svm_full, sp500_clean\n",
    ")\n",
    "\n",
    "# Align lengths\n",
    "min_len = min(\n",
    "    len(sp500_arima_strategy_returns),\n",
    "    len(sp500_lstm_strategy_returns),\n",
    "    len(sp500_svm_strategy_returns),\n",
    "    len(sp500_bnh_returns)\n",
    ")\n",
    "\n",
    "sp500_arima_aligned = sp500_arima_strategy_returns.iloc[:min_len].values\n",
    "sp500_lstm_aligned = sp500_lstm_strategy_returns.iloc[:min_len].values\n",
    "sp500_svm_aligned = sp500_svm_strategy_returns.iloc[:min_len].values\n",
    "sp500_bnh_aligned = sp500_bnh_returns[:min_len]\n",
    "\n",
    "# sp500_arima_aligned = sp500_arima_strategy_returns[-min_len:]\n",
    "# sp500_lstm_aligned  = sp500_lstm_strategy_returns[-min_len:]\n",
    "# sp500_svm_aligned   = sp500_svm_strategy_returns[-min_len:]\n",
    "# sp500_bnh_aligned   = sp500_bnh_returns[-min_len:]\n",
    "print(f\"Aligned length: {min_len} days\")\n",
    "\n",
    "# Evaluate metrics directly (NO evaluate_model_longshort!)\n",
    "print(\"\\nComputing performance metrics...\")\n",
    "results_sp500 = []\n",
    "\n",
    "# ARIMA\n",
    "arima_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_arima_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "arima_metrics['Model'] = 'ARIMA'\n",
    "arima_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(sp500_arima_aligned > 0)) > 0))\n",
    "results_sp500.append(arima_metrics)\n",
    "print(f\"  âœ“ ARIMA: ARC={arima_metrics['ARC']:.4f}, IR={arima_metrics['IR']:.4f}\")\n",
    "\n",
    "# LSTM\n",
    "lstm_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_lstm_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "lstm_metrics['Model'] = 'LSTM'\n",
    "lstm_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(sp500_lstm_aligned > 0)) > 0))\n",
    "results_sp500.append(lstm_metrics)\n",
    "print(f\"  âœ“ LSTM: ARC={lstm_metrics['ARC']:.4f}, IR={lstm_metrics['IR']:.4f}\")\n",
    "\n",
    "# SVM\n",
    "svm_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_svm_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "svm_metrics['Model'] = 'SVM'\n",
    "svm_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(sp500_svm_aligned > 0)) > 0))\n",
    "results_sp500.append(svm_metrics)\n",
    "print(f\"  âœ“ SVM: ARC={svm_metrics['ARC']:.4f}, IR={svm_metrics['IR']:.4f}\")\n",
    "\n",
    "# Create TABLE 2\n",
    "print(\"\\nGenerating Table 2...\")\n",
    "table2_sp500 = pd.DataFrame(results_sp500)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"TABLE 2: S&P 500 Long-Short Strategy Results\")\n",
    "print(\"=\"*90)\n",
    "print(table2_sp500[['Model', 'ARC', 'ASD', 'MD', 'IR', 'IR*', 'SR']].to_string(index=False))\n",
    "\n",
    "table2_sp500.to_csv('table2_sp500.csv', index=False)\n",
    "print(\"\\nâœ“ Results saved to 'table2_sp500.csv'\")\n",
    "\n",
    "best_idx = table2_sp500['IR'].idxmax()\n",
    "print(f\"\\nâœ“ Best Model: {table2_sp500.loc[best_idx, 'Model']} (IR = {table2_sp500.loc[best_idx, 'IR']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999698b",
   "metadata": {},
   "source": [
    "## Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6966b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATING S&P 500 LONG-SHORT STRATEGY\n",
      "================================================================================\n",
      "\n",
      "âœ“ Buy-and-Hold baseline: 3285 days\n",
      "\n",
      "Extracting strategy returns from each model...\n",
      "Aligned length: 1699 days\n",
      "\n",
      "Computing performance metrics...\n",
      "  âœ“ ARIMA: ARC=-0.0976, IR=-0.3903\n",
      "  âœ“ LSTM: ARC=-0.1857, IR=-0.7347\n",
      "  âœ“ SVM: ARC=-0.1753, IR=-0.6935\n",
      "\n",
      "Generating Table 2...\n",
      "\n",
      "==========================================================================================\n",
      "TABLE 2: S&P 500 Long-Short Strategy Results\n",
      "==========================================================================================\n",
      "Model       ARC      ASD       MD        IR       IR*        SR\n",
      "ARIMA -0.097639 0.250197 0.808602 -0.390250 -0.047123 -0.526868\n",
      " LSTM -0.185721 0.252788 0.879089 -0.734691 -0.155215 -0.967020\n",
      "  SVM -0.175323 0.252811 0.874117 -0.693494 -0.139095 -0.904270\n",
      "\n",
      "âœ“ Results saved to 'table2_sp500.csv'\n",
      "\n",
      "âœ“ Best Model: ARIMA (IR = -0.3903)\n"
     ]
    }
   ],
   "source": [
    "# S&P 500 Evaluation - APPROACH A\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING S&P 500 LONG-SHORT STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "TRADING_DAYS = 365\n",
    "\n",
    "# Get benchmark returns (Buy-and-Hold)\n",
    "bitcoin_bnh_returns = bitcoin_clean['Log_Returns'].values\n",
    "\n",
    "# sp500_bnh_returns = sp500_clean['Log_Returns'].values\n",
    "\n",
    "print(f\"\\nâœ“ Buy-and-Hold baseline: {len(bitcoin_bnh_returns)} days\")\n",
    "\n",
    "# Extract STRATEGY RETURNS (already has signals applied!)\n",
    "print(\"\\nExtracting strategy returns from each model...\")\n",
    "\n",
    "\n",
    "bitcoin_arima_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    bitcoin_arima_results, bitcoin_clean\n",
    ")\n",
    "bitcoin_lstm_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    bitcoin_lstm_full, bitcoin_clean\n",
    ")\n",
    "bitcoin_svm_strategy_returns = extract_model_returns_from_results_fixed(\n",
    "    bitcoin_svm_full, bitcoin_clean\n",
    ")\n",
    "\n",
    "# Align lengths\n",
    "min_len = min(\n",
    "    len(bitcoin_arima_strategy_returns),\n",
    "    len(bitcoin_lstm_strategy_returns),\n",
    "    len(bitcoin_svm_strategy_returns),\n",
    "    len(bitcoin_bnh_returns)\n",
    ")\n",
    "\n",
    "bitcoin_arima_aligned = bitcoin_arima_strategy_returns.iloc[:min_len].values\n",
    "bitcoin_lstm_aligned = bitcoin_lstm_strategy_returns.iloc[:min_len].values\n",
    "bitcoin_svm_aligned = bitcoin_svm_strategy_returns.iloc[:min_len].values\n",
    "bitcoin_bnh_aligned = bitcoin_bnh_returns[:min_len]\n",
    "\n",
    "# sp500_arima_aligned = sp500_arima_strategy_returns[-min_len:]\n",
    "# sp500_lstm_aligned  = sp500_lstm_strategy_returns[-min_len:]\n",
    "# sp500_svm_aligned   = sp500_svm_strategy_returns[-min_len:]\n",
    "# sp500_bnh_aligned   = sp500_bnh_returns[-min_len:]\n",
    "print(f\"Aligned length: {min_len} days\")\n",
    "\n",
    "# Evaluate metrics directly (NO evaluate_model_longshort!)\n",
    "print(\"\\nComputing performance metrics...\")\n",
    "results_sp500 = []\n",
    "\n",
    "# ARIMA\n",
    "arima_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_arima_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "arima_metrics['Model'] = 'ARIMA'\n",
    "arima_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(bitcoin_arima_aligned > 0)) > 0))\n",
    "results_sp500.append(arima_metrics)\n",
    "print(f\"  âœ“ ARIMA: ARC={arima_metrics['ARC']:.4f}, IR={arima_metrics['IR']:.4f}\")\n",
    "\n",
    "# LSTM\n",
    "lstm_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_lstm_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "lstm_metrics['Model'] = 'LSTM'\n",
    "lstm_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(bitcoin_lstm_aligned > 0)) > 0))\n",
    "results_sp500.append(lstm_metrics)\n",
    "print(f\"  âœ“ LSTM: ARC={lstm_metrics['ARC']:.4f}, IR={lstm_metrics['IR']:.4f}\")\n",
    "\n",
    "# SVM\n",
    "svm_metrics = compute_performance_indicators(\n",
    "    pd.Series(sp500_svm_aligned),\n",
    "    pd.Series(sp500_bnh_aligned)\n",
    ")\n",
    "svm_metrics['Model'] = 'SVM'\n",
    "svm_metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(bitcoin_svm_aligned > 0)) > 0))\n",
    "results_sp500.append(svm_metrics)\n",
    "print(f\"  âœ“ SVM: ARC={svm_metrics['ARC']:.4f}, IR={svm_metrics['IR']:.4f}\")\n",
    "\n",
    "# Create TABLE 2\n",
    "print(\"\\nGenerating Table 2...\")\n",
    "table2_sp500 = pd.DataFrame(results_sp500)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"TABLE 2: S&P 500 Long-Short Strategy Results\")\n",
    "print(\"=\"*90)\n",
    "print(table2_sp500[['Model', 'ARC', 'ASD', 'MD', 'IR', 'IR*', 'SR']].to_string(index=False))\n",
    "\n",
    "table2_sp500.to_csv('table2_bitcoin.csv', index=False)\n",
    "print(\"\\nâœ“ Results saved to 'table2_bitcoin.csv'\")\n",
    "\n",
    "best_idx = table2_sp500['IR'].idxmax()\n",
    "print(f\"\\nâœ“ Best Model: {table2_sp500.loc[best_idx, 'Model']} (IR = {table2_sp500.loc[best_idx, 'IR']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdc334d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.000000\n",
       "1       0.000000\n",
       "2       0.006103\n",
       "3       0.000000\n",
       "4      -0.000000\n",
       "          ...   \n",
       "4023   -0.005851\n",
       "4024   -0.000000\n",
       "4025    0.012093\n",
       "4026   -0.017311\n",
       "4027   -0.000000\n",
       "Length: 4028, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_arima_strategy_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b25dd79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Dates After Fix ---\n",
      "Start: 2007-12-31 00:00:00\n",
      "End:   2023-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dates = sp500_clean.index[-len(sp500_arima_strategy_returns):] \n",
    "sp500_arima_strategy_returns.index = pd.to_datetime(dates)\n",
    "\n",
    "# OPTION B: If the index is just strings (e.g. '2022-01-01'), convert it directly\n",
    "# sp500_arima_strategy_returns.index = pd.to_datetime(sp500_arima_strategy_returns.index)\n",
    "\n",
    "# 3. Now Check the Period Again\n",
    "print(\"\\n--- Checking Dates After Fix ---\")\n",
    "print(f\"Start: {sp500_arima_strategy_returns.index.min()}\")\n",
    "print(f\"End:   {sp500_arima_strategy_returns.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57057cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2007-12-31   -0.000000\n",
       "2008-01-02    0.000000\n",
       "2008-01-03    0.006103\n",
       "2008-01-04    0.000000\n",
       "2008-01-07   -0.000000\n",
       "                ...   \n",
       "2023-12-22   -0.005851\n",
       "2023-12-26   -0.000000\n",
       "2023-12-27    0.012093\n",
       "2023-12-28   -0.017311\n",
       "2023-12-29   -0.000000\n",
       "Length: 4028, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_arima_strategy_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb6f3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Dates After Fix ---\n",
      "Start: 2009-10-09 00:00:00\n",
      "End:   2023-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dates = sp500_clean.index[-len(sp500_lstm_strategy_returns):] \n",
    "sp500_lstm_strategy_returns.index = pd.to_datetime(dates)\n",
    "\n",
    "# OPTION B: If the index is just strings (e.g. '2022-01-01'), convert it directly\n",
    "# sp500_arima_strategy_returns.index = pd.to_datetime(sp500_arima_strategy_returns.index)\n",
    "\n",
    "# 3. Now Check the Period Again\n",
    "print(\"\\n--- Checking Dates After Fix ---\")\n",
    "print(f\"Start: {sp500_lstm_strategy_returns.index.min()}\")\n",
    "print(f\"End:   {sp500_lstm_strategy_returns.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "564f7be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Dates After Fix ---\n",
      "Start: 2009-10-09 00:00:00\n",
      "End:   2023-12-29 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dates = sp500_clean.index[-len(sp500_svm_strategy_returns):] \n",
    "sp500_svm_strategy_returns.index = pd.to_datetime(dates)\n",
    "\n",
    "# OPTION B: If the index is just strings (e.g. '2022-01-01'), convert it directly\n",
    "# sp500_arima_strategy_returns.index = pd.to_datetime(sp500_arima_strategy_returns.index)\n",
    "\n",
    "# 3. Now Check the Period Again\n",
    "print(\"\\n--- Checking Dates After Fix ---\")\n",
    "print(f\"Start: {sp500_svm_strategy_returns.index.min()}\")\n",
    "print(f\"End:   {sp500_svm_strategy_returns.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f89ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_longshort_signals(predictions, transaction_costs, prediction_type='return'):\n",
    "#     \"\"\"\n",
    "#     Generate Long-Short trading signals matching paper's Section 4.5.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     predictions : array-like\n",
    "#         Model predictions (returns or volatility)\n",
    "#     transaction_costs : float\n",
    "#         0.005 for S&P 500, 0.01 for Bitcoin\n",
    "#     prediction_type : str\n",
    "#         'return' (paper's method) or 'volatility'\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     signals : np.array\n",
    "#         Trading signals: 1 (long), -1 (short), 0 (hold)\n",
    "    \n",
    "#     Signal Rules (from paper Section 4.5):\n",
    "#     - Signal = 1 if prediction > transaction_costs (BUY/LONG)\n",
    "#     - Signal = -1 if prediction < -transaction_costs (SELL/SHORT)\n",
    "#     - Signal = 0 if |prediction| <= transaction_costs (HOLD)\n",
    "#     \"\"\"\n",
    "#     predictions = np.asarray(predictions)\n",
    "    \n",
    "#     if prediction_type == 'return':\n",
    "#         signals = np.zeros(len(predictions))\n",
    "#         signals[predictions > transaction_costs] = 1\n",
    "#         signals[predictions < -transaction_costs] = -1\n",
    "#         return signals\n",
    "    \n",
    "#     elif prediction_type == 'volatility':\n",
    "#         pred_median = np.median(predictions)\n",
    "#         signals = np.where(predictions < pred_median, 1, -1)\n",
    "#         return signals\n",
    "    \n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown prediction_type: {prediction_type}\")\n",
    "\n",
    "\n",
    "# print(\"âœ“ Signal generation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efea94a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model_longshort(predictions, actual_returns, benchmark_returns,\n",
    "#                              asset_type='sp500', prediction_type='volatility',\n",
    "#                              model_name=\"Model\"):\n",
    "#     \"\"\"\n",
    "#     Evaluate a model's Long-Short strategy using all metrics.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     predictions : array-like\n",
    "#         Model predictions\n",
    "#     actual_returns : array-like\n",
    "#         Actual daily returns\n",
    "#     benchmark_returns : array-like\n",
    "#         Benchmark returns (e.g., Buy-and-Hold)\n",
    "#     asset_type : str\n",
    "#         'sp500' or 'bitcoin'\n",
    "#     prediction_type : str\n",
    "#         'return' or 'volatility'\n",
    "#     model_name : str\n",
    "#         Name of model for identification\n",
    "    \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     dict : Dictionary with all metrics and statistics\n",
    "#     \"\"\"\n",
    "#     # Ensure proper types and alignment\n",
    "#     predictions = np.asarray(predictions)\n",
    "#     actual_returns = np.asarray(actual_returns)\n",
    "#     benchmark_returns = np.asarray(benchmark_returns)\n",
    "    \n",
    "#     min_len = min(len(predictions), len(actual_returns), len(benchmark_returns))\n",
    "#     predictions = predictions[:min_len]\n",
    "#     actual_returns = actual_returns[:min_len]\n",
    "#     benchmark_returns = benchmark_returns[:min_len]\n",
    "    \n",
    "#     # Get transaction costs for asset\n",
    "#     transaction_costs = TRANSACTION_COSTS[asset_type]\n",
    "    \n",
    "#     # Generate Long-Short signals\n",
    "#     signals = generate_longshort_signals(predictions, transaction_costs, prediction_type)\n",
    "    \n",
    "#     # Calculate strategy returns\n",
    "#     strategy_returns = signals * actual_returns\n",
    "    \n",
    "#     # Convert to pandas Series for metric functions\n",
    "#     strategy_returns_series = pd.Series(strategy_returns)\n",
    "#     benchmark_returns_series = pd.Series(benchmark_returns)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     metrics = compute_performance_indicators(\n",
    "#         strategy_returns_series,\n",
    "#         benchmark_returns_series\n",
    "#     )\n",
    "    \n",
    "#     # Add trading statistics\n",
    "#     metrics['Model'] = model_name\n",
    "#     metrics['Num_Long'] = int(np.sum(signals == 1))\n",
    "#     metrics['Num_Short'] = int(np.sum(signals == -1))\n",
    "#     metrics['Num_Hold'] = int(np.sum(signals == 0))\n",
    "#     metrics['Num_Trades'] = int(np.sum(np.abs(np.diff(signals)) > 0))\n",
    "#     metrics['Win_Rate'] = float(np.mean(strategy_returns > 0))\n",
    "    \n",
    "#     return metrics\n",
    "\n",
    "\n",
    "# print(\"âœ“ Model evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "babdff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Align lengths\n",
    "# min_len = min(len(sp500_arima_returns), \n",
    "#               len(sp500_lstm_returns), \n",
    "#               len(sp500_svm_returns),\n",
    "#               len(sp500_bnh_returns))\n",
    "\n",
    "# print(f\"Aligning data lengths: {min_len} days\\n\")\n",
    "\n",
    "# sp500_arima_returns_aligned = sp500_arima_returns.iloc[:min_len].values\n",
    "# sp500_lstm_returns_aligned = sp500_lstm_returns.iloc[:min_len].values\n",
    "# sp500_svm_returns_aligned = sp500_svm_returns.iloc[:min_len].values\n",
    "# sp500_bnh_returns_aligned = sp500_bnh_returns[:min_len]\n",
    "\n",
    "# # Evaluate each model\n",
    "# print(\"Evaluating Long-Short strategies...\\n\")\n",
    "\n",
    "# results_sp500 = []\n",
    "\n",
    "# # ARIMA\n",
    "# print(\"  â€¢ Evaluating ARIMA...\")\n",
    "# arima_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_arima_returns_aligned,\n",
    "#     actual_returns=sp500_bnh_returns_aligned,\n",
    "#     benchmark_returns=sp500_bnh_returns_aligned,\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='volatility',\n",
    "#     model_name='ARIMA'\n",
    "# )\n",
    "# results_sp500.append(arima_metrics)\n",
    "# print(f\"    â†’ ARC: {arima_metrics['ARC']:.4f}, IR: {arima_metrics['IR']:.4f}\")\n",
    "\n",
    "# # LSTM\n",
    "# print(\"\\n  â€¢ Evaluating LSTM...\")\n",
    "# lstm_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_lstm_returns_aligned,\n",
    "#     actual_returns=sp500_bnh_returns_aligned,\n",
    "#     benchmark_returns=sp500_bnh_returns_aligned,\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='volatility',\n",
    "#     model_name='LSTM'\n",
    "# )\n",
    "# results_sp500.append(lstm_metrics)\n",
    "# print(f\"    â†’ ARC: {lstm_metrics['ARC']:.4f}, IR: {lstm_metrics['IR']:.4f}\")\n",
    "\n",
    "# # SVM\n",
    "# print(\"\\n  â€¢ Evaluating SVM...\")\n",
    "# svm_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_svm_returns_aligned,\n",
    "#     actual_returns=sp500_bnh_returns_aligned,\n",
    "#     benchmark_returns=sp500_bnh_returns_aligned,\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='volatility',\n",
    "#     model_name='SVM'\n",
    "# )\n",
    "# results_sp500.append(svm_metrics)\n",
    "# print(f\"    â†’ ARC: {svm_metrics['ARC']:.4f}, IR: {svm_metrics['IR']:.4f}\")\n",
    "\n",
    "# print(\"\\nâœ“ All models evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94f5efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "# table2_sp500 = pd.DataFrame(results_sp500)\n",
    "\n",
    "# # Display main metrics\n",
    "# print(\"\\n\" + \"=\"*90)\n",
    "# print(\"TABLE 2: S&P 500 Long-Short Strategy Results\")\n",
    "# print(\"=\"*90)\n",
    "# print(table2_sp500[['Model', 'ARC', 'ASD', 'MD', 'IR', 'IR*', 'SR', 'Num_Trades']].to_string(index=False))\n",
    "\n",
    "# # Find best model\n",
    "# best_sp500_idx = table2_sp500['IR'].idxmax()\n",
    "# best_sp500 = table2_sp500.loc[best_sp500_idx]\n",
    "# print(f\"\\nâœ“ Best S&P 500 Model: {best_sp500['Model']} (IR = {best_sp500['IR']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e69924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp500_bnh_returns = sp500_clean['Log_Returns'].values\n",
    "\n",
    "# sp500_bnh_returns = sp500_clean['Log_Returns'].values\n",
    "\n",
    "# # Step 2: Extract returns (same as before)\n",
    "# sp500_arima_returns = extract_model_returns_from_results_fixed(\n",
    "#     sp500_arima_results, sp500_clean\n",
    "# )\n",
    "# sp500_lstm_returns = extract_model_returns_from_results_fixed(\n",
    "#     sp500_lstm_full, sp500_clean\n",
    "# )\n",
    "# sp500_svm_returns = extract_model_returns_from_results_fixed(\n",
    "#     sp500_svm_full, sp500_clean\n",
    "# )\n",
    "\n",
    "# # Step 3: Align lengths\n",
    "# min_len = min(len(sp500_arima_returns), \n",
    "#               len(sp500_lstm_returns), \n",
    "#               len(sp500_svm_returns),\n",
    "#               len(sp500_bnh_returns))\n",
    "\n",
    "# # Step 4: Evaluate each model\n",
    "# results_sp500 = []\n",
    "\n",
    "# arima_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_arima_returns.iloc[:min_len].values,\n",
    "#     actual_returns=sp500_bnh_returns[:min_len],\n",
    "#     benchmark_returns=sp500_bnh_returns[:min_len],\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='return',\n",
    "#     model_name='ARIMA'\n",
    "# )\n",
    "# results_sp500.append(arima_metrics)\n",
    "\n",
    "# lstm_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_lstm_returns.iloc[:min_len].values,\n",
    "#     actual_returns=sp500_bnh_returns[:min_len],\n",
    "#     benchmark_returns=sp500_bnh_returns[:min_len],\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='return',\n",
    "#     model_name='LSTM'\n",
    "# )\n",
    "# results_sp500.append(lstm_metrics)\n",
    "\n",
    "# svm_metrics = evaluate_model_longshort(\n",
    "#     predictions=sp500_svm_returns.iloc[:min_len].values,\n",
    "#     actual_returns=sp500_bnh_returns[:min_len],\n",
    "#     benchmark_returns=sp500_bnh_returns[:min_len],\n",
    "#     asset_type='sp500',\n",
    "#     prediction_type='return',\n",
    "#     model_name='SVM'\n",
    "# )\n",
    "# results_sp500.append(svm_metrics)\n",
    "\n",
    "# # Step 5: Create table\n",
    "# table_sp500 = pd.DataFrame(results_sp500)\n",
    "# print(table_sp500[['Model', 'ARC', 'ASD', 'MD', 'IR', 'IR*', 'SR', 'Num_Trades']])\n",
    "# table_sp500.to_csv('table2_sp500.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
